Phenotyping at the plant level has crucial applications for highly valuable crops, species selection and botanical research. While two-dimensional imaging is sufficient for field-scale observation, individual monitoring requires three-dimensional imaging. It allows to reach a sufficient precision and level of information regarding the biological traits measured at this level. In this paper we present a 3D-scanning set-up that allows to reconstruct a plant in 3D organ-per-organ and produce a segmented point-cloud of the plant from 2D images taken at various viewpoints. Our method is fast and robust and requires little computational power as the complex step of segmentation is entirely processed at the image-level rather than the volume-level. The method we present relies on computer-vision neural network for the image segmentation. To bypass the problem of manual annotation required to train the network, we present a novel method which relies on 3D model of plants \emph{A. Thaliana} staged in a virtual environment to mimic the 3D scanner and acquire training images for the segmentation neural network. We present quantitative reconstruction results with the 3D virtual scanner and qualitative results with real \emph{A. Thaliana} plants. All the code is available on GitHub, and we address the issue of the ability to transfer the method to other plants by allowing a user to fine-tune the network on his own images. We show that the manual annotation of only two images is sufficient to obtain a reliable 3D reconstruction of a different plant, here a tomato plant.
