
@misc{colliaux_roboitic_nodate,
	title = {The roboitic naturalist and current {SOA} in semantic segmentation},
	url = {https://www.dropbox.com/s/4bynp9v7pk6k766/main.pdf?dl=0},
	abstract = {Partagé avec Dropbox},
	language = {fr},
	urldate = {2019-04-15},
	journal = {Dropbox},
	author = {Colliaux, David},
	file = {Snapshot:/home/alienor/Zotero/storage/8K2SY7AU/main.html:text/html}
}
@inproceedings{schoenberger2016sfm,
    author={Sch\"{o}nberger, Johannes Lutz and Frahm, Jan-Michael},
    title={Structure-from-Motion Revisited},
    booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
    year={2016},
}

@inproceedings{schoenberger2016mvs,
    author={Sch\"{o}nberger, Johannes Lutz and Zheng, Enliang and Pollefeys, Marc and Frahm, Jan-Michael},
    title={Pixelwise View Selection for Unstructured Multi-View Stereo},
    booktitle={European Conference on Computer Vision (ECCV)},
    year={2016},
}
@misc{noauthor_phytotyping4d:_nodate,
	title = {Phytotyping4D: a light‐field imaging system for non‐invasive and accurate monitoring of spatio‐temporal plant growth - {Apelt} - 2015 - {The} {Plant} {Journal} - {Wiley} {Online} {Library}},
	url = {https://onlinelibrary.wiley.com/doi/full/10.1111/tpj.12833},
	urldate = {2019-04-15},
	file = {Phytotyping4D\: a light‐field imaging system for non‐invasive and accurate monitoring of spatio‐temporal plant growth - Apelt - 2015 - The Plant Journal - Wiley Online Library:/home/alienor/Zotero/storage/5KGZ3FXQ/tpj.html:text/html}
}

@article{rezende_unsupervised_nodate,
	title = {Unsupervised {Learning} of 3D {Structure} from {Images}},
	abstract = {A key goal of computer vision is to recover the underlying 3D structure that gives rise to 2D observations of the world. If endowed with 3D understanding, agents can abstract away from the complexity of the rendering process to form stable, disentangled representations of scene elements. In this paper we learn strong deep generative models of 3D structures, and recover these structures from 2D images via probabilistic inference. We demonstrate high-quality samples and report log-likelihoods on several datasets, including ShapeNet [2], and establish the ﬁrst benchmarks in the literature. We also show how these models and their inference networks can be trained jointly, end-to-end, and directly from 2D images without any use of ground-truth 3D labels. This demonstrates for the ﬁrst time the feasibility of learning to infer 3D representations of the world in a purely unsupervised manner.},
	language = {en},
	author = {Rezende, Danilo Jimenez and Eslami, S M Ali and Mohamed, Shakir and Battaglia, Peter and Jaderberg, Max and Heess, Nicolas},
	pages = {9},
	file = {Rezende et al. - Unsupervised Learning of 3D Structure from Images.pdf:/home/alienor/Zotero/storage/KIGYM5MB/Rezende et al. - Unsupervised Learning of 3D Structure from Images.pdf:application/pdf}
}

@article{lawin_deep_2017,
	title = {Deep {Projective} 3D {Semantic} {Segmentation}},
	url = {http://arxiv.org/abs/1705.03428},
	abstract = {Semantic segmentation of 3D point clouds is a challenging problem with numerous real-world applications. While deep learning has revolutionized the ﬁeld of image semantic segmentation, its impact on point cloud data has been limited so far. Recent attempts, based on 3D deep learning approaches (3DCNNs), have achieved below-expected results. Such methods require voxelizations of the underlying point cloud data, leading to decreased spatial resolution and increased memory consumption. Additionally, 3D-CNNs greatly suffer from the limited availability of annotated datasets.},
	language = {en},
	urldate = {2019-04-30},
	journal = {arXiv:1705.03428 [cs]},
	author = {Lawin, Felix Järemo and Danelljan, Martin and Tosteberg, Patrik and Bhat, Goutam and Khan, Fahad Shahbaz and Felsberg, Michael},
	month = may,
	year = {2017},
	note = {arXiv: 1705.03428},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: Submitted to CAIP 2017},
	file = {Lawin et al. - 2017 - Deep Projective 3D Semantic Segmentation.pdf:/home/alienor/Zotero/storage/9YG9NQ3X/Lawin et al. - 2017 - Deep Projective 3D Semantic Segmentation.pdf:application/pdf}
}

@misc{noauthor_z-library_nodate,
	title = {Z-{Library}},
	url = {https://booksc.xyz/ireader/73005455},
	urldate = {2019-05-02},
	file = {Z-Library:/home/alienor/Zotero/storage/B5529VBC/73005455.html:text/html}
}

@misc{noauthor_z-library_nodate-1,
	title = {Z-{Library}},
	url = {https://booksc.xyz/ireader/67468964},
	urldate = {2019-05-02}
}

@inproceedings{fawakherji_crop_2019,
	address = {Naples, Italy},
	title = {Crop and {Weeds} {Classification} for {Precision} {Agriculture} {Using} {Context}-{Independent} {Pixel}-{Wise} {Segmentation}},
	isbn = {978-1-5386-9245-5},
	url = {https://ieeexplore.ieee.org/document/8675654/},
	doi = {10.1109/IRC.2019.00029},
	language = {en},
	urldate = {2019-05-02},
	booktitle = {2019 {Third} {IEEE} {International} {Conference} on {Robotic} {Computing} ({IRC})},
	publisher = {IEEE},
	author = {Fawakherji, Mulham and Youssef, Ali and Bloisi, Domenico and Pretto, Alberto and Nardi, Daniele},
	month = feb,
	year = {2019},
	pages = {146--152},
	file = {Fawakherji et al. - 2019 - Crop and Weeds Classification for Precision Agricu.pdf:/home/alienor/Zotero/storage/QJMPJUPK/Fawakherji et al. - 2019 - Crop and Weeds Classification for Precision Agricu.pdf:application/pdf}
}

@article{guo_review_2018,
	title = {A review of semantic segmentation using deep neural networks},
	volume = {7},
	issn = {2192-662X},
	url = {https://doi.org/10.1007/s13735-017-0141-z},
	doi = {10.1007/s13735-017-0141-z},
	abstract = {During the long history of computer vision, one of the grand challenges has been semantic segmentation which is the ability to segment an unknown image into different parts and objects (e.g., beach, ocean, sun, dog, swimmer). Furthermore, segmentation is even deeper than object recognition because recognition is not necessary for segmentation. Specifically, humans can perform image segmentation without even knowing what the objects are (for example, in satellite imagery or medical X-ray scans, there may be several objects which are unknown, but they can still be segmented within the image typically for further investigation). Performing segmentation without knowing the exact identity of all objects in the scene is an important part of our visual understanding process which can give us a powerful model to understand the world and also be used to improve or augment existing computer vision techniques. Herein this work, we review the field of semantic segmentation as pertaining to deep convolutional neural networks. We provide comprehensive coverage of the top approaches and summarize the strengths, weaknesses and major challenges.},
	language = {en},
	number = {2},
	urldate = {2019-05-03},
	journal = {International Journal of Multimedia Information Retrieval},
	author = {Guo, Yanming and Liu, Yu and Georgiou, Theodoros and Lew, Michael S.},
	month = jun,
	year = {2018},
	keywords = {Computer vision, Convolutional neural networks, Deep learning, Image segmentation, Machine learning},
	pages = {87--93},
	file = {Springer Full Text PDF:/home/alienor/Zotero/storage/VWLIEEES/Guo et al. - 2018 - A review of semantic segmentation using deep neura.pdf:application/pdf}
}

@article{caesar_region-based_2016,
	title = {Region-based semantic segmentation with end-to-end training},
	url = {http://arxiv.org/abs/1607.07671},
	abstract = {We propose a novel method for semantic segmentation, the task of labeling each pixel in an image with a semantic class. Our method combines the advantages of the two main competing paradigms. Methods based on region classiﬁcation oﬀer proper spatial support for appearance measurements, but typically operate in two separate stages, none of which targets pixel labeling performance at the end of the pipeline. More recent fully convolutional methods are capable of end-to-end training for the ﬁnal pixel labeling, but resort to ﬁxed patches as spatial support. We show how to modify modern region-based approaches to enable end-to-end training for semantic segmentation. This is achieved via a diﬀerentiable region-to-pixel layer and a diﬀerentiable free-form Regionof-Interest pooling layer. Our method improves the state-of-the-art in terms of class-average accuracy with 64.0\% on SIFT Flow and 49.9\% on PASCAL Context, and is particularly accurate at object boundaries.},
	language = {en},
	urldate = {2019-05-03},
	journal = {arXiv:1607.07671 [cs]},
	author = {Caesar, Holger and Uijlings, Jasper and Ferrari, Vittorio},
	month = jul,
	year = {2016},
	note = {arXiv: 1607.07671},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: ECCV 2016 camera-ready},
	file = {Caesar et al. - 2016 - Region-based semantic segmentation with end-to-end.pdf:/home/alienor/Zotero/storage/U5XLME3X/Caesar et al. - 2016 - Region-based semantic segmentation with end-to-end.pdf:application/pdf}
}

@article{chen_tensormask:_2019,
	title = {{TensorMask}: {A} {Foundation} for {Dense} {Object} {Segmentation}},
	shorttitle = {{TensorMask}},
	url = {http://arxiv.org/abs/1903.12174},
	abstract = {Sliding-window object detectors that generate boundingbox object predictions over a dense, regular grid have advanced rapidly and proven popular. In contrast, modern instance segmentation approaches are dominated by methods that ﬁrst detect object bounding boxes, and then crop and segment these regions, as popularized by Mask R-CNN. In this work, we investigate the paradigm of dense slidingwindow instance segmentation, which is surprisingly underexplored. Our core observation is that this task is fundamentally different than other dense prediction tasks such as semantic segmentation or bounding-box object detection, as the output at every spatial location is itself a geometric structure with its own spatial dimensions. To formalize this, we treat dense instance segmentation as a prediction task over 4D tensors and present a general framework called TensorMask that explicitly captures this geometry and enables novel operators on 4D tensors. We demonstrate that the tensor view leads to large gains over baselines that ignore this structure, and leads to results comparable to Mask R-CNN. These promising results suggest that TensorMask can serve as a foundation for novel advances in dense mask prediction and a more complete understanding of the task. Code will be made available.},
	language = {en},
	urldate = {2019-05-03},
	journal = {arXiv:1903.12174 [cs]},
	author = {Chen, Xinlei and Girshick, Ross and He, Kaiming and Dollár, Piotr},
	month = mar,
	year = {2019},
	note = {arXiv: 1903.12174},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: 12 pages, technical report},
	file = {Chen et al. - 2019 - TensorMask A Foundation for Dense Object Segmenta.pdf:/home/alienor/Zotero/storage/PN9Q63IA/Chen et al. - 2019 - TensorMask A Foundation for Dense Object Segmenta.pdf:application/pdf}
}

@article{mondal_few-shot_2018,
	title = {Few-shot 3D {Multi}-modal {Medical} {Image} {Segmentation} using {Generative} {Adversarial} {Learning}},
	url = {http://arxiv.org/abs/1810.12241},
	abstract = {We address the problem of segmenting 3D multimodal medical images in scenarios where very few labeled examples are available for training. Leveraging the recent success of adversarial learning for semi-supervised segmentation, we propose a novel method based on Generative Adversarial Networks (GANs) to train a segmentation model with both labeled and unlabeled images. The proposed method prevents over-ﬁtting by learning to discriminate between true and fake patches obtained by a generator network. Our work extends current adversarial learning approaches, which focus on 2D single-modality images, to the more challenging context of 3D volumes of multiple modalities. The proposed method is evaluated on the problem of segmenting brain MRI from the iSEG-2017 and MRBrainS 2013 datasets. Signiﬁcant performance improvement is reported, compared to state-of-art segmentation networks trained in a fully-supervised manner. In addition, our work presents a comprehensive analysis of different GAN architectures for semi-supervised segmentation, showing recent techniques like feature matching to yield a higher performance than conventional adversarial training approaches. Our code is publicly available at https://github.com/arnab39/FewShot GAN-Unet3D.},
	language = {en},
	urldate = {2019-05-03},
	journal = {arXiv:1810.12241 [cs]},
	author = {Mondal, Arnab Kumar and Dolz, Jose and Desrosiers, Christian},
	month = oct,
	year = {2018},
	note = {arXiv: 1810.12241},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: submitted to Medical Image Analysis for review},
	file = {Mondal et al. - 2018 - Few-shot 3D Multi-modal Medical Image Segmentation.pdf:/home/alienor/Zotero/storage/5JULGRWY/Mondal et al. - 2018 - Few-shot 3D Multi-modal Medical Image Segmentation.pdf:application/pdf}
}

@article{huang_eanet:_2018,
	title = {{EANet}: {Enhancing} {Alignment} for {Cross}-{Domain} {Person} {Re}-identification},
	shorttitle = {{EANet}},
	url = {http://arxiv.org/abs/1812.11369},
	abstract = {Person re-identification (ReID) has achieved significant improvement under the single-domain setting. However, directly exploiting a model to new domains is always faced with huge performance drop, and adapting the model to new domains without target-domain identity labels is still challenging. In this paper, we address cross-domain ReID and make contributions for both model generalization and adaptation. First, we propose Part Aligned Pooling (PAP) that brings significant improvement for cross-domain testing. Second, we design a Part Segmentation (PS) constraint over ReID feature to enhance alignment and improve model generalization. Finally, we show that applying our PS constraint to unlabeled target domain images serves as effective domain adaptation. We conduct extensive experiments between three large datasets, Market1501, CUHK03 and DukeMTMC-reID. Our model achieves state-of-the-art performance under both source-domain and cross-domain settings. For completeness, we also demonstrate the complementarity of our model to existing domain adaptation methods. The code is available at https://github.com/huanghoujing/EANet.},
	urldate = {2019-05-03},
	journal = {arXiv:1812.11369 [cs]},
	author = {Huang, Houjing and Yang, Wenjie and Chen, Xiaotang and Zhao, Xin and Huang, Kaiqi and Lin, Jinbin and Huang, Guan and Du, Dalong},
	month = dec,
	year = {2018},
	note = {arXiv: 1812.11369},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv\:1812.11369 PDF:/home/alienor/Zotero/storage/SGLNCT7L/Huang et al. - 2018 - EANet Enhancing Alignment for Cross-Domain Person.pdf:application/pdf;arXiv.org Snapshot:/home/alienor/Zotero/storage/2RSYRS6D/1812.html:text/html}
}

@article{chen_deeplab:_2016,
	title = {{DeepLab}: {Semantic} {Image} {Segmentation} with {Deep} {Convolutional} {Nets}, {Atrous} {Convolution}, and {Fully} {Connected} {CRFs}},
	shorttitle = {{DeepLab}},
	url = {http://arxiv.org/abs/1606.00915},
	abstract = {In this work we address the task of semantic image segmentation with Deep Learning and make three main contributions that are experimentally shown to have substantial practical merit. First, we highlight convolution with upsampled ﬁlters, or ‘atrous convolution’, as a powerful tool in dense prediction tasks. Atrous convolution allows us to explicitly control the resolution at which feature responses are computed within Deep Convolutional Neural Networks. It also allows us to effectively enlarge the ﬁeld of view of ﬁlters to incorporate larger context without increasing the number of parameters or the amount of computation. Second, we propose atrous spatial pyramid pooling (ASPP) to robustly segment objects at multiple scales. ASPP probes an incoming convolutional feature layer with ﬁlters at multiple sampling rates and effective ﬁelds-of-views, thus capturing objects as well as image context at multiple scales. Third, we improve the localization of object boundaries by combining methods from DCNNs and probabilistic graphical models. The commonly deployed combination of max-pooling and downsampling in DCNNs achieves invariance but has a toll on localization accuracy. We overcome this by combining the responses at the ﬁnal DCNN layer with a fully connected Conditional Random Field (CRF), which is shown both qualitatively and quantitatively to improve localization performance. Our proposed “DeepLab” system sets the new state-of-art at the PASCAL VOC-2012 semantic image segmentation task, reaching 79.7\% mIOU in the test set, and advances the results on three other datasets: PASCAL-Context, PASCAL-Person-Part, and Cityscapes. All of our code is made publicly available online.},
	language = {en},
	urldate = {2019-05-03},
	journal = {arXiv:1606.00915 [cs]},
	author = {Chen, Liang-Chieh and Papandreou, George and Kokkinos, Iasonas and Murphy, Kevin and Yuille, Alan L.},
	month = jun,
	year = {2016},
	note = {arXiv: 1606.00915},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: Accepted by TPAMI},
	file = {Chen et al. - 2016 - DeepLab Semantic Image Segmentation with Deep Con.pdf:/home/alienor/Zotero/storage/JPCL7PJN/Chen et al. - 2016 - DeepLab Semantic Image Segmentation with Deep Con.pdf:application/pdf}
}

@article{dezulian_conservation_nodate,
	title = {Conservation and divergence of {microRNA} families in plants},
	abstract = {Background: MicroRNAs (miRNAs) are 20 to 24 nucleotides short RNAs involved in posttranscriptional regulation in plants and animals. MiRNAs are processed from larger precursors with extensive secondary structure. In plants, a total of 286 miRNA genes in Arabidopsis, rice and maize had been identified by March 2005, clustered in 43 families.
Results: Here, we report the bioinformatic identification of 200 members of the 43 miRNA families in the genomes of maize, sorghum, medick and poplar. Furthermore, we report evidence for expression of 37 miRNA precursors that are present in EST collections of soybean and sugarcane. We have used the enlarged data set to systematically analyze several parameters of the plant precursors including stem length, conservation of the precursors and variation in the secondary structure of the miRNA along the precursor.
Conclusion: Based on this 83\% increase in available miRNA precursor sequences, we present an improved view of phylogenetic distribution, positional nucleotide preference, structural features and conservation of miRNA genes. Our results suggest that there are two different classes of plant miRNA precursors. The most abundant class includes precursors that have only two strongly conserved regions, corresponding to the mature miRNA and its complementary sequence. A less frequent class, which includes the miRNA families miR159/319 and miR394, displays two additional conserved sequence blocks. These precursors have larger stems with more extensive secondary structure.},
	language = {en},
	author = {Dezulian, Tobias and Palatnik, Javier F and Huson, Daniel and Weigel, Detlef},
	pages = {25},
	file = {Dezulian et al. - Conservation and divergence of microRNA families i.pdf:/home/alienor/Zotero/storage/A6VFEX3L/Dezulian et al. - Conservation and divergence of microRNA families i.pdf:application/pdf}
}

@article{chaudhary_nanotechnology_2018,
	title = {Nanotechnology based approaches for detection and delivery of {microRNA} in healthcare and crop protection},
	volume = {16},
	issn = {1477-3155},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5897953/},
	doi = {10.1186/s12951-018-0368-8},
	abstract = {Nanobiotechnology has the potential to revolutionize diverse sectors including medicine, agriculture, food, textile and pharmaceuticals. Disease diagnostics, therapeutics and crop protection strategies are fast emerging using nanomaterials preferably nanobiomaterials. It has potential for development of novel nanobiomolecules which offer several advantages over conventional treatment methods. RNA nanoparticles with many unique features are promising candidates in disease treatment. The miRNAs are involved in many biochemical and developmental pathways and their regulation in plants and animals. These appear to be a powerful tool for controlling various pathological diseases in human, plants and animals, however there are challenges associated with miRNA based nanotechnology. Several advancements made in the field of miRNA therapeutics make it an attractive approach, but a lot more has to be explored in nanotechnology assisted miRNA therapy. The miRNA based technologies can be employed for detection and combating crop diseases as well. Despite these potential advantages, nanobiotechnology applications in the agricultural sector are still in its infancy and have not yet made its mark in comparison with healthcare sector. The review provides a platform to discuss nature, role and use of miRNAs in nanobiotechnology applications.},
	urldate = {2019-05-10},
	journal = {Journal of Nanobiotechnology},
	author = {Chaudhary, Vrantika and Jangra, Sumit and Yadav, Neelam R.},
	month = apr,
	year = {2018},
	pmid = {29653577},
	pmcid = {PMC5897953},
	file = {PubMed Central Full Text PDF:/home/alienor/Zotero/storage/YJFCVDFA/Chaudhary et al. - 2018 - Nanotechnology based approaches for detection and .pdf:application/pdf}
}

@article{djami-tchatchou_functional_2017,
	title = {Functional {Roles} of {microRNAs} in {Agronomically} {Important} {Plants}—{Potential} as {Targets} for {Crop} {Improvement} and {Protection}},
	volume = {8},
	issn = {1664-462X},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5360763/},
	doi = {10.3389/fpls.2017.00378},
	abstract = {MicroRNAs (miRNAs) are a class of small non-coding RNAs that have recently emerged as important regulators of gene expression, mainly through cleavage and/or translation inhibition of the target mRNAs during or after transcription. miRNAs play important roles by regulating a multitude of biological processes in plants which include maintenance of genome integrity, development, metabolism, and adaptive responses toward environmental stresses. The increasing population of the world and their food demands requires focused efforts for the improvement of crop plants to ensure sustainable food production. Manipulation of mRNA transcript abundance via miRNA control provides a unique strategy for modulating differential plant gene expression and miRNAs are thus emerging as the next generation targets for genetic engineering for improvement of the agronomic properties of crops. However, a deeper understanding of its potential and the mechanisms involved will facilitate the design of suitable strategies to obtain the desirable traits with minimum trade-offs in the modified crops. In this regard, this review highlights the diverse roles of conserved and newly identified miRNAs in various food and industrial crops and recent advances made in the uses of miRNAs to improve plants of agronomically importance so as to significantly enhance crop yields and increase tolerance to various environmental stress agents of biotic—or abiotic origin.},
	urldate = {2019-05-10},
	journal = {Frontiers in Plant Science},
	author = {Djami-Tchatchou, Arnaud T. and Sanan-Mishra, Neeti and Ntushelo, Khayalethu and Dubery, Ian A.},
	month = mar,
	year = {2017},
	pmid = {28382044},
	pmcid = {PMC5360763},
	file = {PubMed Central Full Text PDF:/home/alienor/Zotero/storage/C9U49N2X/Djami-Tchatchou et al. - 2017 - Functional Roles of microRNAs in Agronomically Imp.pdf:application/pdf}
}

@article{bej_micrornas:_2014,
	title = {{MicroRNAs}: {The} {Potential} {Biomarkers} in {Plant} {Stress} {Response}},
	volume = {2014},
	issn = {2158-2750},
	shorttitle = {{MicroRNAs}},
	url = {http://www.scirp.org/journal/PaperInformation.aspx?PaperID=43925},
	doi = {10.4236/ajps.2014.55089},
	abstract = {MicroRNAs (miRNAs) are endogenous small RNA regulatory molecules of approximate 20-24 nucleotides that are involved in regulating the intrinsic growth and development of organs in plants and animals as well as in maintaining the integrity of genomes. Past few years have witnessed an increase in research reports on the crucial role of miRNAs in plant stress response. Plant miRNAs regulate gene expression at the post-transcriptional level not only by suppression of mRNA translation but also by direct cleavage of the target mRNAs. This review starts with a brief overview on small RNAs including miRNAs, biogenesis of miRNA and focuses mainly on the various up and down-regulated plant miRNAs under different biotic and abiotic stresses showing advancement of studies about miRNA and their stress regulation pathway. This review explores the emerging role of miRNAs as potential biomarkers in plant stress responses.},
	language = {en},
	urldate = {2019-05-10},
	journal = {American Journal of Plant Sciences},
	author = {Bej, Sonali and Basak, Jolly},
	month = mar,
	year = {2014},
	file = {Full Text PDF:/home/alienor/Zotero/storage/MCKEH8ZW/Bej et Basak - 2014 - MicroRNAs The Potential Biomarkers in Plant Stres.pdf:application/pdf;Snapshot:/home/alienor/Zotero/storage/HFLJ8BJQ/24-2601317_43925.html:text/html}
}

@article{xin_diverse_2010,
	title = {Diverse set of {microRNAs} are responsive to powdery mildew infection and heat stress in wheat ({Triticum} aestivum {L}.)},
	volume = {10},
	issn = {1471-2229},
	url = {https://doi.org/10.1186/1471-2229-10-123},
	doi = {10.1186/1471-2229-10-123},
	abstract = {MicroRNAs (miRNAs) are a class of small non-coding regulatory RNAs that regulate gene expression by guiding target mRNA cleavage or translational inhibition. MiRNAs can have large-scale regulatory effects on development and stress response in plants.},
	number = {1},
	urldate = {2019-05-10},
	journal = {BMC Plant Biology},
	author = {Xin, Mingming and Wang, Yu and Yao, Yingyin and Xie, Chaojie and Peng, Huiru and Ni, Zhongfu and Sun, Qixin},
	month = jun,
	year = {2010},
	pages = {123},
	file = {Full Text PDF:/home/alienor/Zotero/storage/SMBGBCYR/Xin et al. - 2010 - Diverse set of microRNAs are responsive to powdery.pdf:application/pdf;Snapshot:/home/alienor/Zotero/storage/8TZNI9BN/1471-2229-10-123.html:text/html}
}

@article{venkat_rajam_micro_2012,
	title = {Micro {RNA} {Interference}: {A} {New} {Platform} for {Crop} {Protection}},
	volume = {01},
	issn = {21689296},
	shorttitle = {Micro {RNA} {Interference}},
	url = {https://www.omicsonline.org/open-access/micro-rna-interference-a-new-platform-for-crop-protection-2168-9296.1000e115.php?aid=8884},
	doi = {10.4172/2168-9296.1000e115},
	language = {en},
	number = {06},
	urldate = {2019-05-10},
	journal = {Cell \& Developmental Biology},
	author = {Venkat Rajam, Manchikatla},
	year = {2012},
	file = {Venkat Rajam - 2012 - Micro RNA Interference A New Platform for Crop Pr.pdf:/home/alienor/Zotero/storage/UBVAYLMX/Venkat Rajam - 2012 - Micro RNA Interference A New Platform for Crop Pr.pdf:application/pdf}
}

@article{hartmann_les_2004,
	title = {Les {microARN}: {Une} nouvelle classe de régulateurs de l’expression génique},
	volume = {20},
	issn = {0767-0974, 1958-5381},
	shorttitle = {Les {microARN}},
	url = {http://www.medecinesciences.org/10.1051/medsci/20042010894},
	doi = {10.1051/medsci/20042010894},
	number = {10},
	urldate = {2019-05-10},
	journal = {médecine/sciences},
	author = {Hartmann, Caroline and Corre-Menguy, Fabienne and Boualem, Adnane and Jovanovic, Mariana and Lelandais-Brière, Christine},
	month = oct,
	year = {2004},
	pages = {894--898},
	file = {Texte intégral:/home/alienor/Zotero/storage/NF5H8Z6U/Hartmann et al. - 2004 - Les microARN Une nouvelle classe de régulateurs d.pdf:application/pdf}
}

@inproceedings{soltani_synthesizing_2017,
	address = {Honolulu, HI},
	title = {Synthesizing 3D {Shapes} via {Modeling} {Multi}-view {Depth} {Maps} and {Silhouettes} with {Deep} {Generative} {Networks}},
	isbn = {978-1-5386-0457-1},
	url = {http://ieeexplore.ieee.org/document/8099752/},
	doi = {10.1109/CVPR.2017.269},
	abstract = {We study the problem of learning generative models of 3D shapes. Voxels or 3D parts have been widely used as the underlying representations to build complex 3D shapes; however, voxel-based representations suffer from high memory requirements, and parts-based models require a large collection of cached or richly parametrized parts. We take an alternative approach: learning a generative model over multi-view depth maps or their corresponding silhouettes, and using a deterministic rendering function to produce 3D shapes from these images. A multi-view representation of shapes enables generation of 3D models with ﬁne details, as 2D depth maps and silhouettes can be modeled at a much higher resolution than 3D voxels. Moreover, our approach naturally brings the ability to recover the underlying 3D representation from depth maps of one or a few viewpoints. Experiments show that our framework can generate 3D shapes with variations and details. We also demonstrate that our model has out-of-sample generalization power for real-world tasks with occluded objects.},
	language = {en},
	urldate = {2019-05-29},
	booktitle = {2017 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Soltani, Amir Arsalan and Huang, Haibin and Wu, Jiajun and Kulkarni, Tejas D. and Tenenbaum, Joshua B.},
	month = jul,
	year = {2017},
	pages = {2511--2519},
	file = {Soltani et al. - 2017 - Synthesizing 3D Shapes via Modeling Multi-view Dep.pdf:/home/alienor/Zotero/storage/B28JDP4S/Soltani et al. - 2017 - Synthesizing 3D Shapes via Modeling Multi-view Dep.pdf:application/pdf}
}

@article{dai_3dmv:_2018,
	title = {3DMV: {Joint} 3D-{Multi}-{View} {Prediction} for 3D {Semantic} {Scene} {Segmentation}},
	shorttitle = {3DMV},
	url = {http://arxiv.org/abs/1803.10409},
	abstract = {We present 3DMV, a novel method for 3D semantic scene segmentation of RGB-D scans in indoor environments using a joint 3Dmulti-view prediction network. In contrast to existing methods that either use geometry or RGB data as input for this task, we combine both data modalities in a joint, end-to-end network architecture. Rather than simply projecting color data into a volumetric grid and operating solely in 3D – which would result in insuﬃcient detail – we ﬁrst extract feature maps from associated RGB images. These features are then mapped into the volumetric feature grid of a 3D network using a diﬀerentiable backprojection layer. Since our target is 3D scanning scenarios with possibly many frames, we use a multi-view pooling approach in order to handle a varying number of RGB input views. This learned combination of RGB and geometric features with our joint 2D-3D architecture achieves signiﬁcantly better results than existing baselines. For instance, our ﬁnal result on the ScanNet 3D segmentation benchmark [1] increases from 52.8\% to 75\% accuracy compared to existing volumetric architectures.},
	language = {en},
	urldate = {2019-05-29},
	journal = {arXiv:1803.10409 [cs]},
	author = {Dai, Angela and Nießner, Matthias},
	month = mar,
	year = {2018},
	note = {arXiv: 1803.10409},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {Dai et Nießner - 2018 - 3DMV Joint 3D-Multi-View Prediction for 3D Semant.pdf:/home/alienor/Zotero/storage/Z4V3SW38/Dai et Nießner - 2018 - 3DMV Joint 3D-Multi-View Prediction for 3D Semant.pdf:application/pdf}
}

@article{kar_learning_2017,
	title = {Learning a {Multi}-{View} {Stereo} {Machine}},
	url = {http://arxiv.org/abs/1708.05375},
	abstract = {We present a learnt system for multi-view stereopsis. In contrast to recent learning based methods for 3D reconstruction, we leverage the underlying 3D geometry of the problem through feature projection and unprojection along viewing rays. By formulating these operations in a differentiable manner, we are able to learn the system end-to-end for the task of metric 3D reconstruction. End-to-end learning allows us to jointly reason about shape priors while conforming geometric constraints, enabling reconstruction from much fewer images (even a single image) than required by classical approaches as well as completion of unseen surfaces. We thoroughly evaluate our approach on the ShapeNet dataset and demonstrate the beneﬁts over classical approaches as well as recent learning based methods.},
	language = {en},
	urldate = {2019-05-29},
	journal = {arXiv:1708.05375 [cs]},
	author = {Kar, Abhishek and Häne, Christian and Malik, Jitendra},
	month = aug,
	year = {2017},
	note = {arXiv: 1708.05375},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {Kar et al. - 2017 - Learning a Multi-View Stereo Machine.pdf:/home/alienor/Zotero/storage/MWP43S7V/Kar et al. - 2017 - Learning a Multi-View Stereo Machine.pdf:application/pdf}
}

@article{mueller_evaluation_nodate,
	title = {{EVALUATION} {OF} 3D {RECONSTRCUTION} {USING} {MULTIVIEW} {BACKPROJECTION}},
	abstract = {This paper evaluates the final reconstruction quality of 3D objects from different reconstruction methods by comparing rendered views of a 3D model to the original views, initially taken from 2D cameras. The paper uses pixel-by-pixel error measures, like pixelwise reconstruction error for non-textured objects and PSNR values for colored or textured objects. Concurrently, the limitations of such measures in connection with 3D reconstruction evaluation are highlighted and a reconstruction measurement based on differential values is investigated, where deviations from reference values are analyzed instead of absolute PSNR-values.},
	language = {en},
	author = {Mueller, K and Zabulis, X and Smolic, A and Wiegand, T},
	pages = {4},
	file = {Mueller et al. - EVALUATION OF 3D RECONSTRCUTION USING MULTIVIEW BA.pdf:/home/alienor/Zotero/storage/F9Q6QCXF/Mueller et al. - EVALUATION OF 3D RECONSTRCUTION USING MULTIVIEW BA.pdf:application/pdf}
}

@article{eid_performance_2005,
	title = {On the {Performance} {Evaluation} of 3D {Reconstruction} {Techniques} from a {Sequence} of {Images}},
	volume = {2005},
	issn = {1687-6180},
	url = {https://asp-eurasipjournals.springeropen.com/articles/10.1155/ASP.2005.1948},
	doi = {10.1155/ASP.2005.1948},
	abstract = {The performance evaluation of 3D reconstruction techniques is not a simple problem to solve. This is not only due to the increased dimensionality of the problem but also due to the lack of standardized and widely accepted testing methodologies. This paper presents a uniﬁed framework for the performance evaluation of diﬀerent 3D reconstruction techniques. This framework includes a general problem formalization, diﬀerent measuring criteria, and a classiﬁcation method as a ﬁrst step in standardizing the evaluation process. Performance characterization of two standard 3D reconstruction techniques, stereo and space carving, is also presented. The evaluation is performed on the same data set using an image reprojection testing methodology to reduce the dimensionality of the evaluation domain. Also, diﬀerent measuring strategies are presented and applied to the stereo and space carving techniques. These measuring strategies have shown consistent results in quantifying the performance of these techniques. Additional experiments are performed on the space carving technique to study the eﬀect of the number of input images and the camera pose on its performance.},
	language = {en},
	number = {13},
	urldate = {2019-05-29},
	journal = {EURASIP Journal on Advances in Signal Processing},
	author = {Eid, Ahmed and Farag, Aly},
	month = dec,
	year = {2005},
	pages = {986306},
	file = {Eid et Farag - 2005 - On the Performance Evaluation of 3D Reconstruction.pdf:/home/alienor/Zotero/storage/AU8YRH5N/Eid et Farag - 2005 - On the Performance Evaluation of 3D Reconstruction.pdf:application/pdf}
}

@article{garbez_predicting_2016,
	title = {Predicting sensorial attribute scores of ornamental plants assessed in 3D through rotation on video by image analysis: {A} study on the morphology of virtual rose bushes},
	volume = {121},
	issn = {01681699},
	shorttitle = {Predicting sensorial attribute scores of ornamental plants assessed in 3D through rotation on video by image analysis},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0168169916000065},
	doi = {10.1016/j.compag.2016.01.001},
	language = {en},
	urldate = {2019-06-13},
	journal = {Computers and Electronics in Agriculture},
	author = {Garbez, M. and Chéné, Y. and Belin, É. and Sigogne, M. and Labatte, J.-M. and Hunault, G. and Symoneaux, R. and Rousseau, D. and Galopin, G.},
	month = feb,
	year = {2016},
	pages = {331--346}
}

@article{weiberg_fungal_2013,
	title = {Fungal {Small} {RNAs} {Suppress} {Plant} {Immunity} by {Hijacking} {Host} {RNA} {Interference} {Pathways}},
	volume = {342},
	issn = {0036-8075},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4096153/},
	doi = {10.1126/science.1239705},
	abstract = {Botrytis cinerea, the causative agent of gray mold disease, is an aggressive fungal pathogen that infects more than 200 plant species. Here, we show that some B. cinerea small RNAs (Bc-sRNAs) can silence Arabidopsis and tomato genes involved in immunity. These Bc-sRNAs hijack the host RNA interference (RNAi) machinery by binding to Arabidopsis Argonaute 1 (AGO1) and selectively silencing host immunity genes. The Arabidopsis ago1 mutant exhibits reduced susceptibility to B. cinerea, and the B. cinerea dcl1 dcl2 double mutant that can no longer produce these Bc-sRNAs displays reduced pathogenicity on Arabidopsis and tomato. Thus, this fungal pathogen transfers “virulent” sRNA effectors into host plant cells to suppress host immunity and achieve infection, which demonstrates a naturally occurring cross-kingdom RNAi as an advanced virulence mechanism.},
	number = {6154},
	urldate = {2019-06-20},
	journal = {Science (New York, N.Y.)},
	author = {Weiberg, Arne and Wang, Ming and Lin, Feng-Mao and Zhao, Hongwei and Zhang, Zhihong and Kaloshian, Isgouhi and Huang, Hsien-Da and Jin, Hailing},
	month = oct,
	year = {2013},
	pmid = {24092744},
	pmcid = {PMC4096153},
	pages = {118--123},
	file = {PubMed Central Full Text PDF:/home/alienor/Zotero/storage/MXD43Y8B/Weiberg et al. - 2013 - Fungal Small RNAs Suppress Plant Immunity by Hijac.pdf:application/pdf}
}

@article{ruiz-ferrer_roles_2009,
	title = {Roles of {Plant} {Small} {RNAs} in {Biotic} {Stress} {Responses}},
	volume = {60},
	issn = {1543-5008, 1545-2123},
	url = {http://www.annualreviews.org/doi/10.1146/annurev.arplant.043008.092111},
	doi = {10.1146/annurev.arplant.043008.092111},
	abstract = {A multitude of small RNAs (sRNAs, 18–25 nt in length) accumulate in plant tissues. Although heterogeneous in size, sequence, genomic distribution, biogenesis, and action, most of these molecules mediate repressive gene regulation through RNA silencing. Besides their roles in developmental patterning and maintenance of genome integrity, sRNAs are also integral components of plant responses to adverse environmental conditions, including biotic stress. Until recently, antiviral RNA silencing was considered a paradigm of the interactions linking RNA silencing to pathogens: Virus-derived sRNAs silence viral gene expression and, accordingly, viruses produce suppressor proteins that target the silencing mechanism. However, increasing evidence shows that endogenous, rather than pathogen-derived, sRNAs also have broad functions in regulating plant responses to various microbes. In turn, microbes have evolved ways to inhibit, avoid, or usurp cellular silencing pathways, thereby prompting the deployment of countercounterdefensive measures by plants, a compelling illustration of the neverending molecular arms race between hosts and parasites.},
	language = {en},
	number = {1},
	urldate = {2019-06-20},
	journal = {Annual Review of Plant Biology},
	author = {Ruiz-Ferrer, Virginia and Voinnet, Olivier},
	month = jun,
	year = {2009},
	pages = {485--510},
	file = {Ruiz-Ferrer et Voinnet - 2009 - Roles of Plant Small RNAs in Biotic Stress Respons.pdf:/home/alienor/Zotero/storage/MFEYBAXE/Ruiz-Ferrer et Voinnet - 2009 - Roles of Plant Small RNAs in Biotic Stress Respons.pdf:application/pdf}
}

@article{zhang_cotton_2016,
	title = {Cotton plants export {microRNAs} to inhibit virulence gene expression in a fungal pathogen},
	volume = {2},
	issn = {2055-0278},
	url = {http://www.nature.com/articles/nplants2016153},
	doi = {10.1038/nplants.2016.153},
	language = {en},
	number = {10},
	urldate = {2019-06-20},
	journal = {Nature Plants},
	author = {Zhang, Tao and Zhao, Yun-Long and Zhao, Jian-Hua and Wang, Sheng and Jin, Yun and Chen, Zhong-Qi and Fang, Yuan-Yuan and Hua, Chen-Lei and Ding, Shou-Wei and Guo, Hui-Shan},
	month = oct,
	year = {2016},
	pages = {16153},
	file = {Zhang et al. - 2016 - Cotton plants export microRNAs to inhibit virulenc.pdf:/home/alienor/Zotero/storage/9CJ73I3I/Zhang et al. - 2016 - Cotton plants export microRNAs to inhibit virulenc.pdf:application/pdf}
}

@article{li_identification_2010,
	title = {Identification of {MicroRNAs} {Involved} in {Pathogen}-{Associated} {Molecular} {Pattern}-{Triggered} {Plant} {Innate} {Immunity}},
	volume = {152},
	issn = {0032-0889, 1532-2548},
	url = {http://www.plantphysiol.org/cgi/doi/10.1104/pp.109.151803},
	doi = {10.1104/pp.109.151803},
	language = {en},
	number = {4},
	urldate = {2019-06-20},
	journal = {PLANT PHYSIOLOGY},
	author = {Li, Y. and Zhang, Q. and Zhang, J. and Wu, L. and Qi, Y. and Zhou, J. M.},
	month = apr,
	year = {2010},
	pages = {2222--2231},
	file = {Li et al. - 2010 - Identification of MicroRNAs Involved in Pathogen-A.pdf:/home/alienor/Zotero/storage/3HTEM9S9/Li et al. - 2010 - Identification of MicroRNAs Involved in Pathogen-A.pdf:application/pdf}
}

@article{crickmore_hox_2006,
	title = {Hox {Control} of {Organ} {Size} by {Regulation} of {Morphogen} {Production} and {Mobility}},
	volume = {313},
	issn = {0036-8075, 1095-9203},
	url = {http://www.sciencemag.org/lookup/doi/10.1126/science.1128650},
	doi = {10.1126/science.1128650},
	language = {en},
	number = {5783},
	urldate = {2019-06-20},
	journal = {Science},
	author = {Crickmore, Michael A. and Mann, Richard S.},
	month = jul,
	year = {2006},
	pages = {63--68},
	file = {Crickmore et Mann - 2006 - Hox Control of Organ Size by Regulation of Morphog.pdf:/home/alienor/Zotero/storage/NEZK2C2K/Crickmore et Mann - 2006 - Hox Control of Organ Size by Regulation of Morphog.pdf:application/pdf}
}

@misc{phillips_what_nodate,
	title = {What {Are} the {Differences} {Between} {siRNA} and {miRNA}?},
	url = {https://www.thebalance.com/the-differences-between-sirna-and-mirna-375536},
	abstract = {Is there a difference between small interfering RNA (siRNA) and micro RNA (miRNA)? Learn where they overlap and where they don't.},
	language = {en},
	urldate = {2019-06-20},
	journal = {The Balance},
	author = {Phillips, Theresa},
	file = {Snapshot:/home/alienor/Zotero/storage/DYDWLCFV/the-differences-between-sirna-and-mirna-375536.html:text/html}
}

@article{kehr_long_2018,
	title = {Long distance {RNA} movement},
	volume = {218},
	issn = {0028646X},
	url = {http://doi.wiley.com/10.1111/nph.15025},
	doi = {10.1111/nph.15025},
	language = {en},
	number = {1},
	urldate = {2019-06-20},
	journal = {New Phytologist},
	author = {Kehr, Julia and Kragler, Friedrich},
	month = apr,
	year = {2018},
	pages = {29--40},
	file = {Kehr et Kragler - 2018 - Long distance RNA movement.pdf:/home/alienor/Zotero/storage/KAZCHJXT/Kehr et Kragler - 2018 - Long distance RNA movement.pdf:application/pdf}
}

@misc{noauthor_rna_duplex_nodate,
	title = {{RNA}\_duplex},
	url = {https://collab.its.virginia.edu/access/content/group/f85bed6c-45d2-4b18-b868-6a2353586804/2/Ch29_Shaykh_R_RNA_Duplex_with_Tandem_Dimethylguanosine_Adenosine_Pairs-_-/Ch29_Shaykh_R_RNA_Duplex_with_Tandem_Dimethylguanosine_Adenosine_Pairs_RNA_duplex.html},
	urldate = {2019-06-20},
	file = {RNA_duplex:/home/alienor/Zotero/storage/ZHUQ5PC7/Ch29_Shaykh_R_RNA_Duplex_with_Tandem_Dimethylguanosine_Adenosine_Pairs_RNA_duplex.html:text/html}
}

@article{melnyk_intercellular_2011,
	title = {Intercellular and systemic movement of {RNA} silencing signals: {Intercellular} and systemic movement of {RNA} silencing signals},
	volume = {30},
	issn = {02614189},
	shorttitle = {Intercellular and systemic movement of {RNA} silencing signals},
	url = {http://emboj.embopress.org/cgi/doi/10.1038/emboj.2011.274},
	doi = {10.1038/emboj.2011.274},
	language = {en},
	number = {17},
	urldate = {2019-06-20},
	journal = {The EMBO Journal},
	author = {Melnyk, Charles W and Molnar, Attila and Baulcombe, David C},
	month = aug,
	year = {2011},
	pages = {3553--3563},
	file = {Melnyk et al. - 2011 - Intercellular and systemic movement of RNA silenci.pdf:/home/alienor/Zotero/storage/ABHRFM2Q/Melnyk et al. - 2011 - Intercellular and systemic movement of RNA silenci.pdf:application/pdf}
}

@misc{noauthor_signalisation_nodate,
	title = {Signalisation calcique cytosolique et nucléaire chez les végétaux {\textbar} {LRSV}},
	url = {https://www.lrsv.ups-tlse.fr/equipes-de-recherche/signalisation-calcique-cytosolique-et-nucleaire-chez-les-vegetaux/},
	language = {fr-FR},
	urldate = {2019-06-20},
	file = {Snapshot:/home/alienor/Zotero/storage/Y64E8B8J/signalisation-calcique-cytosolique-et-nucleaire-chez-les-vegetaux.html:text/html}
}

@article{ranty_calcium_2016,
	title = {Calcium {Sensors} as {Key} {Hubs} in {Plant} {Responses} to {Biotic} and {Abiotic} {Stresses}},
	volume = {7},
	issn = {1664-462X},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4792864/},
	doi = {10.3389/fpls.2016.00327},
	abstract = {The Ca2+ ion is recognized as a crucial second messenger in signaling pathways coupling the perception of environmental stimuli to plant adaptive responses. Indeed, one of the earliest events following the perception of environmental changes (temperature, salt stress, drought, pathogen, or herbivore attack) is intracellular variation of free calcium concentrations. These calcium variations differ in their spatio-temporal characteristics (subcellular location, amplitude, kinetics) with the nature and strength of the stimulus and, for this reason, they are considered as signatures encrypting information from the initial stimulus. This information is believed to drive a specific response by decoding via calcium-binding proteins. Based on recent examples, we illustrate how individual calcium sensors from the calcium-dependent protein kinase and calmodulin-like protein families can integrate inputs from various environmental changes. Focusing on members of these two families, shown to be involved in plant responses to both abiotic and biotic stimuli, we discuss their role as key hubs and we put forward hypotheses explaining how they can drive the signaling pathways toward the appropriate plant responses.},
	urldate = {2019-06-20},
	journal = {Frontiers in Plant Science},
	author = {Ranty, Benoît and Aldon, Didier and Cotelle, Valérie and Galaud, Jean-Philippe and Thuleau, Patrice and Mazars, Christian},
	month = mar,
	year = {2016},
	pmid = {27014336},
	pmcid = {PMC4792864},
	file = {PubMed Central Full Text PDF:/home/alienor/Zotero/storage/PWN7JD2U/Ranty et al. - 2016 - Calcium Sensors as Key Hubs in Plant Responses to .pdf:application/pdf}
}

@article{choi_salt_2014,
	title = {Salt stress-induced {Ca}2+ waves are associated with rapid, long-distance root-to-shoot signaling in plants},
	volume = {111},
	issn = {0027-8424},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4035928/},
	doi = {10.1073/pnas.1319955111},
	abstract = {This work documents a previously unreported plant-wide signaling system based on the rapid, long-distance transmission of Ca2+ waves. In the root these waves move through the cortical and endodermal cell layers at speeds of up to 400 µm/s, i.e., traversing several cells per second. This Ca2+ wave system correlates with the triggering of molecular responses in distant parts of the plant upon perception of localized (salt) stress. Such propagating Ca2+ waves provide a new mechanism for the rapid integration of activities throughout the plant body., Their sessile lifestyle means that plants have to be exquisitely sensitive to their environment, integrating many signals to appropriate developmental and physiological responses. Stimuli ranging from wounding and pathogen attack to the distribution of water and nutrients in the soil are frequently presented in a localized manner but responses are often elicited throughout the plant. Such systemic signaling is thought to operate through the redistribution of a host of chemical regulators including peptides, RNAs, ions, metabolites, and hormones. However, there are hints of a much more rapid communication network that has been proposed to involve signals ranging from action and system potentials to reactive oxygen species. We now show that plants also possess a rapid stress signaling system based on Ca2+ waves that propagate through the plant at rates of up to ∼400 µm/s. In the case of local salt stress to the Arabidopsis thaliana root, Ca2+ wave propagation is channeled through the cortex and endodermal cell layers and this movement is dependent on the vacuolar ion channel TPC1. We also provide evidence that the Ca2+ wave/TPC1 system likely elicits systemic molecular responses in target organs and may contribute to whole-plant stress tolerance. These results suggest that, although plants do not have a nervous system, they do possess a sensory network that uses ion fluxes moving through defined cell types to rapidly transmit information between distant sites within the organism.},
	number = {17},
	urldate = {2019-06-20},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Choi, Won-Gyu and Toyota, Masatsugu and Kim, Su-Hwa and Hilleary, Richard and Gilroy, Simon},
	month = apr,
	year = {2014},
	pmid = {24706854},
	pmcid = {PMC4035928},
	pages = {6497--6502},
	file = {PubMed Central Full Text PDF:/home/alienor/Zotero/storage/MQ5J7THX/Choi et al. - 2014 - Salt stress-induced Ca2+ waves are associated with.pdf:application/pdf}
}

@article{bigeard_signaling_2015,
	series = {Cell {Signaling}},
	title = {Signaling {Mechanisms} in {Pattern}-{Triggered} {Immunity} ({PTI})},
	volume = {8},
	issn = {1674-2052},
	url = {http://www.sciencedirect.com/science/article/pii/S1674205215000878},
	doi = {10.1016/j.molp.2014.12.022},
	abstract = {In nature, plants constantly have to face pathogen attacks. However, plant disease rarely occurs due to efficient immune systems possessed by the host plants. Pathogens are perceived by two different recognition systems that initiate the so-called pattern-triggered immunity (PTI) and effector-triggered immunity (ETI), both of which are accompanied by a set of induced defenses that usually repel pathogen attacks. Here we discuss the complex network of signaling pathways occurring during PTI, focusing on the involvement of mitogen-activated protein kinases.},
	number = {4},
	urldate = {2019-06-20},
	journal = {Molecular Plant},
	author = {Bigeard, Jean and Colcombet, Jean and Hirt, Heribert},
	month = apr,
	year = {2015},
	keywords = {MAPKs, plant defenses, plant immunity, PTI, signaling mechanisms},
	pages = {521--539},
	file = {ScienceDirect Full Text PDF:/home/alienor/Zotero/storage/RWKXIBRJ/Bigeard et al. - 2015 - Signaling Mechanisms in Pattern-Triggered Immunity.pdf:application/pdf;ScienceDirect Snapshot:/home/alienor/Zotero/storage/I97WTTEU/S1674205215000878.html:text/html}
}

@article{silva_review:_2018,
	title = {Review: {Potential} biotechnological assets related to plant immunity modulation applicable in engineering disease-resistant crops},
	volume = {270},
	issn = {0168-9452},
	shorttitle = {Review},
	url = {http://www.sciencedirect.com/science/article/pii/S0168945217309421},
	doi = {10.1016/j.plantsci.2018.02.013},
	abstract = {This review emphasizes the biotechnological potential of molecules implicated in the different layers of plant immunity, including, pathogen-associated molecular pattern (PAMP)-triggered immunity (PTI), effector-triggered susceptibility (ETS), and effector-triggered immunity (ETI) that can be applied in the development of disease-resistant genetically modified (GM) plants. These biomolecules are produced by pathogens (viruses, bacteria, fungi, oomycetes) or plants during their mutual interactions. Biomolecules involved in the first layers of plant immunity, PTI and ETS, include inhibitors of pathogen cell-wall-degrading enzymes (CWDEs), plant pattern recognition receptors (PRRs) and susceptibility (S) proteins, while the ETI-related biomolecules include plant resistance (R) proteins. The biomolecules involved in plant defense PTI/ETI responses described herein also include antimicrobial peptides (AMPs), pathogenesis-related (PR) proteins and ribosome-inhibiting proteins (RIPs), as well as enzymes involved in plant defensive secondary metabolite biosynthesis (phytoanticipins and phytoalexins). Moreover, the regulation of immunity by RNA interference (RNAi) in GM disease-resistant plants is also considered. Therefore, the present review does not cover all the classes of biomolecules involved in plant innate immunity that may be applied in the development of disease-resistant GM crops but instead highlights the most common strategies in the literature, as well as their advantages and disadvantages.},
	urldate = {2019-06-20},
	journal = {Plant Science},
	author = {Silva, Marilia Santos and Arraes, Fabrício Barbosa Monteiro and Campos, Magnólia de Araújo and Grossi-de-Sa, Maira and Fernandez, Diana and Cândido, Elizabete de Souza and Cardoso, Marlon Henrique and Franco, Octávio Luiz and Grossi-de-Sa, Maria Fátima},
	month = may,
	year = {2018},
	keywords = {Disease resistance, Effector-triggered immunity (ETI), Effector-triggered susceptibility (ETS), Genetically modified (GM) crop, Pathogen-associated molecular pattern-triggered immunity (PTI), RNA interference},
	pages = {72--84},
	file = {ScienceDirect Full Text PDF:/home/alienor/Zotero/storage/8AS5G8R8/Silva et al. - 2018 - Review Potential biotechnological assets related .pdf:application/pdf;ScienceDirect Snapshot:/home/alienor/Zotero/storage/NCTP4SRB/S0168945217309421.html:text/html}
}

@article{djami-tchatchou_functional_2017-1,
	title = {Functional {Roles} of {microRNAs} in {Agronomically} {Important} {Plants}—{Potential} as {Targets} for {Crop} {Improvement} and {Protection}},
	volume = {8},
	issn = {1664-462X},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5360763/},
	doi = {10.3389/fpls.2017.00378},
	abstract = {MicroRNAs (miRNAs) are a class of small non-coding RNAs that have recently emerged as important regulators of gene expression, mainly through cleavage and/or translation inhibition of the target mRNAs during or after transcription. miRNAs play important roles by regulating a multitude of biological processes in plants which include maintenance of genome integrity, development, metabolism, and adaptive responses toward environmental stresses. The increasing population of the world and their food demands requires focused efforts for the improvement of crop plants to ensure sustainable food production. Manipulation of mRNA transcript abundance via miRNA control provides a unique strategy for modulating differential plant gene expression and miRNAs are thus emerging as the next generation targets for genetic engineering for improvement of the agronomic properties of crops. However, a deeper understanding of its potential and the mechanisms involved will facilitate the design of suitable strategies to obtain the desirable traits with minimum trade-offs in the modified crops. In this regard, this review highlights the diverse roles of conserved and newly identified miRNAs in various food and industrial crops and recent advances made in the uses of miRNAs to improve plants of agronomically importance so as to significantly enhance crop yields and increase tolerance to various environmental stress agents of biotic—or abiotic origin.},
	urldate = {2019-06-20},
	journal = {Frontiers in Plant Science},
	author = {Djami-Tchatchou, Arnaud T. and Sanan-Mishra, Neeti and Ntushelo, Khayalethu and Dubery, Ian A.},
	month = mar,
	year = {2017},
	pmid = {28382044},
	pmcid = {PMC5360763},
	file = {PubMed Central Full Text PDF:/home/alienor/Zotero/storage/FUJV4NLG/Djami-Tchatchou et al. - 2017 - Functional Roles of microRNAs in Agronomically Imp.pdf:application/pdf}
}

@article{venkat_rajam_micro_2012-1,
	title = {Micro {RNA} {Interference}: {A} {New} {Platform} for {Crop} {Protection}},
	volume = {01},
	issn = {21689296},
	shorttitle = {Micro {RNA} {Interference}},
	url = {https://www.omicsonline.org/open-access/micro-rna-interference-a-new-platform-for-crop-protection-2168-9296.1000e115.php?aid=8884},
	doi = {10.4172/2168-9296.1000e115},
	language = {en},
	number = {06},
	urldate = {2019-06-20},
	journal = {Cell \& Developmental Biology},
	author = {Venkat Rajam, Manchikatla},
	year = {2012},
	file = {Venkat Rajam - 2012 - Micro RNA Interference A New Platform for Crop Pr.pdf:/home/alienor/Zotero/storage/NSIBICMB/Venkat Rajam - 2012 - Micro RNA Interference A New Platform for Crop Pr.pdf:application/pdf}
}

@article{khraiwesh_role_2012,
	title = {Role of {miRNAs} and {siRNAs} in biotic and abiotic stress responses of plants},
	volume = {1819},
	issn = {0006-3002},
	doi = {10.1016/j.bbagrm.2011.05.001},
	abstract = {Small, non-coding RNAs are a distinct class of regulatory RNAs in plants and animals that control a variety of biological processes. In plants, several classes of small RNAs with specific sizes and dedicated functions have evolved through a series of pathways. The major classes of small RNAs include microRNAs (miRNAs) and small interfering RNAs (siRNAs), which differ in their biogenesis. miRNAs control the expression of cognate target genes by binding to reverse complementary sequences, resulting in cleavage or translational inhibition of the target RNAs. siRNAs have a similar structure, function, and biogenesis as miRNAs but are derived from long double-stranded RNAs and can often direct DNA methylation at target sequences. Besides their roles in growth and development and maintenance of genome integrity, small RNAs are also important components in plant stress responses. One way in which plants respond to environmental stress is by modifying their gene expression through the activity of small RNAs. Thus, understanding how small RNAs regulate gene expression will enable researchers to explore the role of small RNAs in biotic and abiotic stress responses. This review focuses on the regulatory roles of plant small RNAs in the adaptive response to stresses. This article is part of a Special Issue entitled: Plant gene regulation in response to abiotic stress.},
	language = {eng},
	number = {2},
	journal = {Biochimica Et Biophysica Acta},
	author = {Khraiwesh, Basel and Zhu, Jian-Kang and Zhu, Jianhua},
	month = feb,
	year = {2012},
	pmid = {21605713},
	pmcid = {PMC3175014},
	keywords = {Gene Expression Regulation, Plant, MicroRNAs, Plant Physiological Phenomena, Plants, RNA, Plant, RNA, Small Interfering, Stress, Physiological},
	pages = {137--148},
	file = {Version acceptée:/home/alienor/Zotero/storage/ZQ9KJFI9/Khraiwesh et al. - 2012 - Role of miRNAs and siRNAs in biotic and abiotic st.pdf:application/pdf}
}

@misc{noauthor_multisensor_nodate,
	title = {Multi‐sensor plant imaging: {Towards} the development of a stress‐catalogue - {Chaerle} - 2009 - {Biotechnology} {Journal} - {Wiley} {Online} {Library}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/biot.200800242},
	urldate = {2019-06-20},
	file = {Multi‐sensor plant imaging\: Towards the development of a stress‐catalogue - Chaerle - 2009 - Biotechnology Journal - Wiley Online Library:/home/alienor/Zotero/storage/B2D6CK8D/biot.html:text/html}
}

@article{yu_how_2017,
	title = {The ‘how’ and ‘where’ of plant {microRNAs}},
	volume = {216},
	issn = {1469-8137},
	url = {https://nph.onlinelibrary.wiley.com/doi/abs/10.1111/nph.14834},
	doi = {10.1111/nph.14834},
	abstract = {Contents 1002 I. 1002 II. 1007 III. 1010 IV. 1013 1013 References 1013 Summary MicroRNAs (miRNAs) are small non-coding RNAs, of typically 20–24 nt, that regulate gene expression post-transcriptionally through sequence complementarity. Since the identification of the first miRNA, lin-4, in the nematode Caenorhabditis elegans in 1993, thousands of miRNAs have been discovered in animals and plants, and their regulatory roles in numerous biological processes have been uncovered. In plants, research efforts have established the major molecular framework of miRNA biogenesis and modes of action, and are beginning to elucidate the mechanisms of miRNA degradation. Studies have implicated restricted and surprising subcellular locations in which miRNA biogenesis or activity takes place. In this article, we summarize the current knowledge on how plant miRNAs are made and degraded, and how they repress target gene expression. We discuss not only the players involved in these processes, but also the subcellular sites in which these processes are known or implicated to take place. We hope to raise awareness that the cell biology of miRNAs holds the key to a full understanding of these enigmatic molecules.},
	language = {en},
	number = {4},
	urldate = {2019-06-20},
	journal = {New Phytologist},
	author = {Yu, Yu and Jia, Tianran and Chen, Xuemei},
	year = {2017},
	keywords = {ARGONAUTE1, DICER-LIKE1, dicing body, endoplasmic reticulum (ER), HYPONASTIC LEAVES 1, membrane-bound polysome, microRNA, phased small interfering RNA},
	pages = {1002--1017},
	file = {Full Text PDF:/home/alienor/Zotero/storage/WDYWYLMK/Yu et al. - 2017 - The ‘how’ and ‘where’ of plant microRNAs.pdf:application/pdf;Snapshot:/home/alienor/Zotero/storage/TZVW89Q6/nph.html:text/html}
}

@article{kumar_regulation_2013,
	title = {Regulation of biotic and abiotic stress responses by plant hormones},
	volume = {32},
	issn = {0721-7714, 1432-203X},
	url = {http://link.springer.com/10.1007/s00299-013-1460-z},
	doi = {10.1007/s00299-013-1460-z},
	language = {en},
	number = {7},
	urldate = {2019-06-20},
	journal = {Plant Cell Reports},
	author = {Kumar, Prakash P.},
	month = jul,
	year = {2013},
	pages = {943--943},
	file = {Texte intégral:/home/alienor/Zotero/storage/99DJRP2W/Kumar - 2013 - Regulation of biotic and abiotic stress responses .pdf:application/pdf}
}

@book{collinge_plant_2016,
	title = {Plant {Pathogen} {Resistance} {Biotechnology}},
	isbn = {978-1-118-86776-1},
	abstract = {Plant pathogens and diseases are among the most significant challenges to survival that plants face. Disease outbreaks caused by microbial or viral pathogens can decimate crop yields and have severe effects on global food supply. Understanding the molecular mechanisms underlying plant immune response and applying this understanding to develop biotechnological tools to enhance plant defense against pathogens has great potential for moderating the impact of plant disease outbreaks. Plant Pathogen Resistance Biotechnology’s main focus is an in depth survey of the biological strategies being used to create transgenic disease resistant plants for sustainable plant resistance Plant Pathogen Resistance Biotechnology is divided into four sections. The first section covers biological mechanisms underpinning disease resistance in plants, while the second highlights case studies of important pathogen-crop groups and then considers why the application of important pathogen-crop groups, transgenic-based strategies designed to selectively target pathogens could benefit crop production. The third section provides information on the status of transgenic crops around the world, and finally the last part explores high-tech alternatives to genetic engineering for developing disease resistant traits in plants. Edited and authored by leaders in the field, Plant Pathogen Resistance Biotechnology will be an invaluable resource to those studying or researching plant biotechnology, plant pathology, plant biology, plant and crop genetics, in addition to crop science.},
	language = {en},
	publisher = {John Wiley \& Sons},
	author = {Collinge, David B.},
	month = jun,
	year = {2016},
	note = {Google-Books-ID: \_FTWCwAAQBAJ},
	keywords = {Science / Biotechnology, Science / Life Sciences / Botany}
}

@article{fiorani_future_2013,
	title = {Future {Scenarios} for {Plant} {Phenotyping}},
	volume = {64},
	issn = {1543-5008, 1545-2123},
	url = {http://www.annualreviews.org/doi/10.1146/annurev-arplant-050312-120137},
	doi = {10.1146/annurev-arplant-050312-120137},
	abstract = {With increasing demand to support and accelerate progress in breeding for novel traits, the plant research community faces the need to accurately measure increasingly large numbers of plants and plant parameters. The goal is to provide quantitative analyses of plant structure and function relevant for traits that help plants better adapt to lowinput agriculture and resource-limited environments. We provide an overview of the inherently multidisciplinary research in plant phenotyping, focusing on traits that will assist in selecting genotypes with increased resource use efﬁciency. We highlight opportunities and challenges for integrating noninvasive or minimally invasive technologies into screening protocols to characterize plant responses to environmental challenges for both controlled and ﬁeld experimentation. Although technology evolves rapidly, parallel efforts are still required because large-scale phenotyping demands accurate reporting of at least a minimum set of information concerning experimental protocols, data management schemas, and integration with modeling. The journey toward systematic plant phenotyping has only just begun.},
	language = {en},
	number = {1},
	urldate = {2019-06-20},
	journal = {Annual Review of Plant Biology},
	author = {Fiorani, Fabio and Schurr, Ulrich},
	month = apr,
	year = {2013},
	pages = {267--291},
	file = {Fiorani et Schurr - 2013 - Future Scenarios for Plant Phenotyping.pdf:/home/alienor/Zotero/storage/7VH9CDMQ/Fiorani et Schurr - 2013 - Future Scenarios for Plant Phenotyping.pdf:application/pdf}
}

@article{biskup_stereo_2007,
	title = {A stereo imaging system for measuring structural parameters of plant canopies},
	volume = {30},
	issn = {1365-3040},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1365-3040.2007.01702.x},
	doi = {10.1111/j.1365-3040.2007.01702.x},
	abstract = {Plants constantly adapt their leaf orientation in response to fluctuations in the environment, to maintain radiation use efficiency in the face of varying intensity and incidence direction of sunlight. Various methods exist for measuring structural canopy parameters such as leaf angle distribution. However, direct methods tend to be labour-intensive, while indirect methods usually give statistical information on stand level rather than on individual leaves. We present an area-based, binocular stereo system composed of commercially available components that allows three-dimensional reconstruction of small- to medium-sized canopies on the level of single leaves under field conditions. Spatial orientation of single leaves is computed with automated processes using modern, well-established stereo matching and segmentation techniques, which were adapted for the properties of plant canopies, providing high spatial and temporal resolution (angle measurements with an accuracy of approx. ±5° and a maximum sampling rate of three frames per second). The applicability of our approach is demonstrated in three case studies: (1) the dihedral leaflet angle of an individual soybean was tracked to monitor nocturnal and daytime leaf movement showing different frequencies and amplitudes; (2) drought stress was diagnosed in soybean by quantifying changes in the zenith leaflet angle distribution; and (3) the diurnal course of the zenith leaf angle distribution of a closed soybean canopy was measured.},
	language = {en},
	number = {10},
	urldate = {2019-06-20},
	journal = {Plant, Cell \& Environment},
	author = {Biskup, Bernhard and Scharr, Hanno and Schurr, Ulrich and Rascher, Uwe},
	year = {2007},
	keywords = {3D reconstruction, canopy, leaf movement, screening, stereo imaging, systems biology},
	pages = {1299--1308},
	file = {Full Text PDF:/home/alienor/Zotero/storage/I2NEN8CR/Biskup et al. - 2007 - A stereo imaging system for measuring structural p.pdf:application/pdf;Snapshot:/home/alienor/Zotero/storage/Y9W6RTD7/j.1365-3040.2007.01702.html:text/html}
}

@misc{noauthor_irrigation_nodate,
	title = {Irrigation control of cowpea plants using the measurement of leaf thickness under greenhouse conditions {\textbar} {Seelig}, {Hans}-{Dieter}; {Stoner}, {Richard} {J}.; {Linden}, {James} {C}. {\textbar} download},
	url = {https://booksc.xyz/book/12793550/cb9ac0},
	urldate = {2019-06-20},
	file = {Irrigation control of cowpea plants using the measurement of leaf thickness under greenhouse conditions | Seelig, Hans-Dieter\; Stoner, Richard J.\; Linden, James C. | download:/home/alienor/Zotero/storage/CXU39K3F/cb9ac0.html:text/html}
}

@article{munns_new_2010,
	title = {New phenotyping methods for screening wheat and barley for beneficial responses to water deficit},
	volume = {61},
	issn = {0022-0957, 1460-2431},
	url = {https://academic.oup.com/jxb/article-lookup/doi/10.1093/jxb/erq199},
	doi = {10.1093/jxb/erq199},
	abstract = {This review considers stomatal conductance as an indicator of genotypic differences in the growth response to water stress. The beneﬁts of using stomatal conductance are compared with photosynthetic rate and other indicators of genetic variation in water stress tolerance, along with the use of modern phenomics technologies. Various treatments for screening for genetic diversity in response to water deﬁcit in controlled environments are considered. There is no perfect medium: there are pitfalls in using soil in pots, and in using hydroponics with ionic and non-ionic osmotica. Use of mixed salts or NaCl is recommended over non-ionic osmotica. Developments in infrared thermography provide new and feasible screening methods for detecting genetic variation in the stomatal response to water deﬁcit in controlled environments and in the ﬁeld.},
	language = {en},
	number = {13},
	urldate = {2019-06-20},
	journal = {Journal of Experimental Botany},
	author = {Munns, R. and James, R. A. and Sirault, X. R. R. and Furbank, R. T. and Jones, H. G.},
	month = aug,
	year = {2010},
	pages = {3499--3507},
	file = {Munns et al. - 2010 - New phenotyping methods for screening wheat and ba.pdf:/home/alienor/Zotero/storage/YX9I2FYT/Munns et al. - 2010 - New phenotyping methods for screening wheat and ba.pdf:application/pdf}
}

@article{furbank_plant_nodate,
	title = {Plant phenomics: from gene to form and function},
	abstract = {To exploit the wealth of gene sequence information provided by the ‘genomics revolution’ and mine agricultural germplasm for genetic diversity, high resolution, high throughput technologies in plant physiology are required for bridging the gap between genotype and phenotype. This special issue is dedicated to plant phenomics approaches to provide the quantitative phenotyping needed to elucidate the genetic bases for agricultural traits, and to screen germplasm for genetic variation in form, function and performance. These new techniques will enable the discovery of mechanisms and adaptations of plant responses to the environment.},
	language = {en},
	author = {Furbank, Robert T},
	pages = {2},
	file = {Furbank - Plant phenomics from gene to form and function.pdf:/home/alienor/Zotero/storage/VVHH4FLT/Furbank - Plant phenomics from gene to form and function.pdf:application/pdf}
}

@article{yoo_application_2015,
	title = {Application of {Chlorophyll} {Fluorescence} {Imaging} {Technology} for {Fresh} {Quality} {Control} of {Grape} {Fruit} {Preserved} {Under} {Different} {Storage} {Conditions}},
	volume = {6},
	abstract = {The objective of this study was to find a rapid determination of the freshness of grape (Vitis vinifera. L.) fruits using portable chlorophyll fluorescence imaging instrument. To assess the fresh quality of grape fruits, an imaging technique of the photochemical responses of pericarp of grape fruit was performed with fruits preserved under the different storage conditions. The observed chlorophyll imaging photos were numerically transformed to the photochemical parameters on the basis of chlorophyll fluorescence. The storage conditions for fruits were regulated as follows; room temperature (control), heat (42°C), wet (22°C±2 and 80\% relative humidity), and chilling (4°C) conditions.},
	language = {en},
	number = {6},
	journal = {International Journal of Engineering and Technology},
	author = {Yoo, Sung Yung and Samait, Sok and Park, Jong Yong and Kim, Tae Wan},
	year = {2015},
	pages = {8},
	file = {Yoo et al. - 2015 - Application of Chlorophyll Fluorescence Imaging Te.pdf:/home/alienor/Zotero/storage/YJM4DJVH/Yoo et al. - 2015 - Application of Chlorophyll Fluorescence Imaging Te.pdf:application/pdf}
}

@article{gorbe_applications_2012,
	title = {Applications of chlorophyll fluorescence imaging technique in horticultural research: {A} review},
	volume = {138},
	issn = {03044238},
	shorttitle = {Applications of chlorophyll fluorescence imaging technique in horticultural research},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0304423812000593},
	doi = {10.1016/j.scienta.2012.02.002},
	language = {en},
	urldate = {2019-06-20},
	journal = {Scientia Horticulturae},
	author = {Gorbe, Elisa and Calatayud, Angeles},
	month = may,
	year = {2012},
	pages = {24--35}
}

@article{udink_ten_cate_computer_1978,
	title = {{COMPUTER} {CONTROL} {OF} {GREENHOUSE} {CLIMATES}},
	issn = {0567-7572, 2406-6168},
	url = {https://www.actahort.org/books/87/87_28.htm},
	doi = {10.17660/ActaHortic.1978.87.28},
	number = {87},
	urldate = {2019-06-20},
	journal = {Acta Horticulturae},
	author = {Udink ten Cate, A.J. and Bot, G.P.A. and van Dixhoorn, J.J.},
	month = dec,
	year = {1978},
	pages = {265--272}
}

@article{nishina_development_2015,
	title = {Development of {Speaking} {Plant} {Approach} {Technique} for {Intelligent} {Greenhouse}},
	volume = {3},
	issn = {22107843},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2210784315000054},
	doi = {10.1016/j.aaspro.2015.01.004},
	abstract = {The Research Center for High-technology Greenhouse Plant Production of Ehime University provides a seamless technology development to establish INTELLIGENT GREENHOUSE SYSTEMS (IGS). The core concept as the basis of IGS is ‘Speaking plant approach (SPA)’, which was originally proposed by Udink ten Cate et al. and Hashimoto who is a professor emeritus at Ehime University. The SPA concept defines that optimal crop cultivation conditions should be based on the physiological status of the plants. The first step of the SPA is to obtain physiological information from a living plant. As a successful example, a chlorophyll fluorescence imaging robot, which can be used to grasp the heterogeneous distribution of photosynthetic activity of tomato plants in a greenhouse, is introduced. The primary feature of this robot is the feasible design, automated simple operation and low-cost, for implementation in commercial tomato production greenhouses. In addition, it is also focusing on the development of postharvest management techniques to improve the fruit quality. Here, a study to investigate the effects of storage temperature on the color of tomato fruit would be briefly introduced.},
	language = {en},
	urldate = {2019-06-20},
	journal = {Agriculture and Agricultural Science Procedia},
	author = {Nishina, Hiroshige},
	year = {2015},
	pages = {9--13},
	file = {Nishina - 2015 - Development of Speaking Plant Approach Technique f.pdf:/home/alienor/Zotero/storage/GD5TI4VE/Nishina - 2015 - Development of Speaking Plant Approach Technique f.pdf:application/pdf}
}

@article{hemming_speaking_nodate,
	title = {Speaking plant approach – {Future} dream or reality?},
	language = {en},
	author = {Hemming, Silke},
	pages = {6},
	file = {Hemming - Speaking plant approach – Future dream or reality.pdf:/home/alienor/Zotero/storage/ASXHKMJF/Hemming - Speaking plant approach – Future dream or reality.pdf:application/pdf}
}

@article{hemming_remote_2019,
	title = {Remote {Control} of {Greenhouse} {Vegetable} {Production} with {Artificial} {Intelligence}—{Greenhouse} {Climate}, {Irrigation}, and {Crop} {Production}},
	volume = {19},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/1424-8220/19/8/1807},
	doi = {10.3390/s19081807},
	abstract = {The global population is increasing rapidly, together with the demand for healthy fresh food. The greenhouse industry can play an important role, but encounters difficulties finding skilled staff to manage crop production. Artificial intelligence (AI) has reached breakthroughs in several areas, however, not yet in horticulture. An international competition on \&ldquo;autonomous greenhouses\&rdquo; aimed to combine horticultural expertise with AI to make breakthroughs in fresh food production with fewer resources. Five international teams, consisting of scientists, professionals, and students with different backgrounds in horticulture and AI, participated in a greenhouse growing experiment. Each team had a 96 m2 modern greenhouse compartment to grow a cucumber crop remotely during a 4-month-period. Each compartment was equipped with standard actuators (heating, ventilation, screening, lighting, fogging, CO2 supply, water and nutrient supply). Control setpoints were remotely determined by teams using their own AI algorithms. Actuators were operated by a process computer. Different sensors continuously collected measurements. Setpoints and measurements were exchanged via a digital interface. Achievements in AI-controlled compartments were compared with a manually operated reference. Detailed results on cucumber yield, resource use, and net profit obtained by teams are explained in this paper. We can conclude that in general AI performed well in controlling a greenhouse. One team outperformed the manually-grown reference.},
	language = {en},
	number = {8},
	urldate = {2019-06-20},
	journal = {Sensors},
	author = {Hemming, Silke and de Zwart, Feije and Elings, Anne and Righini, Isabella and Petropoulou, Anna},
	month = jan,
	year = {2019},
	keywords = {artificial intelligence, crop production, indoor farming, resource use efficiency, sensors},
	pages = {1807},
	file = {Full Text PDF:/home/alienor/Zotero/storage/JP9G7YS5/Hemming et al. - 2019 - Remote Control of Greenhouse Vegetable Production .pdf:application/pdf;Snapshot:/home/alienor/Zotero/storage/YVEH42LE/htm.html:text/html}
}

@article{fargier_etude_nodate,
	title = {L'etude de la pathologie de {Xanthomonas} campestris et de la structure génétique de ses pathovars a permis l'amélioration de la détection du pathogéne dans les semences de {Brassicacées}},
	language = {fr},
	author = {Fargier, Emilie},
	pages = {237},
	file = {Fargier - L'etude de la pathologie de Xanthomonas campestris.pdf:/home/alienor/Zotero/storage/Z3UMH8Y4/Fargier - L'etude de la pathologie de Xanthomonas campestris.pdf:application/pdf}
}

@article{mendell_micrornas_2012,
	title = {{MicroRNAs} in {Stress} {Signaling} and {Human} {Disease}},
	volume = {148},
	issn = {0092-8674, 1097-4172},
	url = {https://www.cell.com/cell/abstract/S0092-8674(12)00162-6},
	doi = {10.1016/j.cell.2012.02.005},
	language = {English},
	number = {6},
	urldate = {2019-06-24},
	journal = {Cell},
	author = {Mendell, Joshua T. and Olson, Eric N.},
	month = mar,
	year = {2012},
	pmid = {22424228},
	pages = {1172--1187},
	file = {Full Text PDF:/home/alienor/Zotero/storage/76EKLA9L/Mendell et Olson - 2012 - MicroRNAs in Stress Signaling and Human Disease.pdf:application/pdf;Snapshot:/home/alienor/Zotero/storage/JQRL398Z/S0092-8674(12)00162-6.html:text/html}
}

@article{li_identification_2010-1,
	title = {Identification of {microRNAs} involved in pathogen-associated molecular pattern-triggered plant innate immunity},
	volume = {152},
	issn = {1532-2548},
	doi = {10.1104/pp.109.151803},
	abstract = {Pathogen-associated molecular patterns (PAMPs) trigger plant defenses when perceived by surface-localized immune receptors. PAMP-triggered immunity (PTI) plays a vital role in the resistance of plants to numerous potential pathogens. MicroRNA (miRNA) biogenesis is known to be important for PTI, but miRNA species involved in this process have not been fully explored. Here we show that the Arabidopsis (Arabidopsis thaliana) miRNA effector protein, Argonaute1 (AGO1), is required for a number of PTI responses including PAMP-induced callose deposition, gene expression, and seedling growth inhibition. Deep sequencing of AGO1-bound small RNAs led to the identification of a number of miRNAs that are up- or down-regulated by flg22, a well-studied PAMP. Overexpression of selected miRNAs in stable transgenic plants demonstrated that miR160a positively regulate PAMP-induced callose deposition, whereas miR398b and miR773 negatively regulate PAMP-induced callose deposition and disease resistance to bacteria, suggesting a complexity of the miRNA regulation in plant innate immunity.},
	language = {eng},
	number = {4},
	journal = {Plant Physiology},
	author = {Li, Yan and Zhang, QingQing and Zhang, Jiangguang and Wu, Liang and Qi, Yijun and Zhou, Jian-Min},
	month = apr,
	year = {2010},
	pmid = {20164210},
	pmcid = {PMC2850012},
	keywords = {MicroRNAs, Plants, Arabidopsis, Immunity, Innate, Molecular Sequence Data},
	pages = {2222--2231},
	file = {Texte intégral:/home/alienor/Zotero/storage/DZSACJ2T/Li et al. - 2010 - Identification of microRNAs involved in pathogen-a.pdf:application/pdf}
}

@article{pant_microrna399_2008,
	title = {{MicroRNA}399 is a long-distance signal for the regulation of plant phosphate homeostasis},
	volume = {53},
	issn = {0960-7412, 1365-313X},
	url = {http://doi.wiley.com/10.1111/j.1365-313X.2007.03363.x},
	doi = {10.1111/j.1365-313X.2007.03363.x},
	abstract = {The presence of microRNA species in plant phloem sap suggests potential signaling roles by long-distance regulation of gene expression. Proof for such a role for a phloem-mobile microRNA is lacking. Here we show that phosphate (Pi) starvation-induced microRNA399 (miR399) is present in the phloem sap of two diverse plant species, rapeseed and pumpkin, and levels are strongly and specifically increased in phloem sap during Pi deprivation. By performing micro-grafting experiments using Arabidopsis, we further show that chimeric plants constitutively over-expressing miR399 in the shoot accumulate mature miR399 species to very high levels in their wild-type roots, while corresponding primary transcripts are virtually absent in roots, demonstrating shoot-to-root transport. The chimeric plants exhibit (i) down-regulation of the miR399 target transcript [PH02{\textbackslash}, which encodes a critical component for maintenance of Pi homeostasis, in the wild-type root, and (ii) Pi accumulation in the shoot, which is the phenotype of pho2 mutants, miR399 over-ex pressors or chimeric plants with a genetic knock-out of PH02 in the root. Hence the transported miR399 molecules retain biological activity. This is a demonstration of systemic control of a biological process, i.e. maintenance of plant Pi homeostasis, by a phloem-mobile microRNA.},
	language = {en},
	number = {5},
	urldate = {2019-06-25},
	journal = {The Plant Journal},
	author = {Pant, Bikram Datt and Buhtz, Anja and Kehr, Julia and Scheible, Wolf-Rüdiger},
	month = mar,
	year = {2008},
	pages = {731--738},
	file = {Pant et al. - 2008 - MicroRNA399 is a long-distance signal for the regu.pdf:/home/alienor/Zotero/storage/3JNY87PC/Pant et al. - 2008 - MicroRNA399 is a long-distance signal for the regu.pdf:application/pdf}
}

@article{ko_shootroot_2017,
	title = {Shoot–{Root} {Communication} in {Flowering} {Plants}},
	volume = {27},
	issn = {0960-9822},
	url = {http://www.sciencedirect.com/science/article/pii/S0960982217307911},
	doi = {10.1016/j.cub.2017.06.054},
	abstract = {Summary
As sessile organisms, terrestrial plants have evolved sophisticated mechanisms to coordinate the growth and development of two distinct systems, the shoot and the root, in response to environmental fluctuations. Adaptive systemic responses are accomplished by shoot–root communication, which involves diverse long-distance signalling molecules. During the last few decades, various genetic, biochemical, molecular, and grafting studies have identified multiple long-distance signalling molecules which are crucial for plants to adapt to external changes. In this minireview, the long-distance signals implicated in systemic responses to various environmental cues are discussed.},
	number = {17},
	urldate = {2019-06-25},
	journal = {Current Biology},
	author = {Ko, Donghwi and Helariutta, Ykä},
	month = sep,
	year = {2017},
	pages = {R973--R978},
	file = {ScienceDirect Full Text PDF:/home/alienor/Zotero/storage/GMVH2LXK/Ko et Helariutta - 2017 - Shoot–Root Communication in Flowering Plants.pdf:application/pdf;ScienceDirect Snapshot:/home/alienor/Zotero/storage/5JLPGI3S/S0960982217307911.html:text/html}
}

@article{chen_transport_2006,
	title = {Transport of macromolecules through plasmodesmata and the phloem},
	volume = {126},
	issn = {1399-3054},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1399-3054.2006.00630.x},
	doi = {10.1111/j.1399-3054.2006.00630.x},
	abstract = {Cell-to-cell communication is a pivotal process in the determination of cell fate during development and physiological adaptation in response to environmental stimuli. The intercellular trafficking of proteins and RNAs has emerged as a novel mechanism of cell-to-cell signaling in plants. As a strategy for efficient intercellular communication, plants have evolved plant-specific symplasmic communication networks via plasmodesmata (PD) and the phloem. PD are symplasmic channels connecting the cytoplasm of neighboring cells and are responsible for the local exchange of metabolites and signaling molecules. The phloem is the sieve-tube system that allows rapid, long-distance translocation of molecules. Together, PD and phloem conduits have been shown to allow the transport of proteins and RNAs in non-selective or/and selective modes. This review describes the current understanding of macromolecule trafficking through PD and the phloem.},
	language = {en},
	number = {4},
	urldate = {2019-06-25},
	journal = {Physiologia Plantarum},
	author = {Chen, Xiong-Yan and Kim, Jae-Yean},
	year = {2006},
	pages = {560--571},
	file = {Full Text PDF:/home/alienor/Zotero/storage/FDQAYCR6/Chen et Kim - 2006 - Transport of macromolecules through plasmodesmata .pdf:application/pdf;Snapshot:/home/alienor/Zotero/storage/TBXRVWT6/j.1399-3054.2006.00630.html:text/html}
}

@article{buhtz_identification_2008,
	title = {Identification and characterization of small {RNAs} from the phloem of {Brassica} napus},
	volume = {53},
	issn = {1365-313X},
	doi = {10.1111/j.1365-313X.2007.03368.x},
	abstract = {Systemic signalling is indispensable for the coordination of diverse physiological processes during development, defence and nutrient allocation. Indirect evidence suggests that plant small RNAs (smRNAs) could be involved in long-distance information transfer via the vasculature of the plant. Analyses of the smRNA complements of vascular exudates from oilseed rape (Brassica napus) showed that xylem sap is devoid of RNA, whereas phloem sap contained a large number of smRNAs. In addition to 32 annotated microRNAs (miRNAs) from 18 different families that could be identified and approved, a set of unknown smRNAs, predominantly of 21 and 24 nucleotides in length, was obtained, and selected candidates were found to be highly abundant in phloem sap. Moreover, we could demonstrate that the levels of three miRNAs known to respond to nutrient deprivation in non-vascular tissue, miR395 (sulphate), miR398 (copper) and miR399 (phosphate), were increased in phloem sap during the growth of plants under the respective starvation conditions. Interestingly, only mature miRNA molecules were found to be stress responsive, demonstrating that single-stranded sense miRNAs are most likely to represent the physiologically relevant molecules. The strong responses in the phloem suggest a role of miRNAs in systemic information transfer via this long-distance transport system.},
	language = {eng},
	number = {5},
	journal = {The Plant Journal: For Cell and Molecular Biology},
	author = {Buhtz, Anja and Springer, Franziska and Chappell, Louise and Baulcombe, David C. and Kehr, Julia},
	month = mar,
	year = {2008},
	pmid = {18005229},
	keywords = {Gene Expression Regulation, Plant, MicroRNAs, RNA, Plant, Brassica napus, Phloem, Xylem},
	pages = {739--749},
	file = {Texte intégral:/home/alienor/Zotero/storage/8A7W3HQ6/Buhtz et al. - 2008 - Identification and characterization of small RNAs .pdf:application/pdf}
}

@article{soto-suarez_arabidopsis_2017,
	title = {The {Arabidopsis} {miR}396 mediates pathogen-associated molecular pattern-triggered immune responses against fungal pathogens},
	volume = {7},
	copyright = {2017 Nature Publishing Group},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/srep44898},
	doi = {10.1038/srep44898},
	abstract = {MicroRNAs (miRNAs) play a pivotal role in regulating gene expression during plant development. Although a substantial fraction of plant miRNAs has proven responsive to pathogen infection, their role in disease resistance remains largely unknown, especially during fungal infections. In this study, we screened Arabidopsis thaliana lines in which miRNA activity has been reduced using artificial miRNA target mimics (MIM lines) for their response to fungal pathogens. Reduced activity of miR396 (MIM396 plants) was found to confer broad resistance to necrotrophic and hemibiotrophic fungal pathogens. MiR396 levels gradually decreased during fungal infection, thus, enabling its GRF (GROWTH-REGULATING FACTOR) transcription factor target genes to trigger host reprogramming. Pathogen resistance in MIM396 plants is based on a superactivation of defense responses consistent with a priming event during pathogen infection. Notably, low levels of miR396 are not translated in developmental defects in absence of pathogen challenge. Our findings support a role of miR396 in regulating plant immunity, and broaden our knowledge about the molecular players and processes that sustain defense priming. That miR396 modulates innate immunity without growth costs also suggests fine-tuning of miR396 levels as an effective biotechnological means for protection against pathogen infection.},
	language = {en},
	urldate = {2019-06-28},
	journal = {Scientific Reports},
	author = {Soto-Suárez, Mauricio and Baldrich, Patricia and Weigel, Detlef and Rubio-Somoza, Ignacio and San Segundo, Blanca},
	month = mar,
	year = {2017},
	pages = {44898},
	file = {Full Text PDF:/home/alienor/Zotero/storage/Y9GSTKKX/Soto-Suárez et al. - 2017 - The Arabidopsis miR396 mediates pathogen-associate.pdf:application/pdf;Snapshot:/home/alienor/Zotero/storage/2I27XNJI/srep44898.html:text/html}
}

@article{nedbal_photosynthesis_2005,
	title = {Photosynthesis in dynamic light: systems biology of unconventional chlorophyll fluorescence transients in {Synechocystis} sp. {PCC} 6803},
	volume = {84},
	issn = {0166-8595, 1573-5079},
	shorttitle = {Photosynthesis in dynamic light},
	url = {http://link.springer.com/10.1007/s11120-004-6428-y},
	doi = {10.1007/s11120-004-6428-y},
	abstract = {Photosynthetic organisms live in a dynamic environment where light typically ﬂuctuates around a mean level that is slowly drifting during the solar day. We show that the far-from-equilibrium photosynthesis occurring in a rapidly ﬂuctuating light diﬀers vastly from the stationary-ﬂux photosynthesis attained in a constant or slowly drifting light. Photosynthetic organisms in a static or slowly drifting light can be characterized by a steady-state quantum yield of chlorophyll ﬂuorescence emission F 0 that is changing linearly with small and slow variations of the incident irradiance I þ DIðtÞ : F 0ðI þ DIðtÞÞ \% Fm0 eanðdF Þ=ðdIÞ Á DIðtÞ. In Synechocystis sp. PCC 6803, the linear approximation holds for an extended interval covering largely the static irradiance range experienced by the cyanobacteria in nature. The photosynthetic dynamism and, consequently, the dynamism of the chlorophyll ﬂuorescence emission change dramatically when exposing the organism to a ﬂuctuating irradiance. Harmonically-modulated irradiance I þ DI Á sinð2pt=T Þ, T » 1–25 s induces perpetual, far-from-equilibrium forced oscillations that are strongly non-linear, exhibiting signiﬁcant hysteresis with multiple ﬂuorescence levels corresponding to a single instantaneous level of the incident irradiance. We propose that, in nature, the far-from-equilibrium dynamic phenomena represent a signiﬁcant correction to the steady-state photosynthetic activity that is typically investigated in laboratory. Analysis of the forced oscillations by the tools of systems biology suggests that the dynamism of photosynthesis observed in ﬂuctuating light can be explained by a delayed action of regulatory agents.},
	language = {en},
	number = {1-3},
	urldate = {2019-07-09},
	journal = {Photosynthesis Research},
	author = {Nedbal, Ladislav and Březina, Vítězslav and Červený, Jan and Trtílek, Martin},
	month = jun,
	year = {2005},
	pages = {99--106},
	file = {Nedbal et al. - 2005 - Photosynthesis in dynamic light systems biology o.pdf:/home/alienor/Zotero/storage/KSG4FTK6/Nedbal et al. - 2005 - Photosynthesis in dynamic light systems biology o.pdf:application/pdf}
}

@article{kupper_cadmium-induced_2007,
	title = {Cadmium-induced inhibition of photosynthesis and long-term acclimation to cadmium stress in the hyperaccumulator {Thlaspi} caerulescens},
	volume = {175},
	issn = {0028-646X, 1469-8137},
	url = {http://doi.wiley.com/10.1111/j.1469-8137.2007.02139.x},
	doi = {10.1111/j.1469-8137.2007.02139.x},
	abstract = {Acclimation of hyperaccumulators to heavy metal-induced stress is crucial for phytoremediation and was investigated using the hyperaccumulator Thlaspi caerulescens and the nonaccumulators T. fendleri and T. ochroleucum.},
	language = {en},
	number = {4},
	urldate = {2019-07-09},
	journal = {New Phytologist},
	author = {Küpper, Hendrik and Parameswaran, Aravind and Leitenmaier, Barbara and Trtílek, Martin and Šetlík, Ivan},
	month = sep,
	year = {2007},
	pages = {655--674},
	file = {Küpper et al. - 2007 - Cadmium-induced inhibition of photosynthesis and l.pdf:/home/alienor/Zotero/storage/QSADSNN8/Küpper et al. - 2007 - Cadmium-induced inhibition of photosynthesis and l.pdf:application/pdf}
}

@article{nedbal_complex_2002,
	title = {Complex {Metabolic} {Oscillations} in {Plants} {Forced} by {Harmonic} {Irradiance}},
	volume = {83},
	issn = {00063495},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0006349502739787},
	doi = {10.1016/S0006-3495(02)73978-7},
	abstract = {Plants exposed to harmonically modulated irradiance, Ϸ1 ϩ cos(␻t), exhibit a complex periodic pattern of chlorophyll fluorescence emission that can be deconvoluted into a steady-state component, a component that is modulated with the frequency of the irradiance (␻), and into at least two upper harmonic components (2␻ and 3␻). A model is proposed that accounts for the upper harmonics in fluorescence emission by nonlinear negative feedback regulation of photosynthesis. In contrast to simpler linear models, the model predicts that the steady-state fluorescence component will depend on the frequency of light modulation, and that amplitudes of all fluorescence components will exhibit resonance peak(s) when the irradiance frequency is tuned to an internal frequency of a regulatory component. The experiments confirmed that the upper harmonic components appear and exhibit distinct resonant peaks. The frequency of autonomous oscillations observed earlier upon an abrupt increase in CO2 concentration corresponds to the sharpest of the resonant peaks of the forced oscillations. We propose that the underlying principles are general for a wide spectrum of negative-feedback regulatory mechanisms. The analysis by forced harmonic oscillations will enable us to examine internal dynamics of regulatory processes that have not been accessible to noninvasive fluorescence monitoring to date.},
	language = {en},
	number = {4},
	urldate = {2019-07-09},
	journal = {Biophysical Journal},
	author = {Nedbal, Ladislav and Březina, Vítězslav},
	month = oct,
	year = {2002},
	pages = {2180--2189},
	file = {Nedbal et Březina - 2002 - Complex Metabolic Oscillations in Plants Forced by.pdf:/home/alienor/Zotero/storage/8CNTMR23/Nedbal et Březina - 2002 - Complex Metabolic Oscillations in Plants Forced by.pdf:application/pdf}
}

@article{nedbal_kinetic_nodate,
	title = {Kinetic imaging of chlorophyll ﬂuorescence using modulated light},
	abstract = {Fluorometers that measure the kinetics of chlorophyll ﬂuorescence have become invaluable tools for determining the photosynthetic performance of plants. Many of these instruments use high frequency modulated light to measure the rate, efﬁciency and regulation of photosynthesis. The technique is non-invasive and is effective under diverse environmental conditions. Recently, imaging ﬂuorometers have been introduced that reveal variability in photosynthesis over the surface of a leaf or between individual plants. Most imaging instruments depend on continuous light or low frequency modulated light for ﬂuorescence excitation, which imposes serious limitations on measurements of the ﬂuorescence parameters, especially the minimum ﬂuorescence (F0) and variable ﬂuorescence (FV). Here, we describe a new instrument that combines the advantage of high frequency modulated light with two-dimensional imaging of chlorophyll ﬂuorescence. The ﬂuorometer produces dynamic images of chlorophyll ﬂuorescence from leaves or plants, providing accurate mapping of F0 and FV, and non-photochemical quenching. A signiﬁcant feature of the instrument is that it can record ﬂuorescence images of leaves in daylight under ﬁeld conditions.},
	language = {en},
	author = {Nedbal, Ladislav and Soukupova, Julie and Kaftan, David and Whitmarsh, John and Trtılek, Martin},
	pages = {10},
	file = {Nedbal et al. - Kinetic imaging of chlorophyll ﬂuorescence using m.pdf:/home/alienor/Zotero/storage/CD5RB6NV/Nedbal et al. - Kinetic imaging of chlorophyll ﬂuorescence using m.pdf:application/pdf}
}

@article{nedbal_negative_2003,
	title = {Negative feedback regulation is responsible for the non-linear modulation of photosynthetic activity in plants and cyanobacteria exposed to a dynamic light environment},
	volume = {1607},
	issn = {00052728},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0005272803001130},
	doi = {10.1016/j.bbabio.2003.08.005},
	abstract = {Photosynthetic organisms exposed to a dynamic light environment exhibit complex transients of photosynthetic activities that are strongly dependent on the temporal pattern of the incident irradiance. In a harmonically modulated light of intensity I c const. + sin(xt), chlorophyll fluorescence response consists of a steady-state component, a component modulated with the angular frequency of the irradiance x and several upper harmonic components (2x, 3x and higher). Our earlier reverse engineering analysis suggests that the non-linear response can be caused by a negative feedback regulation of photosynthesis. Here, we present experimental evidence that the negative feedback regulation of the energetic coupling between phycobilisome and Photosystem II (PSII) in the cyanobacterium Synechocystis sp. PCC6803 indeed results in the appearance of upper harmonic modes in the chlorophyll fluorescence emission. Dynamic changes in the coupling of the phycobilisome to PSII are not accompanied by corresponding antiparallel changes in the Photosystem I (PSI) excitation, suggesting a regulation limited to PSII. Strong upper harmonic modes were also found in the kinetics of the non-photochemical quenching (NPQ) of chlorophyll fluorescence, of the P700 redox state and of the CO2 assimilation in tobacco (Nicotiana tabaccum) exposed to harmonically modulated light. They are ascribed to negative feedback regulation of the reactions of the Calvin – Benson cycle limiting the photosynthetic electron transport. We propose that the observed non-linear response of photosynthesis may also be relevant in a natural light environment that is modulated, e.g., by ocean waves, moving canopy or by varying cloud cover. Under controlled laboratory conditions, the non-linear photosynthetic response provides a new insight into dynamics of the regulatory processes.},
	language = {en},
	number = {1},
	urldate = {2019-07-09},
	journal = {Biochimica et Biophysica Acta (BBA) - Bioenergetics},
	author = {Nedbal, Ladislav and Březina, Vı́tězslav and Adamec, František and Štys, Dalibor and Oja, Vello and Laisk, Agu and {Govindjee}},
	month = oct,
	year = {2003},
	pages = {5--17},
	file = {Nedbal et al. - 2003 - Negative feedback regulation is responsible for th.pdf:/home/alienor/Zotero/storage/AG5NKEGM/Nedbal et al. - 2003 - Negative feedback regulation is responsible for th.pdf:application/pdf}
}

@article{lakowicz_principles_2008,
	title = {Principles of {Fluorescence} {Spectroscopy}, {Third} {Edition}},
	volume = {13},
	issn = {10833668},
	url = {http://biomedicaloptics.spiedigitallibrary.org/article.aspx?doi=10.1117/1.2904580},
	doi = {10.1117/1.2904580},
	language = {en},
	number = {2},
	urldate = {2019-07-09},
	journal = {Journal of Biomedical Optics},
	author = {Lakowicz, Joseph R. and Masters, Barry R.},
	year = {2008},
	pages = {029901},
	file = {Lakowicz et Masters - 2008 - Principles of Fluorescence Spectroscopy, Third Edi.pdf:/home/alienor/Zotero/storage/BGHIAPD9/Lakowicz et Masters - 2008 - Principles of Fluorescence Spectroscopy, Third Edi.pdf:application/pdf}
}

@inproceedings{ying_zheng_detailed_2011,
	address = {Barcelona, Spain},
	title = {Detailed reconstruction of 3D plant root shape},
	isbn = {978-1-4577-1102-2 978-1-4577-1101-5 978-1-4577-1100-8},
	url = {http://ieeexplore.ieee.org/document/6126475/},
	doi = {10.1109/ICCV.2011.6126475},
	abstract = {We study the 3D reconstruction of plant roots from multiple 2D images. To meet the challenge caused by the delicate nature of thin branches, we make three innovations to cope with the sensitivity to image quality and calibration. First, we model the background as a harmonic function to improve the segmentation of the root in each 2D image. Second, we develop the concept of the regularized visual hull which reduces the effect of jittering and refraction by ensuring consistency with one 2D image. Third, we guarantee connectedness through adjustments to the 3D reconstruction that minimize global error. Our software is part of a biological phenotype/genotype study of agricultural root systems. It has been tested on more than 40 plant roots and results are promising in terms of reconstruction quality and efﬁciency. Figure 1. Plant root imaging system.},
	language = {en},
	urldate = {2019-07-10},
	booktitle = {2011 {International} {Conference} on {Computer} {Vision}},
	publisher = {IEEE},
	author = {{Ying Zheng} and Gu, Steve and Edelsbrunner, Herbert and Tomasi, Carlo and Benfey, Philip},
	month = nov,
	year = {2011},
	pages = {2026--2033},
	file = {Ying Zheng et al. - 2011 - Detailed reconstruction of 3D plant root shape.pdf:/home/alienor/Zotero/storage/4I2FARQR/Ying Zheng et al. - 2011 - Detailed reconstruction of 3D plant root shape.pdf:application/pdf}
}

@article{garrido_3d_2015,
	title = {3D {Maize} {Plant} {Reconstruction} {Based} on {Georeferenced} {Overlapping} {LiDAR} {Point} {Clouds}},
	volume = {7},
	issn = {2072-4292},
	url = {http://www.mdpi.com/2072-4292/7/12/15870},
	doi = {10.3390/rs71215870},
	language = {en},
	number = {12},
	urldate = {2019-07-10},
	journal = {Remote Sensing},
	author = {Garrido, Miguel and Paraforos, Dimitris and Reiser, David and Vázquez Arellano, Manuel and Griepentrog, Hans and Valero, Constantino},
	month = dec,
	year = {2015},
	pages = {17077--17096},
	file = {Garrido et al. - 2015 - 3D Maize Plant Reconstruction Based on Georeferenc.pdf:/home/alienor/Zotero/storage/DGF37AKD/Garrido et al. - 2015 - 3D Maize Plant Reconstruction Based on Georeferenc.pdf:application/pdf}
}

@inproceedings{quan_image-based_2006,
	address = {Boston, Massachusetts},
	title = {Image-based plant modeling},
	isbn = {978-1-59593-364-5},
	url = {http://portal.acm.org/citation.cfm?doid=1179352.1141929},
	doi = {10.1145/1179352.1141929},
	abstract = {In this paper, we propose a semi-automatic technique for modeling plants directly from images. Our image-based approach has the distinct advantage that the resulting model inherits the realistic shape and complexity of a real plant. We designed our modeling system to be interactive, automating the process of shape recovery while relying on the user to provide simple hints on segmentation. Segmentation is performed in both image and 3D spaces, allowing the user to easily visualize its effect immediately. Using the segmented image and 3D data, the geometry of each leaf is then automatically recovered from the multiple views by ﬁtting a deformable leaf model. Our system also allows the user to easily reconstruct branches in a similar manner. We show realistic reconstructions of a variety of plants, and demonstrate examples of plant editing.},
	language = {en},
	urldate = {2019-07-10},
	booktitle = {{ACM} {SIGGRAPH} 2006 {Papers} on   - {SIGGRAPH} '06},
	publisher = {ACM Press},
	author = {Quan, Long and Tan, Ping and Zeng, Gang and Yuan, Lu and Wang, Jingdong and Kang, Sing Bing},
	year = {2006},
	pages = {599},
	file = {Quan et al. - 2006 - Image-based plant modeling.pdf:/home/alienor/Zotero/storage/Y6HEHW5J/Quan et al. - 2006 - Image-based plant modeling.pdf:application/pdf}
}

@article{paproki_novel_2012,
	title = {A novel mesh processing based technique for 3D plant analysis},
	volume = {12},
	issn = {1471-2229},
	url = {https://doi.org/10.1186/1471-2229-12-63},
	doi = {10.1186/1471-2229-12-63},
	abstract = {In recent years, imaging based, automated, non-invasive, and non-destructive high-throughput plant phenotyping platforms have become popular tools for plant biology, underpinning the field of plant phenomics. Such platforms acquire and record large amounts of raw data that must be accurately and robustly calibrated, reconstructed, and analysed, requiring the development of sophisticated image understanding and quantification algorithms. The raw data can be processed in different ways, and the past few years have seen the emergence of two main approaches: 2D image processing and 3D mesh processing algorithms. Direct image quantification methods (usually 2D) dominate the current literature due to comparative simplicity. However, 3D mesh analysis provides the tremendous potential to accurately estimate specific morphological features cross-sectionally and monitor them over-time.},
	number = {1},
	urldate = {2019-07-10},
	journal = {BMC Plant Biology},
	author = {Paproki, Anthony and Sirault, Xavier and Berry, Scott and Furbank, Robert and Fripp, Jurgen},
	month = may,
	year = {2012},
	pages = {63},
	file = {Full Text PDF:/home/alienor/Zotero/storage/594VPSAC/Paproki et al. - 2012 - A novel mesh processing based technique for 3D pla.pdf:application/pdf;Snapshot:/home/alienor/Zotero/storage/CXYSGXE4/1471-2229-12-63.html:text/html}
}

@article{fang_3d_2009,
	title = {3D reconstruction and dynamic modeling of root architecture in situ and its application to crop phosphorus research},
	abstract = {Root architecture plays important roles in plant water and nutrient acquisition. However, accurate modeling of the root system that provides a realistic representation of roots in the soil is limited by a lack of appropriate tools for the non-destructive and precise measurement of the root system architecture in situ. Here we describe a root growth system in which the roots grow in a solid gel matrix that was used to reconstruct 3D root architecture in situ and dynamically simulate its changes under various nutrient conditions with a high degree of precision. A 3D laser scanner combined with a transparent gel-based growth system was used to capture 3D images of roots. The root system skeleton was extracted using a skeleton extraction method based on the Hough transformation, and mesh modeling using Ball-B spline was employed. We successfully used this system to reconstruct rice and soybean root architectures and determine their changes under various phosphorus (P) supply conditions. Our results showed that the 3D root architecture parameters that were dynamically calculated based on the skeletonization and simulation of root systems were signiﬁcantly correlated with the biomass and P content of rice and soybean based on both the simulation system and previous reports. Therefore, this approach provides a novel technique for the study of crop root growth and its adaptive changes to various environmental conditions.},
	language = {en},
	journal = {The Plant Journal},
	author = {Fang, Suqin and Yan, Xiaolong and Liao, Hong},
	year = {2009},
	pages = {13},
	file = {Fang et al. - 2009 - 3D reconstruction and dynamic modeling of root arc.pdf:/home/alienor/Zotero/storage/Z6AUPW7C/Fang et al. - 2009 - 3D reconstruction and dynamic modeling of root arc.pdf:application/pdf}
}

@article{sonohat_three-dimensional_2006,
	title = {Three-dimensional reconstruction of partially 3D-digitized peach tree canopies},
	volume = {26},
	issn = {0829-318X, 1758-4469},
	url = {https://academic.oup.com/treephys/article-lookup/doi/10.1093/treephys/26.3.337},
	doi = {10.1093/treephys/26.3.337},
	abstract = {A simplified method for building three-dimensional (3D) mock-ups of peach trees is presented. The method combines partial digitizing of tree structure with reconstruction rules for non-digitized organs. Reconstruction was applied at two scales: leaves on current-year shoots (CYS) and shoots on 1-year-old shoots (OYOS). Reconstruction rules make use of allometric relationships, random sampling of shoot attribute distribution and additional hypotheses (e.g., constant internode length). The method was quantitatively assessed for two training systems (tight goblet and wide-double-Y), at a range of spatial scales. For this purpose, light interception properties of reference and reconstructed mock-ups were compared. Mockup quality depended on scale. Foliage reconstruction on CYS was unsuitable for generating a given CYS. Similarly, CYS reconstruction on OYOS was unsuitable for generating a given OYOS. This is because generic rules derived at the population scale do not consider specific foliage or shoot attributes of a given CYS or OYOS. In contrast, foliage reconstruction on CYS was able to generate OYOS mock-ups having light properties similar to the reference mock-ups. The same held for CYS reconstruction on OYOS for light capture properties at the tree scale. The CYS reconstruction on OYOS was also suitable for deriving OYOS distribution as a function of light interception ability. Reconstruction rules were successfully used to build the vegetation neighborhood of a reference shoot. The proposed method could therefore be used to make 3D tree mock-ups usable for a range of some, but not all, light computations. Because the simplified method allows large time savings, it could be used in virtual experiments requiring large numbers of replicates, such as comparative studies of tree genotypes or training systems.},
	language = {en},
	number = {3},
	urldate = {2019-07-10},
	journal = {Tree Physiology},
	author = {Sonohat, G. and Sinoquet, H. and Kulandaivelu, V. and Combes, D. and Lescourret, F.},
	month = mar,
	year = {2006},
	pages = {337--351},
	file = {Sonohat et al. - 2006 - Three-dimensional reconstruction of partially 3D-d.pdf:/home/alienor/Zotero/storage/X8EBEIU5/Sonohat et al. - 2006 - Three-dimensional reconstruction of partially 3D-d.pdf:application/pdf}
}

@article{santos_automatic_nodate,
	title = {Automatic 3D plant reconstruction from photographies, segmentation and classification of leaves and internodes using clustering},
	language = {en},
	author = {Santos, Thiago and Ueda, Julio},
	pages = {3},
	file = {Santos et Ueda - Automatic 3D plant reconstruction from photographi.pdf:/home/alienor/Zotero/storage/6GK757JE/Santos et Ueda - Automatic 3D plant reconstruction from photographi.pdf:application/pdf}
}

@inproceedings{paproki_automated_2011,
	address = {Noosa, QLD, Australia},
	title = {Automated 3D {Segmentation} and {Analysis} of {Cotton} {Plants}},
	isbn = {978-1-4577-2006-2 978-0-7695-4588-2},
	url = {http://ieeexplore.ieee.org/document/6128719/},
	doi = {10.1109/DICTA.2011.99},
	abstract = {One of the main challenges in high-throughput plant data acquisition is the robust and automated analysis of the data. This includes a high-resolution 3D plant model reconstruction and an automated 3D segmentation. In this paper we present our top-down partitioning pipeline used to automatically segment high-resolution plant meshes. The proposed method produces a smart partition of the initial mesh that allows to identify the main stem, branches, and leaves of the plant. Extracted regions are then processed through the next stage of the automated analysis, which retrieves accurate plant information such as stem length, leaf width, length or area. Results involved applying our topdown approach on a prototype population of 6 cotton-plant meshes studied at 3 or 4 time points. Using our partitioning pipeline, we obtained accurate meshes segmentations for 20 plants out of the initial 22. Results validate the feasibility of an automated analysis of plant data. Future work will involve extending our approach to multiple plant varieties and using an atlas-based iterative feedback scheme to improve the 3D plant reconstruction.},
	language = {en},
	urldate = {2019-07-10},
	booktitle = {2011 {International} {Conference} on {Digital} {Image} {Computing}: {Techniques} and {Applications}},
	publisher = {IEEE},
	author = {Paproki, Anthony and Fripp, Jurgen and Salvado, Olivier and Sirault, Xavier and Berry, Scott and Furbank, Robert},
	month = dec,
	year = {2011},
	pages = {555--560},
	file = {Paproki et al. - 2011 - Automated 3D Segmentation and Analysis of Cotton P.pdf:/home/alienor/Zotero/storage/5D22I9TF/Paproki et al. - 2011 - Automated 3D Segmentation and Analysis of Cotton P.pdf:application/pdf}
}

@inproceedings{sodhi_-field_2017,
	address = {Vancouver, BC},
	title = {In-field segmentation and identification of plant structures using 3D imaging},
	isbn = {978-1-5386-2682-5},
	url = {http://ieeexplore.ieee.org/document/8206407/},
	doi = {10.1109/IROS.2017.8206407},
	abstract = {Automatically correlating plant observable characteristics to their underlying genetics will streamline selection methods in plant breeding. Measurement of plant observable characteristics is called phenotyping, and knowing plant phenotypes accurately and throughout a plant’s growth is central to making breeding decisions. In-ﬁeld plant phenotyping in an automated and noninvasive manner is hence crucial to accelerating plant breeding methods. However, most of the existing methods on plant phenotyping using visual imaging are conﬁned to controlled greenhouse environments.},
	language = {en},
	urldate = {2019-07-10},
	booktitle = {2017 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS})},
	publisher = {IEEE},
	author = {Sodhi, Paloma and Vijayarangan, Srinivasan and Wettergreen, David},
	month = sep,
	year = {2017},
	pages = {5180--5187},
	file = {Sodhi et al. - 2017 - In-field segmentation and identification of plant .pdf:/home/alienor/Zotero/storage/99NZJY57/Sodhi et al. - 2017 - In-field segmentation and identification of plant .pdf:application/pdf}
}

@article{nguyen_structured_2015,
	title = {Structured {Light}-{Based} 3D {Reconstruction} {System} for {Plants}},
	volume = {15},
	issn = {1424-8220},
	url = {http://www.mdpi.com/1424-8220/15/8/18587},
	doi = {10.3390/s150818587},
	abstract = {Camera-based 3D reconstruction of physical objects is one of the most popular computer vision trends in recent years. Many systems have been built to model different real-world subjects, but there is lack of a completely robust system for plants. This paper presents a full 3D reconstruction system that incorporates both hardware structures (including the proposed structured light system to enhance textures on object surfaces) and software algorithms (including the proposed 3D point cloud registration and plant feature measurement). This paper demonstrates the ability to produce 3D models of whole plants created from multiple pairs of stereo images taken at different viewing angles, without the need to destructively cut away any parts of a plant. The ability to accurately predict phenotyping features, such as the number of leaves, plant height, leaf size and internode distances, is also demonstrated. Experimental results show that, for plants having a range of leaf sizes and a distance between leaves appropriate for the hardware design, the algorithms successfully predict phenotyping features in the target crops, with a recall of 0.97 and a precision of 0.89 for leaf detection and less than a 13-mm error for plant size, leaf size and internode distance.},
	language = {en},
	number = {8},
	urldate = {2019-07-10},
	journal = {Sensors},
	author = {Nguyen, Thuy and Slaughter, David and Max, Nelson and Maloof, Julin and Sinha, Neelima},
	month = jul,
	year = {2015},
	pages = {18587--18612},
	file = {Nguyen et al. - 2015 - Structured Light-Based 3D Reconstruction System fo.pdf:/home/alienor/Zotero/storage/KSF968E9/Nguyen et al. - 2015 - Structured Light-Based 3D Reconstruction System fo.pdf:application/pdf}
}

@incollection{lichtenthaler_vivo_1988,
	address = {Dordrecht},
	title = {In {Vivo} {Chlorophyll} {Fluorescence} as a {Tool} for {Stress} {Detection} in {Plants}},
	isbn = {978-94-010-7771-2 978-94-009-2823-7},
	url = {http://link.springer.com/10.1007/978-94-009-2823-7_16},
	language = {en},
	urldate = {2019-07-11},
	booktitle = {Applications of {Chlorophyll} {Fluorescence} in {Photosynthesis} {Research}, {Stress} {Physiology}, {Hydrobiology} and {Remote} {Sensing}},
	publisher = {Springer Netherlands},
	author = {Lichtenthaler, Hartmut K.},
	editor = {Lichtenthaler, Hartmut K.},
	year = {1988},
	doi = {10.1007/978-94-009-2823-7_16},
	pages = {129--142}
}

@incollection{suggett_fluorescence_2010,
	address = {Dordrecht},
	title = {Fluorescence as a {Tool} to {Understand} {Changes} in {Photosynthetic} {Electron} {Flow} {Regulation}},
	isbn = {978-90-481-9267-0 978-90-481-9268-7},
	url = {http://link.springer.com/10.1007/978-90-481-9268-7_4},
	language = {en},
	urldate = {2019-07-11},
	booktitle = {Chlorophyll a {Fluorescence} in {Aquatic} {Sciences}: {Methods} and {Applications}},
	publisher = {Springer Netherlands},
	author = {Ralph, Peter J. and Wilhelm, Christian and Lavaud, Johann and Jakob, Torsten and Petrou, Katherina and Kranz, Sven A.},
	editor = {Suggett, David J. and Prášil, Ondrej and Borowitzka, Michael A.},
	year = {2010},
	doi = {10.1007/978-90-481-9268-7_4},
	pages = {75--89},
	file = {Ralph et al. - 2010 - Fluorescence as a Tool to Understand Changes in Ph.pdf:/home/alienor/Zotero/storage/UWZRGL85/Ralph et al. - 2010 - Fluorescence as a Tool to Understand Changes in Ph.pdf:application/pdf}
}

@inproceedings{kutulakos_theory_1999,
	address = {Kerkyra, Greece},
	title = {A theory of shape by space carving},
	isbn = {978-0-7695-0164-2},
	url = {http://ieeexplore.ieee.org/document/791235/},
	doi = {10.1109/ICCV.1999.791235},
	abstract = {In this paper we consider the problem of computing the 3D shape of an unknown, arbitrarily-shaped scene from multiple photographs taken at known but arbitrarily-distributed viewpoints. By studying the equivalence class of all 3D shapes that reproduce the input photographs, we prove the existence of a special member of this class, the photo hull, that (1) can be computed directly from photographs of the scene, and (2) subsumes all other members of this class. We then give a provably-correct algorithm, called Space Carving, for computing this shape and present experimental results on complex real-world scenes. The approach is designed to (1) capture photorealistic shapes that accurately model scene appearance from a wide range of viewpoints, and (2) account for the complex interactions between occlusion, parallax, shading, and their view-dependent effects on scene-appearance.},
	language = {en},
	urldate = {2019-07-17},
	booktitle = {Proceedings of the {Seventh} {IEEE} {International} {Conference} on {Computer} {Vision}},
	publisher = {IEEE},
	author = {Kutulakos, K.N. and Seitz, S.M.},
	year = {1999},
	pages = {307--314 vol.1},
	file = {Kutulakos et Seitz - 1999 - A theory of shape by space carving.pdf:/home/alienor/Zotero/storage/EY4E6VIB/Kutulakos et Seitz - 1999 - A theory of shape by space carving.pdf:application/pdf}
}

@article{ronneberger_u-net:_2015,
	title = {U-{Net}: {Convolutional} {Networks} for {Biomedical} {Image} {Segmentation}},
	shorttitle = {U-{Net}},
	url = {http://arxiv.org/abs/1505.04597},
	abstract = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more eﬃciently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caﬀe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.},
	language = {en},
	urldate = {2019-07-17},
	journal = {arXiv:1505.04597 [cs]},
	author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
	month = may,
	year = {2015},
	note = {arXiv: 1505.04597},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: conditionally accepted at MICCAI 2015},
	file = {Ronneberger et al. - 2015 - U-Net Convolutional Networks for Biomedical Image.pdf:/home/alienor/Zotero/storage/BXZJ5KWY/Ronneberger et al. - 2015 - U-Net Convolutional Networks for Biomedical Image.pdf:application/pdf}
}

@article{he_deep_2015,
	title = {Deep {Residual} {Learning} for {Image} {Recognition}},
	url = {http://arxiv.org/abs/1512.03385},
	abstract = {Deeper neural networks are more difﬁcult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers—8× deeper than VGG nets [41] but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classiﬁcation task. We also present analysis on CIFAR-10 with 100 and 1000 layers.},
	language = {en},
	urldate = {2019-07-17},
	journal = {arXiv:1512.03385 [cs]},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	month = dec,
	year = {2015},
	note = {arXiv: 1512.03385},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: Tech report},
	file = {He et al. - 2015 - Deep Residual Learning for Image Recognition.pdf:/home/alienor/Zotero/storage/DNVG7YMF/He et al. - 2015 - Deep Residual Learning for Image Recognition.pdf:application/pdf}
}
@Misc{scipy,
  author =    {Eric Jones and Travis Oliphant and Pearu Peterson and others},
  title =     {{SciPy}: Open source scientific tools for {Python}},
  year =      {2001--},
  url = "http://www.scipy.org/",
  note = {[Online; accessed ]}
} 

@article{long_fully_nodate,
	title = {Fully {Convolutional} {Networks} for {Semantic} {Segmentation}},
	abstract = {Convolutional networks are powerful visual models that yield hierarchies of features. We show that convolutional networks by themselves, trained end-to-end, pixelsto-pixels, exceed the state-of-the-art in semantic segmentation. Our key insight is to build “fully convolutional” networks that take input of arbitrary size and produce correspondingly-sized output with efﬁcient inference and learning. We deﬁne and detail the space of fully convolutional networks, explain their application to spatially dense prediction tasks, and draw connections to prior models. We adapt contemporary classiﬁcation networks (AlexNet [22], the VGG net [34], and GoogLeNet [35]) into fully convolutional networks and transfer their learned representations by ﬁne-tuning [5] to the segmentation task. We then deﬁne a skip architecture that combines semantic information from a deep, coarse layer with appearance information from a shallow, ﬁne layer to produce accurate and detailed segmentations. Our fully convolutional network achieves stateof-the-art segmentation of PASCAL VOC (20\% relative improvement to 62.2\% mean IU on 2012), NYUDv2, and SIFT Flow, while inference takes less than one ﬁfth of a second for a typical image.},
	language = {en},
	author = {Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
	pages = {10},
	file = {Long et al. - Fully Convolutional Networks for Semantic Segmenta.pdf:/home/alienor/Zotero/storage/8L9KL3DB/Long et al. - Fully Convolutional Networks for Semantic Segmenta.pdf:application/pdf}
}

@misc{noauthor_christophe_nodate,
	title = {Christophe {\textbar} {ROMI} {Slack}},
	url = {https://ro-mi.slack.com/messages/DLD96L98R/?},
	urldate = {2019-07-19},
	file = {Christophe | ROMI Slack:/home/alienor/Zotero/storage/U83BAJDG/DLD96L98R.html:text/html}
}

@book{denis1998symmetry,
  title={Symmetry in plants},
  author={Denis, Barabe and others},
  volume={4},
  year={1998},
  publisher={World Scientific}
}
@inproceedings{qiu2016unrealcv,
  title={Unrealcv: Connecting computer vision to unreal engine},
  author={Qiu, Weichao and Yuille, Alan},
  booktitle={European Conference on Computer Vision},
  pages={909--916},
  year={2016},
  organization={Springer}
}
@article{alhaija2018augmented,
  title={Augmented reality meets computer vision: Efficient data generation for urban driving scenes},
  author={Alhaija, Hassan Abu and Mustikovela, Siva Karthik and Mescheder, Lars and Geiger, Andreas and Rother, Carsten},
  journal={International Journal of Computer Vision},
  volume={126},
  number={9},
  pages={961--972},
  year={2018},
  publisher={Springer}
}
@article{shi2019plant,
  title={Plant-part segmentation using deep learning and multi-view vision},
  author={Shi, Weinan and van de Zedde, Rick and Jiang, Huanyu and Kootstra, Gert},
  journal={Biosystems Engineering},
  volume={187},
  pages={81--95},
  year={2019},
  publisher={Elsevier}
}
@inproceedings{long2015fully,
  title={Fully convolutional networks for semantic segmentation},
  author={Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3431--3440},
  year={2015}
}
@inproceedings{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle={Advances in neural information processing systems},
  pages={1097--1105},
  year={2012}
}
@inproceedings{ronneberger2015u,
  title={U-net: Convolutional networks for biomedical image segmentation},
  author={Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  booktitle={International Conference on Medical image computing and computer-assisted intervention},
  pages={234--241},
  year={2015},
  organization={Springer}
}
@article{minervini2015image,
  title={Image analysis: the new bottleneck in plant phenotyping [applications corner]},
  author={Minervini, Massimo and Scharr, Hanno and Tsaftaris, Sotirios A},
  journal={IEEE signal processing magazine},
  volume={32},
  number={4},
  pages={126--131},
  year={2015},
  publisher={IEEE}
}

@article{peirone2018assessing,
  title={Assessing the efficiency of phenotyping early traits in a greenhouse automated platform for predicting drought tolerance of soybean in the field},
  author={Peirone, Laura Soledad and Pereyra Irujo, Gustavo and Bolton, Alejandro and Erreguerena, Ignacio and Aguirrezabal, Luis AN},
  journal={Frontiers in plant science},
  volume={9},
  pages={587},
  year={2018},
  publisher={Frontiers}
}
@book{prusinkiewicz2012algorithmic,
  title={The algorithmic beauty of plants},
  author={Prusinkiewicz, Przemyslaw and Lindenmayer, Aristid},
  year={2012},
  publisher={Springer Science \& Business Media}
}
@article{pradal2009plantgl,
  title={PlantGL: a Python-based geometric library for 3D plant modelling at different scales},
  author={Pradal, Christophe and Boudon, Fr{\'e}d{\'e}ric and Nouguier, Christophe and Chopard, J{\'e}r{\^o}me and Godin, Christophe},
  journal={Graphical models},
  volume={71},
  number={1},
  pages={1--21},
  year={2009},
  publisher={Elsevier}
}

@article{mayer_large_2016,
	title = {A {Large} {Dataset} to {Train} {Convolutional} {Networks} for {Disparity}, {Optical} {Flow}, and {Scene} {Flow} {Estimation}},
	url = {http://arxiv.org/abs/1512.02134},
	doi = {10.1109/CVPR.2016.438},
	abstract = {Recent work has shown that optical ﬂow estimation can be formulated as a supervised learning task and can be successfully solved with convolutional networks. Training of the so-called FlowNet was enabled by a large synthetically generated dataset. The present paper extends the concept of optical ﬂow estimation via convolutional networks to disparity and scene ﬂow estimation. To this end, we propose three synthetic stereo video datasets with sufﬁcient realism, variation, and size to successfully train large networks. Our datasets are the ﬁrst large-scale datasets to enable training and evaluating scene ﬂow methods. Besides the datasets, we present a convolutional network for real-time disparity estimation that provides state-of-the-art results. By combining a ﬂow and disparity estimation network and training it jointly, we demonstrate the ﬁrst scene ﬂow estimation with a convolutional network.},
	language = {en},
	urldate = {2019-07-24},
	journal = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	author = {Mayer, Nikolaus and Ilg, Eddy and Häusser, Philip and Fischer, Philipp and Cremers, Daniel and Dosovitskiy, Alexey and Brox, Thomas},
	month = jun,
	year = {2016},
	note = {arXiv: 1512.02134},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, I.2.10, I.2.6, I.4.8, Statistics - Machine Learning},
	pages = {4040--4048},
	annote = {Comment: Includes supplementary material},
	file = {Mayer et al. - 2016 - A Large Dataset to Train Convolutional Networks fo.pdf:/home/alienor/Zotero/storage/LYAG827S/Mayer et al. - 2016 - A Large Dataset to Train Convolutional Networks fo.pdf:application/pdf}
}

@article{duboudin_toward_2019,
	title = {Toward a {Procedural} {Fruit} {Tree} {Rendering} {Framework} for {Image} {Analysis}},
	url = {http://arxiv.org/abs/1907.04759},
	abstract = {We propose a procedural fruit tree rendering framework, based on Blender and Python scripts allowing to generate quickly labeled dataset (i.e. including ground truth semantic segmentation). It is designed to train image analysis deep learning methods (e.g. in a robotic fruit harvesting context), where real labeled training datasets are usually scarce and existing synthetic ones are too specialized. Moreover, the framework includes the possibility to introduce parametrized variations in the model (e.g. lightning conditions, background), producing a dataset with embedded Domain Randomization aspect.},
	language = {en},
	urldate = {2019-08-02},
	journal = {arXiv:1907.04759 [cs]},
	author = {Duboudin, Thomas and Petit, Maxime and Chen, Liming},
	month = jul,
	year = {2019},
	note = {arXiv: 1907.04759},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Robotics},
	file = {Duboudin et al. - 2019 - Toward a Procedural Fruit Tree Rendering Framework.pdf:/home/alienor/Zotero/storage/VLQFTNMJ/Duboudin et al. - 2019 - Toward a Procedural Fruit Tree Rendering Framework.pdf:application/pdf}
}



@article{serna_detection_2014,
	title = {Detection, segmentation and classification of 3D urban objects using mathematical morphology and supervised learning},
	volume = {93},
	issn = {09242716},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0924271614000872},
	doi = {10.1016/j.isprsjprs.2014.03.015},
	abstract = {In this paper, we propose an automatic and robust approach to detect, segment and classify urban objects from 3D point clouds. Processing is carried out using elevation images, called also digital elevation models, and the ﬁnal result is presented reprojecting the image onto the 3D point cloud. First, the ground is segmented and objects are detected as discontinuities on the ground. Then, connected objects are segmented using a watershed constrained by the signiﬁcant maxima. Finally, objects are classiﬁed in several categories using a support vector machine (SVM) approach with geometrical and contextual features.},
	language = {en},
	urldate = {2019-08-02},
	journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
	author = {Serna, Andrés and Marcotegui, Beatriz},
	month = jul,
	year = {2014},
	pages = {243--255},
	file = {Serna et Marcotegui - 2014 - Detection, segmentation and classification of 3D u.pdf:/home/alienor/Zotero/storage/9JXZ55XT/Serna et Marcotegui - 2014 - Detection, segmentation and classification of 3D u.pdf:application/pdf}
}

@article{DBLP:journals/corr/Smith15a,
  author    = {Leslie N. Smith},
  title     = {No More Pesky Learning Rate Guessing Games},
  journal   = {CoRR},
  volume    = {abs/1506.01186},
  year      = {2015},
  url       = {http://arxiv.org/abs/1506.01186},
  archivePrefix = {arXiv},
  eprint    = {1506.01186},
  timestamp = {Mon, 13 Aug 2018 16:47:53 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/Smith15a},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{srivastava2017drought,
  title={Drought stress classification using 3D plant models},
  author={Srivastava, Siddharth and Bhugra, Swati and Lall, Brejesh and Chaudhury, Santanu},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={2046--2054},
  year={2017}
}
@inproceedings{das2017automated,
  title={Automated stem angle determination for temporal plant phenotyping analysis},
  author={Das Choudhury, Sruti and Goswami, Saptarsi and Bashyam, Srinidhi and Samal, Ashok and Awada, Tala},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={2022--2029},
  year={2017}
}
@article{scharr2017fast,
  title={Fast high resolution volume carving for 3D plant shoot reconstruction},
  author={Scharr, Hanno and Briese, Christoph and Embgenbroich, Patrick and Fischbach, Andreas and Fiorani, Fabio and M{\"u}ller-Linow, Mark},
  journal={Frontiers in plant science},
  volume={8},
  pages={1680},
  year={2017},
  publisher={Frontiers}
}
@Manual{blender,
   title = {Blender - a 3D modelling and rendering package},
   author = {{Blender Online Community}},
   organization = {Blender Foundation},
   address = {Blender Institute, Amsterdam},
   year = {2019},
   url = {http://www.blender.org},
 }
@Manual{xcarve,
   title = {X-Carve},
   author = {{Inventables}},
   year = {2019},
   url = {http://www.inventables.com},
 }



@misc{colliaux_roboitic_2019,
	title = {The roboitic naturalist and current {SOA} in semantic segmentation},
	url = {https://www.dropbox.com/s/4bynp9v7pk6k766/main.pdf?dl=0},
	abstract = {Partagé avec Dropbox},
	language = {fr},
	urldate = {2019-04-15},
	journal = {Dropbox},
	author = {Colliaux, David},
	month = apr,
	year = {2019},
	file = {Snapshot:C\:\\Users\\alien\\Zotero\\storage\\VGZ6V7LW\\main.html:text/html}
}

@misc{noauthor_phytotyping4d:_2019,
	title = {{Phytotyping4D}: a light‐field imaging system for non‐invasive and accurate monitoring of spatio‐temporal plant growth - {Apelt} - 2015 - {The} {Plant} {Journal} - {Wiley} {Online} {Library}},
	url = {https://onlinelibrary.wiley.com/doi/full/10.1111/tpj.12833},
	urldate = {2019-04-15},
	month = apr,
	year = {2019},
	file = {Phytotyping4D\: a light‐field imaging system for non‐invasive and accurate monitoring of spatio‐temporal plant growth - Apelt - 2015 - The Plant Journal - Wiley Online Library:C\:\\Users\\alien\\Zotero\\storage\\TZQXVY2M\\tpj.html:text/html}
}

@article{rezende_unsupervised_nodate,
	title = {Unsupervised {Learning} of {3D} {Structure} from {Images}},
	abstract = {A key goal of computer vision is to recover the underlying 3D structure that gives rise to 2D observations of the world. If endowed with 3D understanding, agents can abstract away from the complexity of the rendering process to form stable, disentangled representations of scene elements. In this paper we learn strong deep generative models of 3D structures, and recover these structures from 2D images via probabilistic inference. We demonstrate high-quality samples and report log-likelihoods on several datasets, including ShapeNet [2], and establish the ﬁrst benchmarks in the literature. We also show how these models and their inference networks can be trained jointly, end-to-end, and directly from 2D images without any use of ground-truth 3D labels. This demonstrates for the ﬁrst time the feasibility of learning to infer 3D representations of the world in a purely unsupervised manner.},
	language = {en},
	author = {Rezende, Danilo Jimenez and Eslami, S M Ali and Mohamed, Shakir and Battaglia, Peter and Jaderberg, Max and Heess, Nicolas},
	pages = {9},
	file = {Rezende et al. - Unsupervised Learning of 3D Structure from Images.pdf:C\:\\Users\\alien\\Zotero\\storage\\YA23M635\\Rezende et al. - Unsupervised Learning of 3D Structure from Images.pdf:application/pdf}
}

@article{lawin_deep_2017,
	title = {Deep {Projective} {3D} {Semantic} {Segmentation}},
	url = {http://arxiv.org/abs/1705.03428},
	abstract = {Semantic segmentation of 3D point clouds is a challenging problem with numerous real-world applications. While deep learning has revolutionized the ﬁeld of image semantic segmentation, its impact on point cloud data has been limited so far. Recent attempts, based on 3D deep learning approaches (3DCNNs), have achieved below-expected results. Such methods require voxelizations of the underlying point cloud data, leading to decreased spatial resolution and increased memory consumption. Additionally, 3D-CNNs greatly suffer from the limited availability of annotated datasets.},
	language = {en},
	urldate = {2019-04-30},
	journal = {arXiv:1705.03428 [cs]},
	author = {Lawin, Felix Järemo and Danelljan, Martin and Tosteberg, Patrik and Bhat, Goutam and Khan, Fahad Shahbaz and Felsberg, Michael},
	month = may,
	year = {2017},
	note = {arXiv: 1705.03428},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: Submitted to CAIP 2017},
	file = {Lawin et al. - 2017 - Deep Projective 3D Semantic Segmentation.pdf:C\:\\Users\\alien\\Zotero\\storage\\6DUHPSKS\\Lawin et al. - 2017 - Deep Projective 3D Semantic Segmentation.pdf:application/pdf}
}

@misc{noauthor_z-library_2019,
	title = {Z-{Library}},
	url = {https://booksc.xyz/ireader/73005455},
	urldate = {2019-05-02},
	month = may,
	year = {2019},
	file = {Z-Library:C\:\\Users\\alien\\Zotero\\storage\\9NI4PUEP\\73005455.html:text/html}
}

@misc{noauthor_z-library_2019-1,
	title = {Z-{Library}},
	url = {https://booksc.xyz/ireader/67468964},
	urldate = {2019-05-02},
	month = may,
	year = {2019}
}

@inproceedings{fawakherji_crop_2019,
	address = {Naples, Italy},
	title = {Crop and {Weeds} {Classification} for {Precision} {Agriculture} {Using} {Context}-{Independent} {Pixel}-{Wise} {Segmentation}},
	isbn = {978-1-5386-9245-5},
	url = {https://ieeexplore.ieee.org/document/8675654/},
	doi = {10.1109/IRC.2019.00029},
	language = {en},
	urldate = {2019-05-02},
	booktitle = {2019 {Third} {IEEE} {International} {Conference} on {Robotic} {Computing} ({IRC})},
	publisher = {IEEE},
	author = {Fawakherji, Mulham and Youssef, Ali and Bloisi, Domenico and Pretto, Alberto and Nardi, Daniele},
	month = feb,
	year = {2019},
	pages = {146--152},
	file = {Fawakherji et al. - 2019 - Crop and Weeds Classification for Precision Agricu.pdf:C\:\\Users\\alien\\Zotero\\storage\\8XJ2BIK2\\Fawakherji et al. - 2019 - Crop and Weeds Classification for Precision Agricu.pdf:application/pdf}
}


@article{caesar_region-based_2016,
	title = {Region-based semantic segmentation with end-to-end training},
	url = {http://arxiv.org/abs/1607.07671},
	abstract = {We propose a novel method for semantic segmentation, the task of labeling each pixel in an image with a semantic class. Our method combines the advantages of the two main competing paradigms. Methods based on region classiﬁcation oﬀer proper spatial support for appearance measurements, but typically operate in two separate stages, none of which targets pixel labeling performance at the end of the pipeline. More recent fully convolutional methods are capable of end-to-end training for the ﬁnal pixel labeling, but resort to ﬁxed patches as spatial support. We show how to modify modern region-based approaches to enable end-to-end training for semantic segmentation. This is achieved via a diﬀerentiable region-to-pixel layer and a diﬀerentiable free-form Regionof-Interest pooling layer. Our method improves the state-of-the-art in terms of class-average accuracy with 64.0\% on SIFT Flow and 49.9\% on PASCAL Context, and is particularly accurate at object boundaries.},
	language = {en},
	urldate = {2019-05-03},
	journal = {arXiv:1607.07671 [cs]},
	author = {Caesar, Holger and Uijlings, Jasper and Ferrari, Vittorio},
	month = jul,
	year = {2016},
	note = {arXiv: 1607.07671},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: ECCV 2016 camera-ready},
	file = {Caesar et al. - 2016 - Region-based semantic segmentation with end-to-end.pdf:C\:\\Users\\alien\\Zotero\\storage\\CI7XNGRU\\Caesar et al. - 2016 - Region-based semantic segmentation with end-to-end.pdf:application/pdf}
}

@article{chen_tensormask:_2019,
	title = {{TensorMask}: {A} {Foundation} for {Dense} {Object} {Segmentation}},
	shorttitle = {{TensorMask}},
	url = {http://arxiv.org/abs/1903.12174},
	abstract = {Sliding-window object detectors that generate boundingbox object predictions over a dense, regular grid have advanced rapidly and proven popular. In contrast, modern instance segmentation approaches are dominated by methods that ﬁrst detect object bounding boxes, and then crop and segment these regions, as popularized by Mask R-CNN. In this work, we investigate the paradigm of dense slidingwindow instance segmentation, which is surprisingly underexplored. Our core observation is that this task is fundamentally different than other dense prediction tasks such as semantic segmentation or bounding-box object detection, as the output at every spatial location is itself a geometric structure with its own spatial dimensions. To formalize this, we treat dense instance segmentation as a prediction task over 4D tensors and present a general framework called TensorMask that explicitly captures this geometry and enables novel operators on 4D tensors. We demonstrate that the tensor view leads to large gains over baselines that ignore this structure, and leads to results comparable to Mask R-CNN. These promising results suggest that TensorMask can serve as a foundation for novel advances in dense mask prediction and a more complete understanding of the task. Code will be made available.},
	language = {en},
	urldate = {2019-05-03},
	journal = {arXiv:1903.12174 [cs]},
	author = {Chen, Xinlei and Girshick, Ross and He, Kaiming and Dollár, Piotr},
	month = mar,
	year = {2019},
	note = {arXiv: 1903.12174},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: 12 pages, technical report},
	file = {Chen et al. - 2019 - TensorMask A Foundation for Dense Object Segmenta.pdf:C\:\\Users\\alien\\Zotero\\storage\\6DLBJLET\\Chen et al. - 2019 - TensorMask A Foundation for Dense Object Segmenta.pdf:application/pdf}
}

@article{mondal_few-shot_2018,
	title = {Few-shot {3D} {Multi}-modal {Medical} {Image} {Segmentation} using {Generative} {Adversarial} {Learning}},
	url = {http://arxiv.org/abs/1810.12241},
	abstract = {We address the problem of segmenting 3D multimodal medical images in scenarios where very few labeled examples are available for training. Leveraging the recent success of adversarial learning for semi-supervised segmentation, we propose a novel method based on Generative Adversarial Networks (GANs) to train a segmentation model with both labeled and unlabeled images. The proposed method prevents over-ﬁtting by learning to discriminate between true and fake patches obtained by a generator network. Our work extends current adversarial learning approaches, which focus on 2D single-modality images, to the more challenging context of 3D volumes of multiple modalities. The proposed method is evaluated on the problem of segmenting brain MRI from the iSEG-2017 and MRBrainS 2013 datasets. Signiﬁcant performance improvement is reported, compared to state-of-art segmentation networks trained in a fully-supervised manner. In addition, our work presents a comprehensive analysis of different GAN architectures for semi-supervised segmentation, showing recent techniques like feature matching to yield a higher performance than conventional adversarial training approaches. Our code is publicly available at https://github.com/arnab39/FewShot GAN-Unet3D.},
	language = {en},
	urldate = {2019-05-03},
	journal = {arXiv:1810.12241 [cs]},
	author = {Mondal, Arnab Kumar and Dolz, Jose and Desrosiers, Christian},
	month = oct,
	year = {2018},
	note = {arXiv: 1810.12241},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: submitted to Medical Image Analysis for review},
	file = {Mondal et al. - 2018 - Few-shot 3D Multi-modal Medical Image Segmentation.pdf:C\:\\Users\\alien\\Zotero\\storage\\DZJLNHY7\\Mondal et al. - 2018 - Few-shot 3D Multi-modal Medical Image Segmentation.pdf:application/pdf}
}

@article{huang_eanet:_2018,
	title = {{EANet}: {Enhancing} {Alignment} for {Cross}-{Domain} {Person} {Re}-identification},
	shorttitle = {{EANet}},
	url = {http://arxiv.org/abs/1812.11369},
	abstract = {Person re-identification (ReID) has achieved significant improvement under the single-domain setting. However, directly exploiting a model to new domains is always faced with huge performance drop, and adapting the model to new domains without target-domain identity labels is still challenging. In this paper, we address cross-domain ReID and make contributions for both model generalization and adaptation. First, we propose Part Aligned Pooling (PAP) that brings significant improvement for cross-domain testing. Second, we design a Part Segmentation (PS) constraint over ReID feature to enhance alignment and improve model generalization. Finally, we show that applying our PS constraint to unlabeled target domain images serves as effective domain adaptation. We conduct extensive experiments between three large datasets, Market1501, CUHK03 and DukeMTMC-reID. Our model achieves state-of-the-art performance under both source-domain and cross-domain settings. For completeness, we also demonstrate the complementarity of our model to existing domain adaptation methods. The code is available at https://github.com/huanghoujing/EANet.},
	urldate = {2019-05-03},
	journal = {arXiv:1812.11369 [cs]},
	author = {Huang, Houjing and Yang, Wenjie and Chen, Xiaotang and Zhao, Xin and Huang, Kaiqi and Lin, Jinbin and Huang, Guan and Du, Dalong},
	month = dec,
	year = {2018},
	note = {arXiv: 1812.11369},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv\:1812.11369 PDF:C\:\\Users\\alien\\Zotero\\storage\\53CQ465T\\Huang et al. - 2018 - EANet Enhancing Alignment for Cross-Domain Person.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\alien\\Zotero\\storage\\ZLN6ZHAR\\1812.html:text/html}
}

@article{chen_deeplab:_2016,
	title = {{DeepLab}: {Semantic} {Image} {Segmentation} with {Deep} {Convolutional} {Nets}, {Atrous} {Convolution}, and {Fully} {Connected} {CRFs}},
	shorttitle = {{DeepLab}},
	url = {http://arxiv.org/abs/1606.00915},
	abstract = {In this work we address the task of semantic image segmentation with Deep Learning and make three main contributions that are experimentally shown to have substantial practical merit. First, we highlight convolution with upsampled ﬁlters, or ‘atrous convolution’, as a powerful tool in dense prediction tasks. Atrous convolution allows us to explicitly control the resolution at which feature responses are computed within Deep Convolutional Neural Networks. It also allows us to effectively enlarge the ﬁeld of view of ﬁlters to incorporate larger context without increasing the number of parameters or the amount of computation. Second, we propose atrous spatial pyramid pooling (ASPP) to robustly segment objects at multiple scales. ASPP probes an incoming convolutional feature layer with ﬁlters at multiple sampling rates and effective ﬁelds-of-views, thus capturing objects as well as image context at multiple scales. Third, we improve the localization of object boundaries by combining methods from DCNNs and probabilistic graphical models. The commonly deployed combination of max-pooling and downsampling in DCNNs achieves invariance but has a toll on localization accuracy. We overcome this by combining the responses at the ﬁnal DCNN layer with a fully connected Conditional Random Field (CRF), which is shown both qualitatively and quantitatively to improve localization performance. Our proposed “DeepLab” system sets the new state-of-art at the PASCAL VOC-2012 semantic image segmentation task, reaching 79.7\% mIOU in the test set, and advances the results on three other datasets: PASCAL-Context, PASCAL-Person-Part, and Cityscapes. All of our code is made publicly available online.},
	language = {en},
	urldate = {2019-05-03},
	journal = {arXiv:1606.00915 [cs]},
	author = {Chen, Liang-Chieh and Papandreou, George and Kokkinos, Iasonas and Murphy, Kevin and Yuille, Alan L.},
	month = jun,
	year = {2016},
	note = {arXiv: 1606.00915},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: Accepted by TPAMI},
	file = {Chen et al. - 2016 - DeepLab Semantic Image Segmentation with Deep Con.pdf:C\:\\Users\\alien\\Zotero\\storage\\3KLB86GH\\Chen et al. - 2016 - DeepLab Semantic Image Segmentation with Deep Con.pdf:application/pdf}
}

@inproceedings{soltani_synthesizing_2017,
	address = {Honolulu, HI},
	title = {Synthesizing {3D} {Shapes} via {Modeling} {Multi}-view {Depth} {Maps} and {Silhouettes} with {Deep} {Generative} {Networks}},
	isbn = {978-1-5386-0457-1},
	url = {http://ieeexplore.ieee.org/document/8099752/},
	doi = {10.1109/CVPR.2017.269},
	abstract = {We study the problem of learning generative models of 3D shapes. Voxels or 3D parts have been widely used as the underlying representations to build complex 3D shapes; however, voxel-based representations suffer from high memory requirements, and parts-based models require a large collection of cached or richly parametrized parts. We take an alternative approach: learning a generative model over multi-view depth maps or their corresponding silhouettes, and using a deterministic rendering function to produce 3D shapes from these images. A multi-view representation of shapes enables generation of 3D models with ﬁne details, as 2D depth maps and silhouettes can be modeled at a much higher resolution than 3D voxels. Moreover, our approach naturally brings the ability to recover the underlying 3D representation from depth maps of one or a few viewpoints. Experiments show that our framework can generate 3D shapes with variations and details. We also demonstrate that our model has out-of-sample generalization power for real-world tasks with occluded objects.},
	language = {en},
	urldate = {2019-05-29},
	booktitle = {2017 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Soltani, Amir Arsalan and Huang, Haibin and Wu, Jiajun and Kulkarni, Tejas D. and Tenenbaum, Joshua B.},
	month = jul,
	year = {2017},
	pages = {2511--2519},
	file = {Soltani et al. - 2017 - Synthesizing 3D Shapes via Modeling Multi-view Dep.pdf:C\:\\Users\\alien\\Zotero\\storage\\EXW4LBGF\\Soltani et al. - 2017 - Synthesizing 3D Shapes via Modeling Multi-view Dep.pdf:application/pdf}
}

@article{dai_3dmv:_2018,
	title = {{3DMV}: {Joint} {3D}-{Multi}-{View} {Prediction} for {3D} {Semantic} {Scene} {Segmentation}},
	shorttitle = {{3DMV}},
	url = {http://arxiv.org/abs/1803.10409},
	abstract = {We present 3DMV, a novel method for 3D semantic scene segmentation of RGB-D scans in indoor environments using a joint 3Dmulti-view prediction network. In contrast to existing methods that either use geometry or RGB data as input for this task, we combine both data modalities in a joint, end-to-end network architecture. Rather than simply projecting color data into a volumetric grid and operating solely in 3D – which would result in insuﬃcient detail – we ﬁrst extract feature maps from associated RGB images. These features are then mapped into the volumetric feature grid of a 3D network using a diﬀerentiable backprojection layer. Since our target is 3D scanning scenarios with possibly many frames, we use a multi-view pooling approach in order to handle a varying number of RGB input views. This learned combination of RGB and geometric features with our joint 2D-3D architecture achieves signiﬁcantly better results than existing baselines. For instance, our ﬁnal result on the ScanNet 3D segmentation benchmark [1] increases from 52.8\% to 75\% accuracy compared to existing volumetric architectures.},
	language = {en},
	urldate = {2019-05-29},
	journal = {arXiv:1803.10409 [cs]},
	author = {Dai, Angela and Nießner, Matthias},
	month = mar,
	year = {2018},
	note = {arXiv: 1803.10409},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {Dai et Nießner - 2018 - 3DMV Joint 3D-Multi-View Prediction for 3D Semant.pdf:C\:\\Users\\alien\\Zotero\\storage\\WKNVWCCH\\Dai et Nießner - 2018 - 3DMV Joint 3D-Multi-View Prediction for 3D Semant.pdf:application/pdf}
}

@article{kar_learning_2017,
	title = {Learning a {Multi}-{View} {Stereo} {Machine}},
	url = {http://arxiv.org/abs/1708.05375},
	abstract = {We present a learnt system for multi-view stereopsis. In contrast to recent learning based methods for 3D reconstruction, we leverage the underlying 3D geometry of the problem through feature projection and unprojection along viewing rays. By formulating these operations in a differentiable manner, we are able to learn the system end-to-end for the task of metric 3D reconstruction. End-to-end learning allows us to jointly reason about shape priors while conforming geometric constraints, enabling reconstruction from much fewer images (even a single image) than required by classical approaches as well as completion of unseen surfaces. We thoroughly evaluate our approach on the ShapeNet dataset and demonstrate the beneﬁts over classical approaches as well as recent learning based methods.},
	language = {en},
	urldate = {2019-05-29},
	journal = {arXiv:1708.05375 [cs]},
	author = {Kar, Abhishek and Häne, Christian and Malik, Jitendra},
	month = aug,
	year = {2017},
	note = {arXiv: 1708.05375},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {Kar et al. - 2017 - Learning a Multi-View Stereo Machine.pdf:C\:\\Users\\alien\\Zotero\\storage\\5AZP5YZC\\Kar et al. - 2017 - Learning a Multi-View Stereo Machine.pdf:application/pdf}
}

@article{mueller_evaluation_nodate,
	title = {{EVALUATION} {OF} {3D} {RECONSTRCUTION} {USING} {MULTIVIEW} {BACKPROJECTION}},
	abstract = {This paper evaluates the final reconstruction quality of 3D objects from different reconstruction methods by comparing rendered views of a 3D model to the original views, initially taken from 2D cameras. The paper uses pixel-by-pixel error measures, like pixelwise reconstruction error for non-textured objects and PSNR values for colored or textured objects. Concurrently, the limitations of such measures in connection with 3D reconstruction evaluation are highlighted and a reconstruction measurement based on differential values is investigated, where deviations from reference values are analyzed instead of absolute PSNR-values.},
	language = {en},
	author = {Mueller, K and Zabulis, X and Smolic, A and Wiegand, T},
	pages = {4},
	file = {Mueller et al. - EVALUATION OF 3D RECONSTRCUTION USING MULTIVIEW BA.pdf:C\:\\Users\\alien\\Zotero\\storage\\HFKW6A85\\Mueller et al. - EVALUATION OF 3D RECONSTRCUTION USING MULTIVIEW BA.pdf:application/pdf}
}

@article{eid_performance_2005,
	title = {On the {Performance} {Evaluation} of {3D} {Reconstruction} {Techniques} from a {Sequence} of {Images}},
	volume = {2005},
	issn = {1687-6180},
	url = {https://asp-eurasipjournals.springeropen.com/articles/10.1155/ASP.2005.1948},
	doi = {10.1155/ASP.2005.1948},
	abstract = {The performance evaluation of 3D reconstruction techniques is not a simple problem to solve. This is not only due to the increased dimensionality of the problem but also due to the lack of standardized and widely accepted testing methodologies. This paper presents a uniﬁed framework for the performance evaluation of diﬀerent 3D reconstruction techniques. This framework includes a general problem formalization, diﬀerent measuring criteria, and a classiﬁcation method as a ﬁrst step in standardizing the evaluation process. Performance characterization of two standard 3D reconstruction techniques, stereo and space carving, is also presented. The evaluation is performed on the same data set using an image reprojection testing methodology to reduce the dimensionality of the evaluation domain. Also, diﬀerent measuring strategies are presented and applied to the stereo and space carving techniques. These measuring strategies have shown consistent results in quantifying the performance of these techniques. Additional experiments are performed on the space carving technique to study the eﬀect of the number of input images and the camera pose on its performance.},
	language = {en},
	number = {13},
	urldate = {2019-05-29},
	journal = {EURASIP Journal on Advances in Signal Processing},
	author = {Eid, Ahmed and Farag, Aly},
	month = dec,
	year = {2005},
	pages = {986306},
	file = {Eid et Farag - 2005 - On the Performance Evaluation of 3D Reconstruction.pdf:C\:\\Users\\alien\\Zotero\\storage\\65TNYVB6\\Eid et Farag - 2005 - On the Performance Evaluation of 3D Reconstruction.pdf:application/pdf}
}

@article{garbez_predicting_2016,
	title = {Predicting sensorial attribute scores of ornamental plants assessed in {3D} through rotation on video by image analysis: {A} study on the morphology of virtual rose bushes},
	volume = {121},
	issn = {01681699},
	shorttitle = {Predicting sensorial attribute scores of ornamental plants assessed in {3D} through rotation on video by image analysis},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0168169916000065},
	doi = {10.1016/j.compag.2016.01.001},
	language = {en},
	urldate = {2019-06-13},
	journal = {Computers and Electronics in Agriculture},
	author = {Garbez, M. and Chéné, Y. and Belin, É. and Sigogne, M. and Labatte, J.-M. and Hunault, G. and Symoneaux, R. and Rousseau, D. and Galopin, G.},
	month = feb,
	year = {2016},
	pages = {331--346}
}


@article{biskup_stereo_2007,
	title = {A stereo imaging system for measuring structural parameters of plant canopies},
	volume = {30},
	issn = {1365-3040},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1365-3040.2007.01702.x},
	doi = {10.1111/j.1365-3040.2007.01702.x},
	abstract = {Plants constantly adapt their leaf orientation in response to fluctuations in the environment, to maintain radiation use efficiency in the face of varying intensity and incidence direction of sunlight. Various methods exist for measuring structural canopy parameters such as leaf angle distribution. However, direct methods tend to be labour-intensive, while indirect methods usually give statistical information on stand level rather than on individual leaves. We present an area-based, binocular stereo system composed of commercially available components that allows three-dimensional reconstruction of small- to medium-sized canopies on the level of single leaves under field conditions. Spatial orientation of single leaves is computed with automated processes using modern, well-established stereo matching and segmentation techniques, which were adapted for the properties of plant canopies, providing high spatial and temporal resolution (angle measurements with an accuracy of approx. ±5° and a maximum sampling rate of three frames per second). The applicability of our approach is demonstrated in three case studies: (1) the dihedral leaflet angle of an individual soybean was tracked to monitor nocturnal and daytime leaf movement showing different frequencies and amplitudes; (2) drought stress was diagnosed in soybean by quantifying changes in the zenith leaflet angle distribution; and (3) the diurnal course of the zenith leaf angle distribution of a closed soybean canopy was measured.},
	language = {en},
	number = {10},
	urldate = {2019-06-20},
	journal = {Plant, Cell \& Environment},
	author = {Biskup, Bernhard and Scharr, Hanno and Schurr, Ulrich and Rascher, Uwe},
	year = {2007},
	keywords = {3D reconstruction, canopy, leaf movement, screening, stereo imaging, systems biology},
	pages = {1299--1308},
	file = {Full Text PDF:C\:\\Users\\alien\\Zotero\\storage\\BRG3IQPU\\Biskup et al. - 2007 - A stereo imaging system for measuring structural p.pdf:application/pdf;Snapshot:C\:\\Users\\alien\\Zotero\\storage\\C47IL3H3\\j.1365-3040.2007.01702.html:text/html}
}

@misc{noauthor_irrigation_2019,
	title = {Irrigation control of cowpea plants using the measurement of leaf thickness under greenhouse conditions {\textbar} {Seelig}, {Hans}-{Dieter}; {Stoner}, {Richard} {J}.; {Linden}, {James} {C}. {\textbar} download},
	url = {https://booksc.xyz/book/12793550/cb9ac0},
	urldate = {2019-06-20},
	month = jun,
	year = {2019},
	file = {Irrigation control of cowpea plants using the measurement of leaf thickness under greenhouse conditions | Seelig, Hans-Dieter\; Stoner, Richard J.\; Linden, James C. | download:C\:\\Users\\alien\\Zotero\\storage\\ZZKV63BT\\cb9ac0.html:text/html}
}

@inproceedings{ying_zheng_detailed_2011,
	address = {Barcelona, Spain},
	title = {Detailed reconstruction of {3D} plant root shape},
	isbn = {978-1-4577-1102-2 978-1-4577-1101-5 978-1-4577-1100-8},
	url = {http://ieeexplore.ieee.org/document/6126475/},
	doi = {10.1109/ICCV.2011.6126475},
	abstract = {We study the 3D reconstruction of plant roots from multiple 2D images. To meet the challenge caused by the delicate nature of thin branches, we make three innovations to cope with the sensitivity to image quality and calibration. First, we model the background as a harmonic function to improve the segmentation of the root in each 2D image. Second, we develop the concept of the regularized visual hull which reduces the effect of jittering and refraction by ensuring consistency with one 2D image. Third, we guarantee connectedness through adjustments to the 3D reconstruction that minimize global error. Our software is part of a biological phenotype/genotype study of agricultural root systems. It has been tested on more than 40 plant roots and results are promising in terms of reconstruction quality and efﬁciency. Figure 1. Plant root imaging system.},
	language = {en},
	urldate = {2019-07-10},
	booktitle = {2011 {International} {Conference} on {Computer} {Vision}},
	publisher = {IEEE},
	author = {{Ying Zheng} and Gu, Steve and Edelsbrunner, Herbert and Tomasi, Carlo and Benfey, Philip},
	month = nov,
	year = {2011},
	pages = {2026--2033},
	file = {Ying Zheng et al. - 2011 - Detailed reconstruction of 3D plant root shape.pdf:C\:\\Users\\alien\\Zotero\\storage\\RPYGITC9\\Ying Zheng et al. - 2011 - Detailed reconstruction of 3D plant root shape.pdf:application/pdf}
}



@inproceedings{quan_image-based_2006,
	address = {Boston, Massachusetts},
	title = {Image-based plant modeling},
	isbn = {978-1-59593-364-5},
	url = {http://portal.acm.org/citation.cfm?doid=1179352.1141929},
	doi = {10.1145/1179352.1141929},
	abstract = {In this paper, we propose a semi-automatic technique for modeling plants directly from images. Our image-based approach has the distinct advantage that the resulting model inherits the realistic shape and complexity of a real plant. We designed our modeling system to be interactive, automating the process of shape recovery while relying on the user to provide simple hints on segmentation. Segmentation is performed in both image and 3D spaces, allowing the user to easily visualize its effect immediately. Using the segmented image and 3D data, the geometry of each leaf is then automatically recovered from the multiple views by ﬁtting a deformable leaf model. Our system also allows the user to easily reconstruct branches in a similar manner. We show realistic reconstructions of a variety of plants, and demonstrate examples of plant editing.},
	language = {en},
	urldate = {2019-07-10},
	booktitle = {{ACM} {SIGGRAPH} 2006 {Papers} on   - {SIGGRAPH} '06},
	publisher = {ACM Press},
	author = {Quan, Long and Tan, Ping and Zeng, Gang and Yuan, Lu and Wang, Jingdong and Kang, Sing Bing},
	year = {2006},
	pages = {599},
	file = {Quan et al. - 2006 - Image-based plant modeling.pdf:C\:\\Users\\alien\\Zotero\\storage\\QTJNTCBE\\Quan et al. - 2006 - Image-based plant modeling.pdf:application/pdf}
}

@article{paproki_novel_2012,
	title = {A novel mesh processing based technique for {3D} plant analysis},
	volume = {12},
	issn = {1471-2229},
	url = {https://doi.org/10.1186/1471-2229-12-63},
	doi = {10.1186/1471-2229-12-63},
	abstract = {In recent years, imaging based, automated, non-invasive, and non-destructive high-throughput plant phenotyping platforms have become popular tools for plant biology, underpinning the field of plant phenomics. Such platforms acquire and record large amounts of raw data that must be accurately and robustly calibrated, reconstructed, and analysed, requiring the development of sophisticated image understanding and quantification algorithms. The raw data can be processed in different ways, and the past few years have seen the emergence of two main approaches: 2D image processing and 3D mesh processing algorithms. Direct image quantification methods (usually 2D) dominate the current literature due to comparative simplicity. However, 3D mesh analysis provides the tremendous potential to accurately estimate specific morphological features cross-sectionally and monitor them over-time.},
	number = {1},
	urldate = {2019-07-10},
	journal = {BMC Plant Biology},
	author = {Paproki, Anthony and Sirault, Xavier and Berry, Scott and Furbank, Robert and Fripp, Jurgen},
	month = may,
	year = {2012},
	pages = {63},
	file = {Full Text PDF:C\:\\Users\\alien\\Zotero\\storage\\KEQINKZ2\\Paproki et al. - 2012 - A novel mesh processing based technique for 3D pla.pdf:application/pdf;Snapshot:C\:\\Users\\alien\\Zotero\\storage\\U6VXFU5I\\1471-2229-12-63.html:text/html}
}

@article{fang_3d_2009,
	title = {{3D} reconstruction and dynamic modeling of root architecture in situ and its application to crop phosphorus research},
	abstract = {Root architecture plays important roles in plant water and nutrient acquisition. However, accurate modeling of the root system that provides a realistic representation of roots in the soil is limited by a lack of appropriate tools for the non-destructive and precise measurement of the root system architecture in situ. Here we describe a root growth system in which the roots grow in a solid gel matrix that was used to reconstruct 3D root architecture in situ and dynamically simulate its changes under various nutrient conditions with a high degree of precision. A 3D laser scanner combined with a transparent gel-based growth system was used to capture 3D images of roots. The root system skeleton was extracted using a skeleton extraction method based on the Hough transformation, and mesh modeling using Ball-B spline was employed. We successfully used this system to reconstruct rice and soybean root architectures and determine their changes under various phosphorus (P) supply conditions. Our results showed that the 3D root architecture parameters that were dynamically calculated based on the skeletonization and simulation of root systems were signiﬁcantly correlated with the biomass and P content of rice and soybean based on both the simulation system and previous reports. Therefore, this approach provides a novel technique for the study of crop root growth and its adaptive changes to various environmental conditions.},
	language = {en},
	journal = {The Plant Journal},
	author = {Fang, Suqin and Yan, Xiaolong and Liao, Hong},
	year = {2009},
	pages = {13},
	file = {Fang et al. - 2009 - 3D reconstruction and dynamic modeling of root arc.pdf:C\:\\Users\\alien\\Zotero\\storage\\VARLBVGZ\\Fang et al. - 2009 - 3D reconstruction and dynamic modeling of root arc.pdf:application/pdf}
}

@article{sonohat_three-dimensional_2006,
	title = {Three-dimensional reconstruction of partially {3D}-digitized peach tree canopies},
	volume = {26},
	issn = {0829-318X, 1758-4469},
	url = {https://academic.oup.com/treephys/article-lookup/doi/10.1093/treephys/26.3.337},
	doi = {10.1093/treephys/26.3.337},
	abstract = {A simplified method for building three-dimensional (3D) mock-ups of peach trees is presented. The method combines partial digitizing of tree structure with reconstruction rules for non-digitized organs. Reconstruction was applied at two scales: leaves on current-year shoots (CYS) and shoots on 1-year-old shoots (OYOS). Reconstruction rules make use of allometric relationships, random sampling of shoot attribute distribution and additional hypotheses (e.g., constant internode length). The method was quantitatively assessed for two training systems (tight goblet and wide-double-Y), at a range of spatial scales. For this purpose, light interception properties of reference and reconstructed mock-ups were compared. Mockup quality depended on scale. Foliage reconstruction on CYS was unsuitable for generating a given CYS. Similarly, CYS reconstruction on OYOS was unsuitable for generating a given OYOS. This is because generic rules derived at the population scale do not consider specific foliage or shoot attributes of a given CYS or OYOS. In contrast, foliage reconstruction on CYS was able to generate OYOS mock-ups having light properties similar to the reference mock-ups. The same held for CYS reconstruction on OYOS for light capture properties at the tree scale. The CYS reconstruction on OYOS was also suitable for deriving OYOS distribution as a function of light interception ability. Reconstruction rules were successfully used to build the vegetation neighborhood of a reference shoot. The proposed method could therefore be used to make 3D tree mock-ups usable for a range of some, but not all, light computations. Because the simplified method allows large time savings, it could be used in virtual experiments requiring large numbers of replicates, such as comparative studies of tree genotypes or training systems.},
	language = {en},
	number = {3},
	urldate = {2019-07-10},
	journal = {Tree Physiology},
	author = {Sonohat, G. and Sinoquet, H. and Kulandaivelu, V. and Combes, D. and Lescourret, F.},
	month = mar,
	year = {2006},
	pages = {337--351},
	file = {Sonohat et al. - 2006 - Three-dimensional reconstruction of partially 3D-d.pdf:C\:\\Users\\alien\\Zotero\\storage\\RQLFZGVY\\Sonohat et al. - 2006 - Three-dimensional reconstruction of partially 3D-d.pdf:application/pdf}
}

@article{santos_automatic_nodate,
	title = {Automatic {3D} plant reconstruction from photographies, segmentation and classification of leaves and internodes using clustering},
	language = {en},
	author = {Santos, Thiago and Ueda, Julio},
	pages = {3},
	file = {Santos et Ueda - Automatic 3D plant reconstruction from photographi.pdf:C\:\\Users\\alien\\Zotero\\storage\\FWW5VE5Q\\Santos et Ueda - Automatic 3D plant reconstruction from photographi.pdf:application/pdf}
}

@inproceedings{paproki_automated_2011,
	address = {Noosa, QLD, Australia},
	title = {Automated {3D} {Segmentation} and {Analysis} of {Cotton} {Plants}},
	isbn = {978-1-4577-2006-2 978-0-7695-4588-2},
	url = {http://ieeexplore.ieee.org/document/6128719/},
	doi = {10.1109/DICTA.2011.99},
	abstract = {One of the main challenges in high-throughput plant data acquisition is the robust and automated analysis of the data. This includes a high-resolution 3D plant model reconstruction and an automated 3D segmentation. In this paper we present our top-down partitioning pipeline used to automatically segment high-resolution plant meshes. The proposed method produces a smart partition of the initial mesh that allows to identify the main stem, branches, and leaves of the plant. Extracted regions are then processed through the next stage of the automated analysis, which retrieves accurate plant information such as stem length, leaf width, length or area. Results involved applying our topdown approach on a prototype population of 6 cotton-plant meshes studied at 3 or 4 time points. Using our partitioning pipeline, we obtained accurate meshes segmentations for 20 plants out of the initial 22. Results validate the feasibility of an automated analysis of plant data. Future work will involve extending our approach to multiple plant varieties and using an atlas-based iterative feedback scheme to improve the 3D plant reconstruction.},
	language = {en},
	urldate = {2019-07-10},
	booktitle = {2011 {International} {Conference} on {Digital} {Image} {Computing}: {Techniques} and {Applications}},
	publisher = {IEEE},
	author = {Paproki, Anthony and Fripp, Jurgen and Salvado, Olivier and Sirault, Xavier and Berry, Scott and Furbank, Robert},
	month = dec,
	year = {2011},
	pages = {555--560},
	file = {Paproki et al. - 2011 - Automated 3D Segmentation and Analysis of Cotton P.pdf:C\:\\Users\\alien\\Zotero\\storage\\KTEPRATI\\Paproki et al. - 2011 - Automated 3D Segmentation and Analysis of Cotton P.pdf:application/pdf}
}

@article{long_fully_nodate,
	title = {Fully {Convolutional} {Networks} for {Semantic} {Segmentation}},
	abstract = {Convolutional networks are powerful visual models that yield hierarchies of features. We show that convolutional networks by themselves, trained end-to-end, pixelsto-pixels, exceed the state-of-the-art in semantic segmentation. Our key insight is to build “fully convolutional” networks that take input of arbitrary size and produce correspondingly-sized output with efﬁcient inference and learning. We deﬁne and detail the space of fully convolutional networks, explain their application to spatially dense prediction tasks, and draw connections to prior models. We adapt contemporary classiﬁcation networks (AlexNet [22], the VGG net [34], and GoogLeNet [35]) into fully convolutional networks and transfer their learned representations by ﬁne-tuning [5] to the segmentation task. We then deﬁne a skip architecture that combines semantic information from a deep, coarse layer with appearance information from a shallow, ﬁne layer to produce accurate and detailed segmentations. Our fully convolutional network achieves stateof-the-art segmentation of PASCAL VOC (20\% relative improvement to 62.2\% mean IU on 2012), NYUDv2, and SIFT Flow, while inference takes less than one ﬁfth of a second for a typical image.},
	language = {en},
	author = {Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
	pages = {10},
	file = {Long et al. - Fully Convolutional Networks for Semantic Segmenta.pdf:C\:\\Users\\alien\\Zotero\\storage\\383S83CH\\Long et al. - Fully Convolutional Networks for Semantic Segmenta.pdf:application/pdf}
}

@misc{noauthor_christophe_2019,
	title = {Christophe {\textbar} {ROMI} {Slack}},
	url = {https://ro-mi.slack.com/messages/DLD96L98R/?},
	urldate = {2019-07-19},
	month = jul,
	year = {2019},
	file = {Christophe | ROMI Slack:C\:\\Users\\alien\\Zotero\\storage\\UGAM4CBP\\DLD96L98R.html:text/html}
}

@article{boudon_l-py:_2012,
	title = {L-{Py}: {An} {L}-{System} {Simulation} {Framework} for {Modeling} {Plant} {Architecture} {Development} {Based} on a {Dynamic} {Language}},
	volume = {3},
	issn = {1664-462X},
	shorttitle = {L-{Py}},
	url = {https://www.frontiersin.org/articles/10.3389/fpls.2012.00076/full},
	doi = {10.3389/fpls.2012.00076},
	abstract = {The study of plant development requires increasingly powerful modeling tools to help understand and simulate the growth and functioning of plants. In the last decade, the formalism of L-systems has emerged as a major paradigm for modeling plant development. Previous implementations of this formalism were made based on static languages, i.e. languages that require explicit definition of variable types before using them. These languages are often efficient but involve quite a lot of syntactic overhead, thus restricting the flexibility of use for modelers. In this work, we present an adaptation of L-systems to the Python language, a popular and powerful open-license dynamic language. We show that the use of dynamic language properties makes it possible to enhance the development of plant growth models: i) by keeping a simple syntax while allowing for high-level programming constructs, ii) by making code execution easy and avoiding compilation overhead iii) allowing a high level of model reusability and the building of complex modular models iv) and by providing powerful solutions to integrate MTG data-structures (that are a common way to represent plants at several scales) into L-systems and thus enabling to use a wide spectrum of computer tools based on MTGs developed for plant architecture. We then illustrate the use of L-Py in real applications to build complex models or to teach plant modeling in the classroom.},
	language = {English},
	urldate = {2019-07-19},
	journal = {Frontiers in Plant Science},
	author = {Boudon, Frederic and Pradal, Christophe and Cokelaer, Thomas and Prusinkiewicz, Przemyslaw and Godin, Christophe},
	year = {2012},
	keywords = {Design patterns, development, Functional Structural Plant Models, modularity, Multi-scale Tree Graphs, Plant modeling, python, virtual plants},
	file = {Full Text PDF:C\:\\Users\\alien\\Zotero\\storage\\D3ITQLNY\\Boudon et al. - 2012 - L-Py An L-System Simulation Framework for Modelin.pdf:application/pdf}
}

@article{mayer_large_2016,
	title = {A {Large} {Dataset} to {Train} {Convolutional} {Networks} for {Disparity}, {Optical} {Flow}, and {Scene} {Flow} {Estimation}},
	url = {http://arxiv.org/abs/1512.02134},
	doi = {10.1109/CVPR.2016.438},
	abstract = {Recent work has shown that optical ﬂow estimation can be formulated as a supervised learning task and can be successfully solved with convolutional networks. Training of the so-called FlowNet was enabled by a large synthetically generated dataset. The present paper extends the concept of optical ﬂow estimation via convolutional networks to disparity and scene ﬂow estimation. To this end, we propose three synthetic stereo video datasets with sufﬁcient realism, variation, and size to successfully train large networks. Our datasets are the ﬁrst large-scale datasets to enable training and evaluating scene ﬂow methods. Besides the datasets, we present a convolutional network for real-time disparity estimation that provides state-of-the-art results. By combining a ﬂow and disparity estimation network and training it jointly, we demonstrate the ﬁrst scene ﬂow estimation with a convolutional network.},
	language = {en},
	urldate = {2019-07-24},
	journal = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	author = {Mayer, Nikolaus and Ilg, Eddy and Häusser, Philip and Fischer, Philipp and Cremers, Daniel and Dosovitskiy, Alexey and Brox, Thomas},
	month = jun,
	year = {2016},
	note = {arXiv: 1512.02134},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Statistics - Machine Learning, Computer Science - Machine Learning, I.2.10, I.2.6, I.4.8},
	pages = {4040--4048},
	annote = {Comment: Includes supplementary material},
	file = {Mayer et al. - 2016 - A Large Dataset to Train Convolutional Networks fo.pdf:C\:\\Users\\alien\\Zotero\\storage\\2WLSVBE9\\Mayer et al. - 2016 - A Large Dataset to Train Convolutional Networks fo.pdf:application/pdf}
}

@article{serna_detection_2014,
	title = {Detection, segmentation and classification of {3D} urban objects using mathematical morphology and supervised learning},
	volume = {93},
	issn = {09242716},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0924271614000872},
	doi = {10.1016/j.isprsjprs.2014.03.015},
	abstract = {In this paper, we propose an automatic and robust approach to detect, segment and classify urban objects from 3D point clouds. Processing is carried out using elevation images, called also digital elevation models, and the ﬁnal result is presented reprojecting the image onto the 3D point cloud. First, the ground is segmented and objects are detected as discontinuities on the ground. Then, connected objects are segmented using a watershed constrained by the signiﬁcant maxima. Finally, objects are classiﬁed in several categories using a support vector machine (SVM) approach with geometrical and contextual features.},
	language = {en},
	urldate = {2019-08-02},
	journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
	author = {Serna, Andrés and Marcotegui, Beatriz},
	month = jul,
	year = {2014},
	pages = {243--255},
	file = {Serna et Marcotegui - 2014 - Detection, segmentation and classification of 3D u.pdf:C\:\\Users\\alien\\Zotero\\storage\\N5AUVGRF\\Serna et Marcotegui - 2014 - Detection, segmentation and classification of 3D u.pdf:application/pdf}
}

@article{ward_deep_2018,
	title = {Deep {Leaf} {Segmentation} {Using} {Synthetic} {Data}},
	url = {http://arxiv.org/abs/1807.10931},
	abstract = {Automated segmentation of individual leaves of a plant in an image is a prerequisite to measure more complex phenotypic traits in high-throughput phenotyping. Applying state-of-the-art machine learning approaches to tackle leaf instance segmentation requires a large amount of manually annotated training data. Currently, the benchmark datasets for leaf segmentation contain only a few hundred labeled training images. In this paper, we propose a framework for leaf instance segmentation by augmenting real plant datasets with generated synthetic images of plants inspired by domain randomisation. We train a state-of-the-art deep learning segmentation architecture (Mask-RCNN) with a combination of real and synthetic images of Arabidopsis plants. Our proposed approach achieves 90\% leaf segmentation score on the A1 test set outperforming the-state-of-the-art approaches for the CVPPP Leaf Segmentation Challenge (LSC). Our approach also achieves 81\% mean performance over all five test datasets.},
	urldate = {2019-08-05},
	journal = {arXiv:1807.10931 [cs]},
	author = {Ward, Daniel and Moghadam, Peyman and Hudson, Nicolas},
	month = jul,
	year = {2018},
	note = {arXiv: 1807.10931},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: British Machine Vision Conference (BMVC) 2018 Proceedings. CVPPP Workshop at BMVC 2018. Dataset available for download at: https://research.csiro.au/robotics/databases/synthetic-arabidopsis-dataset/},
	file = {arXiv\:1807.10931 PDF:C\:\\Users\\alien\\Zotero\\storage\\RSS8PJPG\\Ward et al. - 2018 - Deep Leaf Segmentation Using Synthetic Data.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\alien\\Zotero\\storage\\DUBW8DD9\\1807.html:text/html}
}

@article{minervini_image-based_2014,
	title = {Image-based plant phenotyping with incremental learning and active contours},
	volume = {23},
	issn = {15749541},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1574954113000691},
	doi = {10.1016/j.ecoinf.2013.07.004},
	language = {en},
	urldate = {2019-08-06},
	journal = {Ecological Informatics},
	author = {Minervini, Massimo and Abdelsamea, Mohammed M. and Tsaftaris, Sotirios A.},
	month = sep,
	year = {2014},
	pages = {35--48},
	file = {Texte intégral:C\:\\Users\\alien\\Zotero\\storage\\H8MVN2LJ\\Minervini et al. - 2014 - Image-based plant phenotyping with incremental lea.pdf:application/pdf}
}

@article{puri_agriculture_2017,
	title = {Agriculture drones: {A} modern breakthrough in precision agriculture},
	volume = {20},
	issn = {0972-0510, 2169-0014},
	shorttitle = {Agriculture drones},
	url = {https://www.tandfonline.com/doi/full/10.1080/09720510.2017.1395171},
	doi = {10.1080/09720510.2017.1395171},
	abstract = {Drones commonly referred, as UAVs are mostly associated with military, industry and other specialized operations but with recent developments in area of sensors and Information Technology in last two decades the scope of drones has been widened to other areas like Agriculture. The drones manufactured these days are becoming smarter by integrating open source technology, smart sensors, better integration, more flight time, tracking down criminals, detecting forest and other disaster areas. The aim of this research paper is to highlight the importance of drones in agriculture and elaborate top drones available in market for Agriculture monitoring and observation for yielding better crop quality and preventing fields from any sort of damage.},
	language = {en},
	number = {4},
	urldate = {2019-08-06},
	journal = {Journal of Statistics and Management Systems},
	author = {Puri, Vikram and Nayyar, Anand and Raja, Linesh},
	month = jul,
	year = {2017},
	pages = {507--518},
	file = {Puri et al. - 2017 - Agriculture drones A modern breakthrough in preci.pdf:C\:\\Users\\alien\\Zotero\\storage\\JPNXDA2N\\Puri et al. - 2017 - Agriculture drones A modern breakthrough in preci.pdf:application/pdf}
}

@article{galvan-ampudia_phyllotaxis:_2016,
	title = {Phyllotaxis: from patterns of organogenesis at the meristem to shoot architecture: {Organogenesis} at the meristem and shoot architecture},
	volume = {5},
	issn = {17597684},
	shorttitle = {Phyllotaxis},
	url = {http://doi.wiley.com/10.1002/wdev.231},
	doi = {10.1002/wdev.231},
	language = {en},
	number = {4},
	urldate = {2019-09-13},
	journal = {Wiley Interdisciplinary Reviews: Developmental Biology},
	author = {Galvan-Ampudia, Carlos S. and Chaumeret, Anaïs M. and Godin, Christophe and Vernoux, Teva},
	month = jul,
	year = {2016},
	pages = {460--473},
	file = {Galvan-Ampudia et al. - 2016 - Phyllotaxis from patterns of organogenesis at the.pdf:C\:\\Users\\alien\\Zotero\\storage\\H282PC8I\\Galvan-Ampudia et al. - 2016 - Phyllotaxis from patterns of organogenesis at the.pdf:application/pdf}
}

@book{hartley_multiple_2015,
	address = {Cambridge},
	edition = {2. ed., 13.pr},
	title = {Multiple view geometry in computer vision},
	isbn = {978-0-521-54051-3},
	language = {en},
	publisher = {Cambridge Univ. Press},
	author = {Hartley, Richard and Zisserman, Andrew},
	year = {2015},
	note = {OCLC: 947203565},
	file = {Hartley et Zisserman - 2015 - Multiple view geometry in computer vision.pdf:C\:\\Users\\alien\\Zotero\\storage\\P6S2KSZQ\\Hartley et Zisserman - 2015 - Multiple view geometry in computer vision.pdf:application/pdf}
}

@article{shaekhani_new_nodate,
	title = {A {New} {4D}-{RGB} {Mapping} {Technique} for {Field}-{Based} {High}-{Throughput} {Phenotyping}},
	abstract = {In this paper, we proposed the use of Infrared Thermography (IRT) along with multiview, visible imaging technology to monitor plants 24/7 and to better understand their behavior in response to different biotic and/or abiotic stresses. The proposed method uses a high-throughput plant phenotyping platform previously developed by the authors: in special an observation tower that collects data throughout the growing season. Stereo RGB and Thermal images are used to create 4D-RGB models of the canopy: i.e. their 3D appearance with temperature and texture information. We evaluate the accuracy of our thermal projection using quantitative and qualitative analysis and the results show high spatial consistency between appearance and temperature. The usefulness of our proposed 4D-RGB point cloud is demonstrated for two test cases: 1) over various days during the growing season; and 2) over various hours throughout the daytime.},
	language = {en},
	author = {Shaﬁekhani, Ali},
	pages = {13},
	file = {Shaﬁekhani - A New 4D-RGB Mapping Technique for Field-Based Hig.pdf:C\:\\Users\\alien\\Zotero\\storage\\WHUVDZEC\\Shaﬁekhani - A New 4D-RGB Mapping Technique for Field-Based Hig.pdf:application/pdf}
}

@article{wintz_automated_nodate,
	title = {Automated extraction of phyllotactic traits from {Arabidopsis} thaliana},
	language = {en},
	author = {Wintz, Timothée},
	pages = {9},
	file = {Wintz - Automated extraction of phyllotactic traits from A.pdf:C\:\\Users\\alien\\Zotero\\storage\\5XHHITP7\\Wintz - Automated extraction of phyllotactic traits from A.pdf:application/pdf}
}

@misc{yakubovskiy_segmentation-models-pytorch:_nodate,
	title = {segmentation-models-pytorch: {Image} segmentation models with pre-trained backbones. {PyTorch}.},
	copyright = {MIT License},
	shorttitle = {segmentation-models-pytorch},
	url = {https://github.com/qubvel/segmentation_models.pytorch},
	urldate = {2019-09-14},
	author = {Yakubovskiy, Pavel},
	file = {Snapshot:C\:\\Users\\alien\\Zotero\\storage\\ZSNBUKEJ\\segmentation-models-pytorch.html:text/html}
}

@article{hu_squeeze-and-excitation_2017,
	title = {Squeeze-and-{Excitation} {Networks}},
	url = {http://arxiv.org/abs/1709.01507},
	abstract = {The central building block of convolutional neural networks (CNNs) is the convolution operator, which enables networks to construct informative features by fusing both spatial and channel-wise information within local receptive fields at each layer. A broad range of prior research has investigated the spatial component of this relationship, seeking to strengthen the representational power of a CNN by enhancing the quality of spatial encodings throughout its feature hierarchy. In this work, we focus instead on the channel relationship and propose a novel architectural unit, which we term the "Squeeze-and-Excitation" (SE) block, that adaptively recalibrates channel-wise feature responses by explicitly modelling interdependencies between channels. We show that these blocks can be stacked together to form SENet architectures that generalise extremely effectively across different datasets. We further demonstrate that SE blocks bring significant improvements in performance for existing state-of-the-art CNNs at slight additional computational cost. Squeeze-and-Excitation Networks formed the foundation of our ILSVRC 2017 classification submission which won first place and reduced the top-5 error to 2.251\%, surpassing the winning entry of 2016 by a relative improvement of {\textasciitilde}25\%. Models and code are available at https://github.com/hujie-frank/SENet.},
	urldate = {2019-09-14},
	journal = {arXiv:1709.01507 [cs]},
	author = {Hu, Jie and Shen, Li and Albanie, Samuel and Sun, Gang and Wu, Enhua},
	month = sep,
	year = {2017},
	note = {arXiv: 1709.01507},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: journal version of the CVPR 2018 paper, accepted by TPAMI},
	file = {arXiv\:1709.01507 PDF:C\:\\Users\\alien\\Zotero\\storage\\XSDZJF7Z\\Hu et al. - 2017 - Squeeze-and-Excitation Networks.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\alien\\Zotero\\storage\\FDAG92DV\\1709.html:text/html}
}

@article{huang_densely_2016,
	title = {Densely {Connected} {Convolutional} {Networks}},
	url = {http://arxiv.org/abs/1608.06993},
	abstract = {Recent work has shown that convolutional networks can be substantially deeper, more accurate, and efficient to train if they contain shorter connections between layers close to the input and those close to the output. In this paper, we embrace this observation and introduce the Dense Convolutional Network (DenseNet), which connects each layer to every other layer in a feed-forward fashion. Whereas traditional convolutional networks with L layers have L connections - one between each layer and its subsequent layer - our network has L(L+1)/2 direct connections. For each layer, the feature-maps of all preceding layers are used as inputs, and its own feature-maps are used as inputs into all subsequent layers. DenseNets have several compelling advantages: they alleviate the vanishing-gradient problem, strengthen feature propagation, encourage feature reuse, and substantially reduce the number of parameters. We evaluate our proposed architecture on four highly competitive object recognition benchmark tasks (CIFAR-10, CIFAR-100, SVHN, and ImageNet). DenseNets obtain significant improvements over the state-of-the-art on most of them, whilst requiring less computation to achieve high performance. Code and pre-trained models are available at https://github.com/liuzhuang13/DenseNet .},
	urldate = {2019-09-14},
	journal = {arXiv:1608.06993 [cs]},
	author = {Huang, Gao and Liu, Zhuang and van der Maaten, Laurens and Weinberger, Kilian Q.},
	month = aug,
	year = {2016},
	note = {arXiv: 1608.06993},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
	annote = {Comment: CVPR 2017},
	file = {arXiv\:1608.06993 PDF:C\:\\Users\\alien\\Zotero\\storage\\8R2V55VH\\Huang et al. - 2016 - Densely Connected Convolutional Networks.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\alien\\Zotero\\storage\\9KW7SKAV\\1608.html:text/html}
}

@inproceedings{szegedy_going_2015,
	address = {Boston, MA, USA},
	title = {Going deeper with convolutions},
	isbn = {978-1-4673-6964-0},
	url = {http://ieeexplore.ieee.org/document/7298594/},
	doi = {10.1109/CVPR.2015.7298594},
	abstract = {We propose a deep convolutional neural network architecture codenamed Inception that achieves the new state of the art for classiﬁcation and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC14). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. By a carefully crafted design, we increased the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation used in our submission for ILSVRC14 is called GoogLeNet, a 22 layers deep network, the quality of which is assessed in the context of classiﬁcation and detection.},
	language = {en},
	urldate = {2019-09-14},
	booktitle = {2015 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Szegedy, Christian and {Wei Liu} and {Yangqing Jia} and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
	month = jun,
	year = {2015},
	pages = {1--9},
	file = {Szegedy et al. - 2015 - Going deeper with convolutions.pdf:C\:\\Users\\alien\\Zotero\\storage\\Y7TFPM3I\\Szegedy et al. - 2015 - Going deeper with convolutions.pdf:application/pdf}
}

@article{simonyan_very_2014,
	title = {Very {Deep} {Convolutional} {Networks} for {Large}-{Scale} {Image} {Recognition}},
	url = {http://arxiv.org/abs/1409.1556},
	abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
	urldate = {2019-09-14},
	journal = {arXiv:1409.1556 [cs]},
	author = {Simonyan, Karen and Zisserman, Andrew},
	month = sep,
	year = {2014},
	note = {arXiv: 1409.1556},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv\:1409.1556 PDF:C\:\\Users\\alien\\Zotero\\storage\\EM36ZJ34\\Simonyan et Zisserman - 2014 - Very Deep Convolutional Networks for Large-Scale I.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\alien\\Zotero\\storage\\KKEJ8656\\1409.html:text/html}
}

@inproceedings{schonberger_structure--motion_2016,
	address = {Las Vegas, NV, USA},
	title = {Structure-from-{Motion} {Revisited}},
	isbn = {978-1-4673-8851-1},
	url = {http://ieeexplore.ieee.org/document/7780814/},
	doi = {10.1109/CVPR.2016.445},
	abstract = {Incremental Structure-from-Motion is a prevalent strategy for 3D reconstruction from unordered image collections. While incremental reconstruction systems have tremendously advanced in all regards, robustness, accuracy, completeness, and scalability remain the key problems towards building a truly general-purpose pipeline. We propose a new SfM technique that improves upon the state of the art to make a further step towards this ultimate goal. The full reconstruction pipeline is released to the public as an open-source implementation.},
	language = {en},
	urldate = {2019-09-14},
	booktitle = {2016 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Schonberger, Johannes L. and Frahm, Jan-Michael},
	month = jun,
	year = {2016},
	pages = {4104--4113},
	file = {Schonberger et Frahm - 2016 - Structure-from-Motion Revisited.pdf:C\:\\Users\\alien\\Zotero\\storage\\PJL9GIT8\\Schonberger et Frahm - 2016 - Structure-from-Motion Revisited.pdf:application/pdf}
}

@article{frederic_multiscale_nodate,
	title = {Multiscale geometric representation of heterogeneous stands},
	abstract = {The aim of this talk is to present a general geometric model for plant representation that considers diﬀerent plant perceptions at diﬀerent levels of organization (or scales). This model is based on a representation of plant topology that integrates several scales within a single framework. This model, called Multiscale Tree Graph (MTG), can be seen as a set of recursively nested graph, representing diﬀerent levels of topological organisation. Each entity of a MTG, at any scale, can be augmented with a geometric model. Several geometric representations of the plant can thus be computed, depending on the scale considered to represent geometry. Since these models are geometric representations of the same real object at diﬀerent scales, they must be consistent with one another. To ensure model deﬁnition consistency, within-scale and between-scale constraints are introduced. This constraints enable ﬂexible management of "multiscale geometric models".},
	language = {en},
	author = {Frédéric, Boudon and Christophe, Nouguier and Christophe, Godin},
	pages = {1},
	file = {Frédéric et al. - Multiscale geometric representation of heterogeneo.pdf:C\:\\Users\\alien\\Zotero\\storage\\WUG367CZ\\Frédéric et al. - Multiscale geometric representation of heterogeneo.pdf:application/pdf}
}

@article{godin_method_1999,
	title = {A {Method} for {Describing} {Plant} {Architecture} which {Integrates} {Topology} and {Geometry}},
	volume = {84},
	issn = {03057364},
	url = {https://academic.oup.com/aob/article-lookup/doi/10.1006/anbo.1999.0923},
	doi = {10.1006/anbo.1999.0923},
	language = {en},
	number = {3},
	urldate = {2019-09-14},
	journal = {Annals of Botany},
	author = {Godin, C},
	month = sep,
	year = {1999},
	pages = {343--357},
	file = {Godin - 1999 - A Method for Describing Plant Architecture which I.pdf:C\:\\Users\\alien\\Zotero\\storage\\SQN7IHQH\\Godin - 1999 - A Method for Describing Plant Architecture which I.pdf:application/pdf}
}

@article{ghozlen_non-destructive_2010,
	title = {Non-{Destructive} {Optical} {Monitoring} of {Grape} {Maturation} by {Proximal} {Sensing}},
	volume = {10},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/1424-8220/10/11/10040},
	doi = {10.3390/s101110040},
	abstract = {A new, commercial, fluorescence-based optical sensor for plant constituent assessment was recently introduced. This sensor, called the Multiplex® (FORCE-A, Orsay, France), was used to monitor grape maturation by specifically monitoring anthocyanin accumulation. We derived the empirical anthocyanin content calibration curves for Champagne red grape cultivars, and we also propose a general model for the influence of the proportion of red berries, skin anthocyanin content and berry size on Multiplex® indices. The Multiplex® was used on both berry samples in the laboratory and on intact clusters in the vineyard. We found that the inverted and log-transformed far-red fluorescence signal called the FERARI index, although sensitive to sample size and distance, is potentially the most widely applicable. The more robust indices, based on chlorophyll fluorescence excitation ratios, showed three ranges of dependence on anthocyanin content. We found that up to 0.16 mg cm−2, equivalent to approximately 0.6 mg g−1, all indices increase with accumulation of skin anthocyanin content. Excitation ratio-based indices decrease with anthocyanin accumulation beyond 0.27 mg cm−2. We showed that the Multiplex® can be advantageously used in vineyards on intact clusters for the non-destructive assessment of anthocyanin content of vine blocks and can now be tested on other fruits and vegetables based on the same model.},
	language = {en},
	number = {11},
	urldate = {2019-09-15},
	journal = {Sensors},
	author = {Ghozlen, Naïma Ben and Cerovic, Zoran G. and Germain, Claire and Toutain, Sandrine and Latouche, Gwendal},
	month = nov,
	year = {2010},
	keywords = {anthocyanins, Chardonnay, chlorophyll fluorescence, fruits, phenolic maturity, Pinot Meunier, Pinot Noir, ripening, vegetables},
	pages = {10040--10068},
	file = {Full Text PDF:C\:\\Users\\alien\\Zotero\\storage\\FWQJ5QE5\\Ghozlen et al. - 2010 - Non-Destructive Optical Monitoring of Grape Matura.pdf:application/pdf;Snapshot:C\:\\Users\\alien\\Zotero\\storage\\SB96VCJE\\htm.html:text/html}
}

@misc{noauthor_use_nodate,
	title = {Use of infrared thermography for monitoring stomatal closure in the field: application to grapevine {\textbar} {Journal} of {Experimental} {Botany} {\textbar} {Oxford} {Academic}},
	url = {https://academic.oup.com/jxb/article/53/378/2249/426550},
	urldate = {2019-09-15},
	file = {Use of infrared thermography for monitoring stomatal closure in the field\: application to grapevine | Journal of Experimental Botany | Oxford Academic:C\:\\Users\\alien\\Zotero\\storage\\IXCMRXI7\\426550.html:text/html}
}

@article{gomez_evaluation_2006,
	title = {Evaluation of tomato maturity by electronic nose},
	volume = {54},
	issn = {0168-1699},
	url = {http://www.sciencedirect.com/science/article/pii/S0168169906000743},
	doi = {10.1016/j.compag.2006.07.002},
	abstract = {Over the past years, electronic nose (E-nose) technology opened has enhanced the possibility of exploiting information on behavior aroma to assess fruit ripening stage. The objective in this study was to evaluate the capacity of electronic nose to monitor the change in volatile production of ripeness states for tomato, using a specific electronic nose device with 10 different metal oxide sensors (portable E-nose, PEN 2). Principal component analysis (PCA) and linear discriminant analysis (LDA) were used to investigate whether the electronic nose was able to distinguishing among different ripeness states (unripe, half-ripe, full-ripe and over-ripe). The loadings analysis was used to identify the sensors responsible for discrimination in the current pattern file. The results prove that the electronic nose PEN 2 could differentiate among the ripeness states of tomato. The electronic nose was able to detect a clearer difference in volatile profile of tomato when using LDA analysis than when using PCA analysis. Using LDA analysis, it was possible to differentiate and to classify the different tomato maturity states, and this method was able to classify 100\% of the total samples in each respective group. Some sensors in E-nose have the highest influence in the current pattern file for electronic nose PEN 2. A subset of a few sensors in E-nose can be chosen to explain all the variance. This result could be used in further studies to optimize the number of sensors.},
	number = {1},
	urldate = {2019-09-15},
	journal = {Computers and Electronics in Agriculture},
	author = {Gómez, Antihus Hernández and Hu, Guixian and Wang, Jun and Pereira, Annia García},
	month = oct,
	year = {2006},
	keywords = {Electronic nose, Maturity, Monitoring, Non-destructive method, Tomato},
	pages = {44--52},
	file = {ScienceDirect Snapshot:C\:\\Users\\alien\\Zotero\\storage\\8U46GJKQ\\S0168169906000743.html:text/html}
}

@article{hoffmann_fluorescence_2015,
	title = {Fluorescence indices for monitoring the ripening of tomatoes in pre- and postharvest phases},
	volume = {191},
	issn = {03044238},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S030442381500254X},
	doi = {10.1016/j.scienta.2015.05.001},
	abstract = {Greenhouse and climate chamber experiments were carried out to evaluate the ability of a portable multiparametric ﬂuorescence sensor to monitor the ripening of tomato fruits (cultivar Cappricia) in preand postharvest phases. Fluorescence recordings were validated against established non-invasive optical methods based on reﬂection and remittance and against a visual colour classiﬁcation scheme. Fruit ripening, as inﬂuenced by water supply (pre-harvest) and light quality (postharvest), was monitored by chlorophyll ﬂuorescence indices (red and far-red ﬂuorescence) after red and UV, red and green, or green and UV excitation. Chlorophyll breakdown was indicated by the ﬂuorescence index NBI R, which showed a negative and strong correlation with the reﬂection index a*/b* (R2 = −0.798) and the remittance based stage-index (R2 = −0.754). Characteristic curve patterns of the indices NBI G, FLAV and Anth RG enabled the pink (NBI G, FLAV) and light red (Anth RG) ripening stages to be deﬁned and were well suited to detecting time-shifts in the ripening process. The potential of this technique for improved ripening monitoring and quality attribute determination in tomatoes is discussed.},
	language = {en},
	urldate = {2019-09-15},
	journal = {Scientia Horticulturae},
	author = {Hoffmann, Anna M. and Noga, Georg and Hunsche, Mauricio},
	month = aug,
	year = {2015},
	pages = {74--81},
	file = {Hoffmann et al. - 2015 - Fluorescence indices for monitoring the ripening o.pdf:C\:\\Users\\alien\\Zotero\\storage\\IUWXD425\\Hoffmann et al. - 2015 - Fluorescence indices for monitoring the ripening o.pdf:application/pdf}
}

@article{padilla_threshold_2015,
	title = {Threshold values of canopy reflectance indices and chlorophyll meter readings for optimal nitrogen nutrition of tomato},
	volume = {166},
	copyright = {© 2014 Association of Applied Biologists},
	issn = {1744-7348},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/aab.12181},
	doi = {10.1111/aab.12181},
	abstract = {Sustainable and optimal economic N management requires correct and timely on-farm assessment of crop N status to detect N deficiency or excess. Optical sensors are promising tools to assess crop N status throughout a crop or at critical times. The ability of optical sensor measurements of canopy reflectance (Crop Circle ACS 470) and leaf chlorophyll (SPAD 502 chlorophyll meter) to assess crop N status was evaluated weekly throughout an indeterminate tomato crop. Strong linear relationships with the optical sensor measurements were obtained, throughout most of the crop, for both (a) crop N content for ranges of 1.5–4.5\%, and (b) the nitrogen nutrition index (NNI) for ranges of 0.4–1.3. The relationships of the optical sensor measurements to crop NNI were generally equal to or slightly better than with crop N content. Indices based on reflectance in the red, the normalised difference vegetation index (NDVI) and the red vegetation index (RVI), were the best predictors of crop N status in terms of goodness of fit, earliness and maintenance of relationships throughout the crop. SPAD chlorophyll readings and reflectance indices based on reflectance in the green, the normalised difference vegetation index on greenness (GNDVI) and the green vegetation index (GVI), were good indicators of crop N status for most of the crop, but with lower goodness of fit in the latter part of the crop. The linear relationships between sensor indices and readings with NNI or crop N content, each week, demonstrated the potential for using proximal canopy reflectance indices such as NDVI and RVI, and chlorophyll meter for monitoring crop N status of indeterminate tomato crops. Threshold values for optimal crop N nutrition for canopy reflectance indices and for chlorophyll meter readings were derived for each day of measurement from the relationships between optical sensor measurements and NNI by solving for NNI = 1. The threshold values obtained for each index and type of measurement varied during the crop cycle. The approach developed for determining threshold values from NNI can facilitate on-farm use of optical sensors for monitoring crop N status, by enabling assessment of whether crop N status is excessive, deficient or adequate.},
	language = {en},
	number = {2},
	urldate = {2019-09-15},
	journal = {Annals of Applied Biology},
	author = {Padilla, F. M. and Peña‐Fleitas, M. T. and Gallardo, M. and Thompson, R. B.},
	year = {2015},
	keywords = {Critical nitrogen curve, horticulture, nitrogen nutrition index, NNI, proximal optical sensors, vegetable production, vegetation index},
	pages = {271--285},
	file = {Snapshot:C\:\\Users\\alien\\Zotero\\storage\\XMTRG3JQ\\aab.html:text/html}
}

@inproceedings{yin_ripe_2009,
	title = {Ripe {Tomato} {Recognition} and {Localization} for a {Tomato} {Harvesting} {Robotic} {System}},
	doi = {10.1109/SoCPaR.2009.111},
	abstract = {A ripe tomato recognition and localization system for tomato harvesting robotic systems in greenhouse is developed. The ripe tomato is segmented by K-means clustering using the L*a*b* color space. To extract a single ripe tomato, mathematical morphology is used to denoise and handle the situations of tomato overlapping and sheltering. Tomato's shape features are combined with the color features to recognize ripe tomatoes. The difference value between the centroid coordinate and the center coordinate of image is used to control the robot arm to aim the tomato center. The turned angles of the robot arm are recorded. The distance between the tomato and robot arm is measured by a laser sensor. With the turned angles and the distance, the tomato's 3D coordinate is calculated under the spherical coordinate system. Experimental results show the effectiveness of the proposed method.},
	booktitle = {2009 {International} {Conference} of {Soft} {Computing} and {Pattern} {Recognition}},
	author = {Yin, H. and Chai, Y. and Yang, S. X. and Mittal, G. S.},
	month = dec,
	year = {2009},
	keywords = {mathematical morphology, agricultural machinery, agricultural products, color space, Computer applications, Constraint optimization, Containers, Design optimization, Integer linear programming, k-means clustering, L*a*b* color space, Laboratories, laser sensor, manipulators, object recognition, path planning, pattern clustering, Pattern recognition, Printing, ripe tomato localization, ripe tomato recognition, robot arm, Robots, spherical coordinate system, Testing, tomato harvesting, tomato harvesting robotic system, tomato localization, tomato overlapping, Tomato recognition, tomato sheltering},
	pages = {557--562},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\alien\\Zotero\\storage\\IBLEZJB4\\5370087.html:text/html}
}

@article{paulus_low-cost_2014,
	title = {Low-{Cost} {3D} {Systems}: {Suitable} {Tools} for {Plant} {Phenotyping}},
	volume = {14},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	shorttitle = {Low-{Cost} {3D} {Systems}},
	url = {https://www.mdpi.com/1424-8220/14/2/3001},
	doi = {10.3390/s140203001},
	abstract = {Over the last few years, 3D imaging of plant geometry has become of significant importance for phenotyping and plant breeding. Several sensing techniques, like 3D reconstruction from multiple images and laser scanning, are the methods of choice in different research projects. The use of RGBcameras for 3D reconstruction requires a significant amount of post-processing, whereas in this context, laser scanning needs huge investment costs. The aim of the present study is a comparison between two current 3D imaging low-cost systems and a high precision close-up laser scanner as a reference method. As low-cost systems, the David laser scanning system and the Microsoft Kinect Device were used. The 3D measuring accuracy of both low-cost sensors was estimated based on the deviations of test specimens. Parameters extracted from the volumetric shape of sugar beet taproots, the leaves of sugar beets and the shape of wheat ears were evaluated. These parameters are compared regarding accuracy and correlation to reference measurements. The evaluation scenarios were chosen with respect to recorded plant parameters in current phenotyping projects. In the present study, low-cost 3D imaging devices have been shown to be highly reliable for the demands of plant phenotyping, with the potential to be implemented in automated application procedures, while saving acquisition costs. Our study confirms that a carefully selected low-cost sensor},
	language = {en},
	number = {2},
	urldate = {2019-09-15},
	journal = {Sensors},
	author = {Paulus, Stefan and Behmann, Jan and Mahlein, Anne-Katrin and Plümer, Lutz and Kuhlmann, Heiner},
	month = feb,
	year = {2014},
	keywords = {3D imaging, close-up scanning, David laser scanning system, low-cost sensors, Microsoft Kinect, parameterization},
	pages = {3001--3018},
	file = {Full Text PDF:C\:\\Users\\alien\\Zotero\\storage\\VYG98W9G\\Paulus et al. - 2014 - Low-Cost 3D Systems Suitable Tools for Plant Phen.pdf:application/pdf;Snapshot:C\:\\Users\\alien\\Zotero\\storage\\EYHYQTCK\\htm.html:text/html}
}

@article{vadez_leasyscan:_2015,
	title = {{LeasyScan}: a novel concept combining {3D} imaging and lysimetry for high-throughput phenotyping of traits controlling plant water budget},
	volume = {66},
	issn = {0022-0957},
	shorttitle = {{LeasyScan}},
	url = {https://academic.oup.com/jxb/article/66/18/5581/481475},
	doi = {10.1093/jxb/erv251},
	abstract = {Highlight.  We present a new concept combining novel 3D scanning of the plant canopy with seamless assessment of plant water use to measure plant traits influen},
	language = {en},
	number = {18},
	urldate = {2019-09-15},
	journal = {Journal of Experimental Botany},
	author = {Vadez, Vincent and Kholová, Jana and Hummel, Grégoire and Zhokhavets, Uladzimir and Gupta, S. K. and Hash, C. Tom},
	month = sep,
	year = {2015},
	pages = {5581--5593},
	file = {Full Text PDF:C\:\\Users\\alien\\Zotero\\storage\\SYFC742W\\Vadez et al. - 2015 - LeasyScan a novel concept combining 3D imaging an.pdf:application/pdf}
}

@article{omasa_3d_2007,
	title = {{3D} lidar imaging for detecting and understanding plant responses and canopy structure},
	volume = {58},
	issn = {0022-0957},
	url = {https://academic.oup.com/jxb/article/58/4/881/425236},
	doi = {10.1093/jxb/erl142},
	abstract = {Abstract.  Understanding and diagnosing plant responses to stress will benefit greatly from three-dimensional (3D) measurement and analysis of plant properties},
	language = {en},
	number = {4},
	urldate = {2019-09-15},
	journal = {Journal of Experimental Botany},
	author = {Omasa, Kenji and Hosoi, Fumiki and Konishi, Atsumi},
	month = mar,
	year = {2007},
	pages = {881--898},
	file = {Full Text PDF:C\:\\Users\\alien\\Zotero\\storage\\FYX8WQM2\\Omasa et al. - 2007 - 3D lidar imaging for detecting and understanding p.pdf:application/pdf;Snapshot:C\:\\Users\\alien\\Zotero\\storage\\GJPKNWFC\\425236.html:text/html}
}

@article{shi_automatic_2013,
	title = {Automatic corn plant location and spacing measurement using laser line-scan technique},
	volume = {14},
	issn = {1385-2256, 1573-1618},
	url = {http://link.springer.com/10.1007/s11119-013-9311-z},
	doi = {10.1007/s11119-013-9311-z},
	abstract = {Identifying corn plant location and/or spacing is important for predicting yield potential and making decisions for in-season nitrogen application rate. In this study, an automatic corn stalk identiﬁcation system based on a laser line-scan technique was developed to measure stalk locations during corn mid-growth stages. A laser line-scan technique is advantageous in this application because the line-scan data sets taken from various points of view of a plant stalk results in less interference and higher probability of plant recognition. Data were collected for two 10-meter-long corn rows at the growth stages of V8 and V10 using a mobile test platform in 2011. Each potential stalk cluster was identiﬁed in a scan and registered with the same stalks in previous scans. The ﬁnal location of a stalk was the average of the measured locations in all scans. The current system setup with data processing algorithms achieved 24.0 and 10.0 \% of mean total errors in plant counting at the V8 and V10 growth stages, respectively. The root-mean-squared error (RMSE) between system measured plant locations and manually measured ones were 2.3 and 2.6 cm at the V8 and V10 growth stages, respectively. The interplant spacing measured by the developed system had a good correlation with the manual measurement with an R2 of 0.962 and 0.951 for the V8 and V10 growth stages, respectively. This system can be ultimately integrated in a variable-rate-spraying system to improve real-time, high spatial resolution variable-rate nitrogen applications.},
	language = {en},
	number = {5},
	urldate = {2019-09-15},
	journal = {Precision Agriculture},
	author = {Shi, Yeyin and Wang, Ning and Taylor, Randal K. and Raun, William R. and Hardin, James A.},
	month = oct,
	year = {2013},
	pages = {478--494},
	file = {Shi et al. - 2013 - Automatic corn plant location and spacing measurem.pdf:C\:\\Users\\alien\\Zotero\\storage\\KW9AJEVK\\Shi et al. - 2013 - Automatic corn plant location and spacing measurem.pdf:application/pdf}
}

@article{azzari_rapid_2013,
	title = {Rapid {Characterization} of {Vegetation} {Structure} with a {Microsoft} {Kinect} {Sensor}},
	volume = {13},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/1424-8220/13/2/2384},
	doi = {10.3390/s130202384},
	abstract = {The importance of vegetation structure and biomass in controlling land-atmosphere exchange is widely recognized, but measurements of canopy structure are challenging, time consuming, and often rely on destructive methods. The Microsoft Kinect is an infrared sensor designed for video gaming that outputs synchronized color and depth images and that has the potential to allow rapid characterization of vegetation structure. We compared depth images from a Kinect sensor with manual measurements of plant structure and size for two species growing in a California grassland. The depth images agreed well with the horizontal and vertical measurements of plant size made manually. Similarly, the plant volumes calculated with a three-dimensional convex hulls approach was well related to plant biomass. The Kinect showed some limitations for ecological observation associated with a short measurement range and daytime light contamination. Nonetheless, the Kinect’s light weight, fast acquisition time, low power requirement, and cost make it a promising tool for rapid field surveys of canopy structure, especially in small-statured vegetation.},
	language = {en},
	number = {2},
	urldate = {2019-09-15},
	journal = {Sensors},
	author = {Azzari, George and Goulden, Michael L. and Rusu, Radu B.},
	month = feb,
	year = {2013},
	keywords = {Microsoft Kinect, biomass, canopy structure, concave hulls, convex hulls, depth images, field measurements, LIDAR, point clouds, terrestrial ecology},
	pages = {2384--2398},
	file = {Full Text PDF:C\:\\Users\\alien\\Zotero\\storage\\N4QFHTJA\\Azzari et al. - 2013 - Rapid Characterization of Vegetation Structure wit.pdf:application/pdf;Snapshot:C\:\\Users\\alien\\Zotero\\storage\\ICACS4BW\\htm.html:text/html}
}

@article{biskup_stereo_2007-1,
	title = {A stereo imaging system for measuring structural parameters of plant canopies},
	volume = {30},
	issn = {1365-3040},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1365-3040.2007.01702.x},
	doi = {10.1111/j.1365-3040.2007.01702.x},
	abstract = {Plants constantly adapt their leaf orientation in response to fluctuations in the environment, to maintain radiation use efficiency in the face of varying intensity and incidence direction of sunlight. Various methods exist for measuring structural canopy parameters such as leaf angle distribution. However, direct methods tend to be labour-intensive, while indirect methods usually give statistical information on stand level rather than on individual leaves. We present an area-based, binocular stereo system composed of commercially available components that allows three-dimensional reconstruction of small- to medium-sized canopies on the level of single leaves under field conditions. Spatial orientation of single leaves is computed with automated processes using modern, well-established stereo matching and segmentation techniques, which were adapted for the properties of plant canopies, providing high spatial and temporal resolution (angle measurements with an accuracy of approx. ±5° and a maximum sampling rate of three frames per second). The applicability of our approach is demonstrated in three case studies: (1) the dihedral leaflet angle of an individual soybean was tracked to monitor nocturnal and daytime leaf movement showing different frequencies and amplitudes; (2) drought stress was diagnosed in soybean by quantifying changes in the zenith leaflet angle distribution; and (3) the diurnal course of the zenith leaf angle distribution of a closed soybean canopy was measured.},
	language = {en},
	number = {10},
	urldate = {2019-09-15},
	journal = {Plant, Cell \& Environment},
	author = {Biskup, Bernhard and Scharr, Hanno and Schurr, Ulrich and Rascher, Uwe},
	year = {2007},
	keywords = {3D reconstruction, canopy, leaf movement, screening, stereo imaging, systems biology},
	pages = {1299--1308},
	file = {Snapshot:C\:\\Users\\alien\\Zotero\\storage\\88T29RLJ\\j.1365-3040.2007.01702.html:text/html}
}

@article{yan_perspective_nodate,
	title = {Perspective {Transformer} {Nets}: {Learning} {Single}-{View} {3D} {Object} {Reconstruction} without {3D} {Supervision}},
	abstract = {Understanding the 3D world is a fundamental problem in computer vision. However, learning a good representation of 3D objects is still an open problem due to the high dimensionality of the data and many factors of variation involved. In this work, we investigate the task of single-view 3D object reconstruction from a learning agent’s perspective. We formulate the learning process as an interaction between 3D and 2D representations and propose an encoder-decoder network with a novel projection loss deﬁned by the perspective transformation. More importantly, the projection loss enables the unsupervised learning using 2D observation without explicit 3D supervision. We demonstrate the ability of the model in generating 3D volume from a single 2D image with three sets of experiments: (1) learning from single-class objects; (2) learning from multi-class objects and (3) testing on novel object classes. Results show superior performance and better generalization ability for 3D object reconstruction when the projection loss is involved.},
	language = {en},
	author = {Yan, Xinchen and Yang, Jimei and Yumer, Ersin and Guo, Yijie and Lee, Honglak},
	pages = {9},
	file = {Yan et al. - Perspective Transformer Nets Learning Single-View.pdf:C\:\\Users\\alien\\Zotero\\storage\\JFU2CPWL\\Yan et al. - Perspective Transformer Nets Learning Single-View.pdf:application/pdf}
}

@article{eslami_neural_2018,
	title = {Neural scene representation and rendering},
	volume = {360},
	copyright = {Copyright © 2018 The Authors, some rights reserved; exclusive licensee American Association for the Advancement of Science. No claim to original U.S. Government Works. http://www.sciencemag.org/about/science-licenses-journal-article-reuseThis is an article distributed under the terms of the Science Journals Default License.},
	issn = {0036-8075, 1095-9203},
	url = {https://science.sciencemag.org/content/360/6394/1204},
	doi = {10.1126/science.aar6170},
	abstract = {A scene-internalizing computer program
To train a computer to “recognize” elements of a scene supplied by its visual sensors, computer scientists typically use millions of images painstakingly labeled by humans. Eslami et al. developed an artificial vision system, dubbed the Generative Query Network (GQN), that has no need for such labeled data. Instead, the GQN first uses images taken from different viewpoints and creates an abstract description of the scene, learning its essentials. Next, on the basis of this representation, the network predicts what the scene would look like from a new, arbitrary viewpoint.
Science, this issue p. 1204
Scene representation—the process of converting visual sensory data into concise descriptions—is a requirement for intelligent behavior. Recent work has shown that neural networks excel at this task when provided with large, labeled datasets. However, removing the reliance on human labeling remains an important open problem. To this end, we introduce the Generative Query Network (GQN), a framework within which machines learn to represent scenes using only their own sensors. The GQN takes as input images of a scene taken from different viewpoints, constructs an internal representation, and uses this representation to predict the appearance of that scene from previously unobserved viewpoints. The GQN demonstrates representation learning without human labels or domain knowledge, paving the way toward machines that autonomously learn to understand the world around them.
A computer vision system predicts how a 3D scene looks from any viewpoint after just a few 2D views from other viewpoints.
A computer vision system predicts how a 3D scene looks from any viewpoint after just a few 2D views from other viewpoints.},
	language = {en},
	number = {6394},
	urldate = {2019-09-15},
	journal = {Science},
	author = {Eslami, S. M. Ali and Rezende, Danilo Jimenez and Besse, Frederic and Viola, Fabio and Morcos, Ari S. and Garnelo, Marta and Ruderman, Avraham and Rusu, Andrei A. and Danihelka, Ivo and Gregor, Karol and Reichert, David P. and Buesing, Lars and Weber, Theophane and Vinyals, Oriol and Rosenbaum, Dan and Rabinowitz, Neil and King, Helen and Hillier, Chloe and Botvinick, Matt and Wierstra, Daan and Kavukcuoglu, Koray and Hassabis, Demis},
	month = jun,
	year = {2018},
	pmid = {29903970},
	pages = {1204--1210},
	file = {Full Text PDF:C\:\\Users\\alien\\Zotero\\storage\\6QJBP78R\\Eslami et al. - 2018 - Neural scene representation and rendering.pdf:application/pdf;Snapshot:C\:\\Users\\alien\\Zotero\\storage\\YDQD7NJV\\1204.html:text/html}
}

@misc{noauthor_biblatex_nodate,
	title = {Biblatex citation styles},
	url = {https://www.overleaf.com/learn/latex/Biblatex_citation_styles},
	abstract = {An online LaTeX editor that's easy to use. No installation, real-time collaboration, version control, hundreds of LaTeX templates, and more.},
	language = {en},
	urldate = {2019-09-15},
	file = {Snapshot:C\:\\Users\\alien\\Zotero\\storage\\XVIGDXXX\\Biblatex_citation_styles.html:text/html}
}

@article{shadrin_instance_nodate,
	title = {Instance segmentation for assessment of plant growth dynamics in artiﬁcial soilless conditions},
	abstract = {The paper presents a technology for plant growth dynamics estimation in an artiﬁcial soilless system. The approach consists of a hardware setup for automated image acquisition, plant feeding system, conditional monitoring and a software for automatic leaves segmentation and tracking. The software part of the system relies on a convolution neural network for instance segmentation. To train the neural network a manually annotated dataset was made.},
	language = {en},
	author = {Shadrin, Dmitrii},
	pages = {11},
	file = {Shadrin - Instance segmentation for assessment of plant grow.pdf:C\:\\Users\\alien\\Zotero\\storage\\KKKQTZDU\\Shadrin - Instance segmentation for assessment of plant grow.pdf:application/pdf}
}

@article{pettorelli_using_2005,
	title = {Using the satellite-derived {NDVI} to assess ecological responses to environmental change.},
	volume = {20},
	doi = {10.1016/j.tree.2005.05.011},
	abstract = {Assessing how environmental changes affect the distribution and dynamics of vegetation and animal populations is becoming increasingly important for terrestrial ecologists to enable better predictions of the effects of global warming, biodiversity reduction or habitat degradation. The ability to predict ecological responses has often been hampered by our rather limited understanding of trophic interactions. Indeed, it has proven difficult to discern direct and indirect effects of environmental change on animal populations owing to limited information about vegetation at large temporal and spatial scales. The rapidly increasing use of the Normalized Difference Vegetation Index (NDVI) in ecological studies has recently changed this situation. Here, we review the use of the NDVI in recent ecological studies and outline its possible key role in future research of environmental change in an ecosystem context.},
	number = {9},
	journal = {Trends in ecology \& evolution},
	author = {Pettorelli, Nathalie and Vik, Jon Olav and Mysterud, Atle and Gaillard, Jean-michel and Tucker, Compton J. and Stenseth, Nils Chr},
	year = {2005},
	keywords = {ATXN3 gene, Curie, Droughts, Ecosystem, Global Warming, Metals, Rare Earth, The Ohio State University Comprehensive Cancer Center, Trait, United States National Aeronautics and Space Administration},
	pages = {503--510}
}

@article{bonfil_wheat_2017,
	title = {Wheat phenomics in the field by {RapidScan}: {NDVI} vs. {NDRE}},
	volume = {64},
	issn = {0792-9978, 2223-8980},
	shorttitle = {Wheat phenomics in the field by {RapidScan}},
	url = {https://brill.com/view/journals/ijps/64/3-4/article-p41_41.xml},
	doi = {10.1080/07929978.2016.1249135},
	language = {en},
	number = {3-4},
	urldate = {2019-09-15},
	journal = {Israel Journal of Plant Sciences},
	author = {Bonfil, David J.},
	month = dec,
	year = {2017},
	pages = {41--54},
	file = {Snapshot:C\:\\Users\\alien\\Zotero\\storage\\KZU8KUWU\\article-p41_41.html:text/html}
}

@article{rouse_j.w_haas_r.h._scheel_j.a._and_deering_d.w._1974_monitoring_1974,
	title = {Monitoring {Vegetation} {Systems} in the {Great} {Plains} with {ERTS}.},
	url = {https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/19740022592.pdf},
	urldate = {2019-09-15},
	author = {Rouse, J.W, Haas, R.H., Scheel, J.A., {and} Deering, D.W. (1974), J.W},
	year = {1974},
	pages = {48--62},
	file = {19740022592.pdf:C\:\\Users\\alien\\Zotero\\storage\\6ND293DM\\19740022592.pdf:application/pdf}
}

@article{tisne_phenoscope:_2013,
	title = {Phenoscope: an automated large-scale phenotyping platform offering high spatial homogeneity},
	volume = {74},
	copyright = {© 2013 The Authors The Plant Journal © 2013 Blackwell Publishing Ltd},
	issn = {1365-313X},
	shorttitle = {Phenoscope},
	url = {https://www.onlinelibrary.wiley.com/doi/abs/10.1111/tpj.12131},
	doi = {10.1111/tpj.12131},
	abstract = {Increased phenotyping accuracy and throughput are necessary to improve our understanding of quantitative variation and to be able to deconstruct complex traits such as those involved in growth responses to the environment. Still, only a few facilities are known to handle individual plants of small stature for non-destructive, real-time phenotype acquisition from plants grown in precisely adjusted and variable experimental conditions. Here, we describe Phenoscope, a high-throughput phenotyping platform that has the unique feature of continuously rotating 735 individual pots over a table. It automatically adjusts watering and is equipped with a zenithal imaging system to monitor rosette size and expansion rate during the vegetative stage, with automatic image analysis allowing manual correction. When applied to Arabidopsis thaliana, we show that rotating the pots strongly reduced micro-environmental disparity: heterogeneity in evaporation was cut by a factor of 2.5 and the number of replicates needed to detect a specific mild genotypic effect was reduced by a factor of 3. In addition, by controlling a large proportion of the micro-environmental variance, other tangible sources of variance become noticeable. Overall, Phenoscope makes it possible to perform large-scale experiments that would not be possible or reproducible by hand. When applied to a typical quantitative trait loci (QTL) mapping experiment, we show that mapping power is more limited by genetic complexity than phenotyping accuracy. This will help to draw a more general picture as to how genetic diversity shapes phenotypic variation.},
	language = {en},
	number = {3},
	urldate = {2019-09-15},
	journal = {The Plant Journal},
	author = {Tisné, Sébastien and Serrand, Yann and Bach, Liên and Gilbault, Elodie and Ameur, Rachid Ben and Balasse, Hervé and Voisin, Roger and Bouchez, David and Durand‐Tardif, Mylène and Guerche, Philippe and Chareyron, Gaël and Rugna, Jérôme Da and Camilleri, Christine and Loudet, Olivier},
	year = {2013},
	keywords = {Arabidopsis thaliana, drought, growth, high-throughput, image analysis, phenotyping, technical advance},
	pages = {534--544},
	file = {Snapshot:C\:\\Users\\alien\\Zotero\\storage\\5UYCR3AR\\tpj.html:text/html}
}

@article{chene_use_2012,
	title = {On the use of depth camera for {3D} phenotyping of entire plants},
	volume = {82},
	issn = {01681699},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S016816991100319X},
	doi = {10.1016/j.compag.2011.12.007},
	abstract = {In this article, we assess the potential of depth imaging systems for 3D measurements in the context of plant phenotyping. We propose an original algorithm to segment depth images of plant from a single topview. Various applications of biological interest involving for illustration rosebush, yucca and apple tree are then presented to demonstrate the practical interest of such imaging systems. In addition, the depth camera used here is very low cost and low weight. The present results therefore open interesting perspectives in the direction of high-throughput phenotyping in controlled environment or in ﬁeld conditions. Ó 2012 Elsevier B.V. All rights reserved.},
	language = {en},
	urldate = {2019-09-15},
	journal = {Computers and Electronics in Agriculture},
	author = {Chéné, Yann and Rousseau, David and Lucidarme, Philippe and Bertheloot, Jessica and Caffier, Valérie and Morel, Philippe and Belin, Étienne and Chapeau-Blondeau, François},
	month = mar,
	year = {2012},
	pages = {122--127},
	file = {Chéné et al. - 2012 - On the use of depth camera for 3D phenotyping of e.pdf:C\:\\Users\\alien\\Zotero\\storage\\INMEXNGA\\Chéné et al. - 2012 - On the use of depth camera for 3D phenotyping of e.pdf:application/pdf}
}

@article{santos_automatic_nodate-1,
	title = {Automatic {3D} plant reconstruction from photographies, segmentation and classification of leaves and internodes using clustering},
	language = {en},
	author = {Santos, Thiago and Ueda, Julio},
	pages = {3},
	file = {Santos et Ueda - Automatic 3D plant reconstruction from photographi.pdf:C\:\\Users\\alien\\Zotero\\storage\\NCTYIJ2J\\Santos et Ueda - Automatic 3D plant reconstruction from photographi.pdf:application/pdf}
}

@book{prusinkiewicz_algorithmic_2012,
	title = {The {Algorithmic} {Beauty} of {Plants}},
	isbn = {978-1-4613-8476-2},
	abstract = {The beauty of plants has attracted the attention of mathematicians for Mathematics centuries. Conspicuous geometric features such as the bilateral sym and beauty metry of leaves, the rotational symmetry of flowers, and the helical arrangements of scales in pine cones have been studied most exten sively. This focus is reflected in a quotation from Weyl [159, page 3], "Beauty is bound up with symmetry. " This book explores two other factors that organize plant structures and therefore contribute to their beauty. The first is the elegance and relative simplicity of developmental algorithms, that is, the rules which describe plant development in time. The second is self-similarity, char acterized by Mandelbrot [95, page 34] as follows: When each piece of a shape is geometrically similar to the whole, both the shape and the cascade that generate it are called self-similar. This corresponds with the biological phenomenon described by Herman, Lindenmayer and Rozenberg [61]: In many growth processes of living organisms, especially of plants, regularly repeated appearances of certain multicel lular structures are readily noticeable. . . . In the case of a compound leaf, for instance, some of the lobes (or leaflets), which are parts of a leaf at an advanced stage, have the same shape as the whole leaf has at an earlier stage. Thus, self-similarity in plants is a result of developmental processes. Growth and By emphasizing the relationship between growth and form, this book form follows a long tradition in biology.},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Prusinkiewicz, Przemyslaw and Lindenmayer, Aristid},
	month = dec,
	year = {2012},
	note = {Google-Books-ID: 4F7lBwAAQBAJ},
	keywords = {Science / Life Sciences / Botany, Computers / Computer Science, Computers / General, Mathematics / General}
}

@incollection{sturm_pinhole_2014,
	address = {Boston, MA},
	title = {Pinhole {Camera} {Model}},
	isbn = {978-0-387-31439-6},
	url = {https://doi.org/10.1007/978-0-387-31439-6_472},
	language = {en},
	urldate = {2019-09-15},
	booktitle = {Computer {Vision}: {A} {Reference} {Guide}},
	publisher = {Springer US},
	author = {Sturm, Peter},
	editor = {Ikeuchi, Katsushi},
	year = {2014},
	doi = {10.1007/978-0-387-31439-6_472},
	pages = {610--613}
}

@misc{achanta_slic_2010,
	title = {{SLIC} {Superpixels}},
	url = {https://infoscience.epfl.ch/record/149300},
	abstract = {Superpixels are becoming increasingly popular for use in computer vision applications. However, there are few algorithms that output a desired number of regular, compact superpixels with a low computational overhead. We introduce a novel algorithm that clusters pixels in the combined five-dimensional color and image plane space to efficiently generate compact, nearly uniform superpixels. The simplicity of our approach makes it extremely easy to use -- a lone parameter specifies the number of superpixels -- and the efficiency of the algorithm makes it very practical. Experiments show that our approach produces superpixels at a lower computational cost while achieving a segmentation quality equal to or greater than four state-of-the-art methods, as measured by boundary recall and under-segmentation error. We also demonstrate the benefits of our superpixel approach in contrast to existing methods for two tasks in which superpixels have already been shown to increase performance over pixel-based methods.},
	language = {fr},
	urldate = {2019-09-15},
	journal = {Infoscience},
	author = {Achanta, Radhakrishna and Shaji, Appu and Smith, Kevin and Lucchi, Aurélien and Fua, Pascal and Süsstrunk, Sabine},
	year = {2010},
	file = {Full Text PDF:C\:\\Users\\alien\\Zotero\\storage\\F5RYIPGJ\\Achanta et al. - 2010 - SLIC Superpixels.pdf:application/pdf;Snapshot:C\:\\Users\\alien\\Zotero\\storage\\MTE6BDW5\\149300.pdf:application/pdf}
}

@incollection{dougherty_morphological_2018,
	edition = {1},
	title = {The {Morphological} {Approach} to {Segmentation}: {The} {Watershed} {Transformation}},
	isbn = {978-1-315-21461-0},
	shorttitle = {The {Morphological} {Approach} to {Segmentation}},
	url = {https://www.taylorfrancis.com/books/9781482277234/chapters/10.1201/9781482277234-12},
	language = {en},
	urldate = {2019-09-15},
	booktitle = {Mathematical {Morphology} in {Image} {Processing}},
	publisher = {CRC Press},
	author = {Beucher, S. and Meyer, F.},
	editor = {Dougherty, Edward R.},
	collaborator = {Dougherty, Edward},
	month = oct,
	year = {2018},
	doi = {10.1201/9781482277234-12},
	pages = {433--481},
	file = {Beucher et Meyer - 2018 - The Morphological Approach to Segmentation The Wa.pdf:C\:\\Users\\alien\\Zotero\\storage\\ZPSG3EUH\\Beucher et Meyer - 2018 - The Morphological Approach to Segmentation The Wa.pdf:application/pdf}
}

@article{kass_snakes:_1988,
	title = {Snakes: {Active} contour models},
	volume = {1},
	issn = {1573-1405},
	shorttitle = {Snakes},
	url = {https://doi.org/10.1007/BF00133570},
	doi = {10.1007/BF00133570},
	abstract = {A snake is an energy-minimizing spline guided by external constraint forces and influenced by image forces that pull it toward features such as lines and edges. Snakes are active contour models: they lock onto nearby edges, localizing them accurately. Scale-space continuation can be used to enlarge the capture region surrounding a feature. Snakes provide a unified account of a number of visual problems, including detection of edges, lines, and subjective contours; motion tracking; and stereo matching. We have used snakes successfully for interactive interpretation, in which user-imposed constraint forces guide the snake near features of interest.},
	language = {en},
	number = {4},
	urldate = {2019-09-15},
	journal = {International Journal of Computer Vision},
	author = {Kass, Michael and Witkin, Andrew and Terzopoulos, Demetri},
	month = jan,
	year = {1988},
	keywords = {Active Contour, Artificial Intelligence, Computer Image, Computer Vision, Image Processing},
	pages = {321--331}
}

@article{girardeau-montaut_cloudcompare-open_2011,
	title = {Cloudcompare-open source project},
	journal = {OpenSource Project},
	author = {Girardeau-Montaut, Daniel},
	year = {2011}
}

@article{paszke_pytorch:_2017,
	title = {Pytorch: {Tensors} and dynamic neural networks in python with strong gpu acceleration},
	volume = {6},
	shorttitle = {Pytorch},
	journal = {PyTorch: Tensors and dynamic neural networks in Python with strong GPU acceleration},
	author = {Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory},
	year = {2017}
}

@incollection{hecht-nielsen_iii.3_1992,
	title = {{III}.3 - {Theory} of the {Backpropagation} {Neural} {Network}**{Based} on “nonindent” by {Robert} {Hecht}-{Nielsen}, which appeared in {Proceedings} of the {International} {Joint} {Conference} on {Neural} {Networks} 1, 593–611, {June} 1989. © 1989 {IEEE}.},
	isbn = {978-0-12-741252-8},
	url = {http://www.sciencedirect.com/science/article/pii/B9780127412528500108},
	abstract = {This chapter presents a survey of the elementary theory of the basic backpropagation neural network architecture, covering the areas of architectural design, performance measurement, function approximation capability, and learning. The survey includes a formulation of the backpropagation neural network architecture to make it a valid neural network and a proof that the backpropagation mean squared error function exists and is differentiable. Also included in the survey is a theorem showing that any L2 function can be implemented to any desired degree of accuracy with a three-layer backpropagation neural network. An appendix presents a speculative neurophysiological model illustrating the way in which the backpropagation neural network architecture might plausibly be implemented in the mammalian brain for corticocortical learning between nearby regions of cerebral cortex. One of the crucial decisions in the design of the backpropagation architecture is the selection of a sigmoidal activation function.},
	urldate = {2019-09-15},
	booktitle = {Neural {Networks} for {Perception}},
	publisher = {Academic Press},
	author = {Hecht-nielsen, ROBERT},
	editor = {Wechsler, Harry},
	month = jan,
	year = {1992},
	doi = {10.1016/B978-0-12-741252-8.50010-8},
	pages = {65--93},
	file = {ScienceDirect Snapshot:C\:\\Users\\alien\\Zotero\\storage\\IV5E7XFC\\B9780127412528500108.html:text/html}
}

@article{kingma_adam:_2014,
	title = {Adam: {A} {Method} for {Stochastic} {Optimization}},
	shorttitle = {Adam},
	url = {http://arxiv.org/abs/1412.6980},
	abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
	urldate = {2019-09-15},
	journal = {arXiv:1412.6980 [cs]},
	author = {Kingma, Diederik P. and Ba, Jimmy},
	month = dec,
	year = {2014},
	note = {arXiv: 1412.6980},
	keywords = {Computer Science - Machine Learning},
	annote = {Comment: Published as a conference paper at the 3rd International Conference for Learning Representations, San Diego, 2015},
	file = {arXiv\:1412.6980 PDF:C\:\\Users\\alien\\Zotero\\storage\\SVLAP4PW\\Kingma et Ba - 2014 - Adam A Method for Stochastic Optimization.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\alien\\Zotero\\storage\\QDI4MMYP\\1412.html:text/html}
}

@article{hochreiter_vanishing_1998,
	title = {The {Vanishing} {Gradient} {Problem} {During} {Learning} {Recurrent} {Neural} {Nets}  and {Problem} {Solutions}},
	volume = {06},
	issn = {0218-4885},
	url = {https://www.worldscientific.com/doi/abs/10.1142/S0218488598000094},
	doi = {10.1142/S0218488598000094},
	abstract = {Recurrent nets are in principle capable to store past inputs to produce  the currently desired output. Because of this property recurrent nets  are used in time series prediction and process control. Practical  applications involve temporal dependencies spanning many time steps,  e.g. between relevant inputs and desired outputs. In this case, however,  gradient based learning methods take too much time. The extremely  increased learning time arises because the error vanishes as it gets  propagated back. In this article the de-caying error flow is theoretically  analyzed. Then methods trying to overcome vanishing gradients are briefly  discussed. Finally, experiments comparing conventional algorithms and  alternative methods are presented. With advanced methods long time lag  problems can be solved in reasonable time.},
	number = {02},
	urldate = {2019-09-15},
	journal = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
	author = {Hochreiter, Sepp},
	month = apr,
	year = {1998},
	pages = {107--116},
	file = {Snapshot:C\:\\Users\\alien\\Zotero\\storage\\A44N8I95\\S0218488598000094.html:text/html}
}

@article{russell_labelme:_2008,
	title = {{LabelMe}: {A} {Database} and {Web}-{Based} {Tool} for {Image} {Annotation}},
	volume = {77},
	issn = {1573-1405},
	shorttitle = {{LabelMe}},
	url = {https://doi.org/10.1007/s11263-007-0090-8},
	doi = {10.1007/s11263-007-0090-8},
	abstract = {We seek to build a large collection of images with ground truth labels to be used for object detection and recognition research. Such data is useful for supervised learning and quantitative evaluation. To achieve this, we developed a web-based tool that allows easy image annotation and instant sharing of such annotations. Using this annotation tool, we have collected a large dataset that spans many object categories, often containing multiple instances over a wide variety of images. We quantify the contents of the dataset and compare against existing state of the art datasets used for object recognition and detection. Also, we show how to extend the dataset to automatically enhance object labels with WordNet, discover object parts, recover a depth ordering of objects in a scene, and increase the number of labels using minimal user supervision and images from the web.},
	language = {en},
	number = {1},
	urldate = {2019-09-15},
	journal = {International Journal of Computer Vision},
	author = {Russell, Bryan C. and Torralba, Antonio and Murphy, Kevin P. and Freeman, William T.},
	month = may,
	year = {2008},
	keywords = {Annotation tool, Database, Object detection, Object recognition},
	pages = {157--173}
}

@article{chang_shapenet:_2015,
	title = {{ShapeNet}: {An} {Information}-{Rich} {3D} {Model} {Repository}},
	shorttitle = {{ShapeNet}},
	url = {http://arxiv.org/abs/1512.03012},
	abstract = {We present ShapeNet: a richly-annotated, large-scale repository of shapes represented by 3D CAD models of objects. ShapeNet contains 3D models from a multitude of semantic categories and organizes them under the WordNet taxonomy. It is a collection of datasets providing many semantic annotations for each 3D model such as consistent rigid alignments, parts and bilateral symmetry planes, physical sizes, keywords, as well as other planned annotations. Annotations are made available through a public web-based interface to enable data visualization of object attributes, promote data-driven geometric analysis, and provide a large-scale quantitative benchmark for research in computer graphics and vision. At the time of this technical report, ShapeNet has indexed more than 3,000,000 models, 220,000 models out of which are classified into 3,135 categories (WordNet synsets). In this report we describe the ShapeNet effort as a whole, provide details for all currently available datasets, and summarize future plans.},
	urldate = {2019-09-15},
	journal = {arXiv:1512.03012 [cs]},
	author = {Chang, Angel X. and Funkhouser, Thomas and Guibas, Leonidas and Hanrahan, Pat and Huang, Qixing and Li, Zimo and Savarese, Silvio and Savva, Manolis and Song, Shuran and Su, Hao and Xiao, Jianxiong and Yi, Li and Yu, Fisher},
	month = dec,
	year = {2015},
	note = {arXiv: 1512.03012},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Artificial Intelligence, Computer Science - Robotics, Computer Science - Computational Geometry, Computer Science - Graphics},
	file = {arXiv\:1512.03012 PDF:C\:\\Users\\alien\\Zotero\\storage\\7U697MPL\\Chang et al. - 2015 - ShapeNet An Information-Rich 3D Model Repository.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\alien\\Zotero\\storage\\5YNSJ6YV\\1512.html:text/html}
}

@misc{noauthor_segmentation_nodate,
	title = {Segmentation of {3D} meshes through spectral clustering - {IEEE} {Conference} {Publication}},
	url = {https://ieeexplore.ieee.org/abstract/document/1348360},
	urldate = {2019-09-15},
	file = {Segmentation of 3D meshes through spectral clustering - IEEE Conference Publication:C\:\\Users\\alien\\Zotero\\storage\\GKQFT7MV\\1348360.html:text/html}
}

@article{fournier_phenomenal_nodate,
	title = {Phenomenal: a software framework for model-assisted analysis of high throughput plant phenotyping data},
	language = {en},
	author = {Fournier, Christian and Artzet, Simon and Chopard, Jérôme and Mielewczik, Michael and Brichet, Nicolas and Cabrera, Llorenç and Sirault, Xavier and Cohen-Boulakia, Sarah and Pradal, Christophe},
	pages = {3},
	file = {Fournier et al. - Phenomenal a software framework for model-assiste.pdf:C\:\\Users\\alien\\Zotero\\storage\\9XCLCTGH\\Fournier et al. - Phenomenal a software framework for model-assiste.pdf:application/pdf}
}



@article{shi_plant-part_2019,
	title = {Plant-part segmentation using deep learning and multi-view vision},
	volume = {187},
	issn = {1537-5110},
	url = {http://www.sciencedirect.com/science/article/pii/S1537511019308098},
	doi = {10.1016/j.biosystemseng.2019.08.014},
	abstract = {To accelerate the understanding of the relationship between genotype and phenotype, plant scientists and plant breeders are looking for more advanced phenotyping systems that provide more detailed phenotypic information about plants. Most current systems provide information on the whole-plant level and not on the level of specific plant parts such as leaves, nodes and stems. Computer vision provides possibilities to extract information from plant parts from images. However, the segmentation of plant parts is a challenging problem, due to the inherent variation in appearance and shape of natural objects. In this paper, deep-learning methods are proposed to deal with this variation. Moreover, a multi-view approach is taken that allows the integration of information from the two-dimensional (2D) images into a three-dimensional (3D) point-cloud model of the plant. Specifically, a fully convolutional network (FCN) and a masked R-CNN (region-based convolutional neural network) were used for semantic and instance segmentation on the 2D images. The different viewpoints were then combined to segment the 3D point cloud. The performance of the 2D and multi-view approaches was evaluated on tomato seedling plants. Our results show that the integration of information in 3D outperforms the 2D approach, because errors in 2D are not persistent for the different viewpoints and can therefore be overcome in 3D.},
	language = {en},
	urldate = {2020-03-23},
	journal = {Biosystems Engineering},
	author = {Shi, Weinan and van de Zedde, Rick and Jiang, Huanyu and Kootstra, Gert},
	month = nov,
	year = {2019},
	keywords = {2D images and 3D point clouds, digital plant phenotyping, instance segmentation, semantic segmentation},
	pages = {81--95},
	file = {ScienceDirect Snapshot:C\:\\Users\\alien\\Zotero\\storage\\PUDL3HLC\\S1537511019308098.html:text/html}
}

@inproceedings{kalogerakis_3d_2017,
	address = {Honolulu, HI},
	title = {{3D} {Shape} {Segmentation} with {Projective} {Convolutional} {Networks}},
	isbn = {978-1-5386-0457-1},
	url = {http://ieeexplore.ieee.org/document/8100185/},
	doi = {10.1109/CVPR.2017.702},
	abstract = {This paper introduces a deep architecture for segmenting 3D objects into their labeled semantic parts. Our architecture combines image-based Fully Convolutional Networks (FCNs) and surface-based Conditional Random Fields (CRFs) to yield coherent segmentations of 3D shapes. The image-based FCNs are used for efﬁcient view-based reasoning about 3D object parts. Through a special projection layer, FCN outputs are effectively aggregated across multiple views and scales, then are projected onto the 3D object surfaces. Finally, a surface-based CRF combines the projected outputs with geometric consistency cues to yield coherent segmentations. The whole architecture (multi-view FCNs and CRF) is trained end-to-end. Our approach signiﬁcantly outperforms the existing stateof-the-art methods in the currently largest segmentation benchmark (ShapeNet). Finally, we demonstrate promising segmentation results on noisy 3D shapes acquired from consumer-grade depth cameras.},
	language = {en},
	urldate = {2020-03-23},
	booktitle = {2017 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Kalogerakis, Evangelos and Averkiou, Melinos and Maji, Subhransu and Chaudhuri, Siddhartha},
	month = jul,
	year = {2017},
	pages = {6630--6639},
	file = {Kalogerakis et al. - 2017 - 3D Shape Segmentation with Projective Convolutiona.pdf:C\:\\Users\\alien\\Zotero\\storage\\7WQ98ZYJ\\Kalogerakis et al. - 2017 - 3D Shape Segmentation with Projective Convolutiona.pdf:application/pdf}
}


@article{li_review_2014,
	title = {A Review of Imaging Techniques for Plant Phenotyping},
	volume = {14},
	issn = {1424-8220},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4279472/},
	doi = {10.3390/s141120078},
	abstract = {Given the rapid development of plant genomic technologies, a lack of access to plant phenotyping capabilities limits our ability to dissect the genetics of quantitative traits. Effective, high-throughput phenotyping platforms have recently been developed to solve this problem. In high-throughput phenotyping platforms, a variety of imaging methodologies are being used to collect data for quantitative studies of complex traits related to the growth, yield and adaptation to biotic or abiotic stress (disease, insects, drought and salinity). These imaging techniques include visible imaging (machine vision), imaging spectroscopy (multispectral and hyperspectral remote sensing), thermal infrared imaging, fluorescence imaging, 3D imaging and tomographic imaging ({MRT}, {PET} and {CT}). This paper presents a brief review on these imaging techniques and their applications in plant phenotyping. The features used to apply these imaging techniques to plant phenotyping are described and discussed in this review.},
	pages = {20078--20111},
	number = {11},
	journaltitle = {Sensors (Basel, Switzerland)},
	shortjournal = {Sensors (Basel)},
	author = {Li, Lei and Zhang, Qin and Huang, Danfeng},
	urldate = {2020-03-23},
	date = {2014-10-24},
	pmid = {25347588},
	pmcid = {PMC4279472},
	file = {PubMed Central Full Text PDF:C\:\\Users\\alien\\Zotero\\storage\\LM72GPJ8\\Li et al. - 2014 - A Review of Imaging Techniques for Plant Phenotypi.pdf:application/pdf}
}

@article{perez-sanz_plant_2017,
	title = {Plant phenomics: an overview of image acquisition technologies and image data analysis algorithms},
	volume = {6},
	url = {https://academic.oup.com/gigascience/article/6/11/gix092/4316962},
	doi = {10.1093/gigascience/gix092},
	shorttitle = {Plant phenomics},
	abstract = {Abstract.  The study of phenomes or phenomics has been a central part of biology. The field of automatic phenotype acquisition technologies based on images has},
	number = {11},
	journaltitle = {{GigaScience}},
	shortjournal = {Gigascience},
	author = {Perez-Sanz, Fernando and Navarro, Pedro J. and Egea-Cortines, Marcos},
	urldate = {2020-03-23},
	date = {2017-11-01},
	langid = {english},
	file = {Full Text PDF:C\:\\Users\\alien\\Zotero\\storage\\GEL5BWQ8\\Perez-Sanz et al. - 2017 - Plant phenomics an overview of image acquisition .pdf:application/pdf;Snapshot:C\:\\Users\\alien\\Zotero\\storage\\YGLMNUEJ\\4316962.html:text/html}
}

@article{Lpy_godin,
  author = {Godin, Christophe},
  title = {Virtual Plants},
  year = {2019},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/romi/VirtualPlants}},
  commit = {df8c147d8d0ba54837016c8e047def249b3196c5}
}
