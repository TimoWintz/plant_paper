In this work, we have presented and assessed a fullly automated method for segmentation of
plants from 2D pictures using convolutional networks for segmentation in 2D and
backprojection of 3D points for segmentation in 3D.

The most noteworthy conclusion from this work is that we have demonstrated that using generative
models of plants for training neural networks and apply the trained algorithms
on real specimen of plants is robust enough that no additional annotation of
data is needed. This is of utmost importance to the field of plant biology, since annotation of data
is very time-consuming, and the variety in plant species makes
the never-ending annotation of new species a never ending task.

We have also shown that minimal annotation of real world data can be enough to
transfer the models to very different plants. These tests done on small datasets
only call for further investigation of how well the models can generalize to whole
classes of plants when mixing several plant models together. We are confident
that they indeed generalize well, given the recent successes in using
convolutional neural network for segmentation tasks, but it would need to
develop or adapt generative models of other plant species.

Another perspective of work is to investigate whether the obtained segmentation is precise
enough that we can use it to gather quantitative data on the plant themselves,
as this would prove to be very valuable to many fields in plant biology. A
testing procedure will be developped and compared to more traditional geometry
based approaches for the specific application of measuring the phyllotactic
angles of Arabidopsis thaliana.
